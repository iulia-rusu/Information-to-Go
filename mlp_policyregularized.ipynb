{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __future__ import should always be first\n",
    "from __future__ import annotations\n",
    "\n",
    "# Standard library imports\n",
    "from collections import defaultdict\n",
    "\n",
    "# Third-party imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Gymnasium & Minigrid imports\n",
    "import gymnasium as gym  # Correct way to import Gymnasium\n",
    "from gymnasium.spaces import Dict, Discrete, Box\n",
    "from minigrid.core.constants import COLOR_NAMES\n",
    "from minigrid.core.constants import DIR_TO_VEC\n",
    "from minigrid.core.grid import Grid\n",
    "from minigrid.core.actions import Actions\n",
    "from minigrid.core.mission import MissionSpace\n",
    "from minigrid.core.world_object import Door, Goal, Key, Wall\n",
    "from minigrid.manual_control import ManualControl\n",
    "from minigrid.minigrid_env import MiniGridEnv\n",
    "from gymnasium.utils.play import play\n",
    "import pandas as pd\n",
    "# Visualization imports\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleEnv(MiniGridEnv):\n",
    "    def __init__(\n",
    "            self, \n",
    "            size=10, \n",
    "            agent_start_pos=(1, 8), \n",
    "            agent_start_dir=0, \n",
    "            max_steps=1000, \n",
    "            **kwargs,\n",
    "    ):\n",
    "        self.agent_start_pos = agent_start_pos\n",
    "        self.agent_start_dir = agent_start_dir\n",
    "        self.goal_pos = (8, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
    "\n",
    "        super().__init__(\n",
    "            mission_space=mission_space,\n",
    "            grid_size=size,\n",
    "            max_steps=max_steps,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "    @staticmethod\n",
    "    def _gen_mission():\n",
    "        return \"Find the shortest path\"\n",
    "\n",
    "    def _gen_grid(self, width, height):\n",
    "        #create gird\n",
    "        self.grid = Grid(width, height)\n",
    "        #place barrier\n",
    "        self.grid.wall_rect(0, 0, width, height)\n",
    "        #place goal\n",
    "        self.put_obj(Goal(), 8, 1)\n",
    "        #place walls\n",
    "        for i in range(1, width // 2):\n",
    "            self.grid.set(i, width - 4, Wall())\n",
    "            self.grid.set(i + width // 2 - 1, width - 7, Wall())\n",
    "        #place agent\n",
    "        if self.agent_start_pos is not None:\n",
    "            self.agent_pos = self.agent_start_pos #check this\n",
    "            self.agent_dir = self.agent_start_dir\n",
    "        else:\n",
    "            self.place_agent()\n",
    "\n",
    "        self.mission = \"find the shortest path\"\n",
    "    \n",
    "    def count_states(self):\n",
    "        free_cells = sum(1 for x in range(self.grid.width)\n",
    "                      for y in range(self.grid.height)\n",
    "                      if not self.grid.get(x, y)) * 4\n",
    "        return free_cells \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SimpleEnv(render_mode= None)\n",
    "env.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs shape after step: (7, 7, 3)\n"
     ]
    }
   ],
   "source": [
    "action = 0\n",
    "obs, _, _, _, _ = env.step(action)\n",
    "print(\"Obs shape after step:\", obs[\"image\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs shape after step: (7, 7, 3)\n"
     ]
    }
   ],
   "source": [
    "action = 0\n",
    "obs1, _, _, _, _ = env.step(action)\n",
    "print(\"Obs shape after step:\", obs[\"image\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGridFlatImg(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Keep only the 7x7 RGB image from a MiniGrid Dict observation.\n",
    "    Output: 147-dim float32 vector in [0, 1].\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        # initialise the parent ObservationWrapper so it can do its bookkeeping\n",
    "        super().__init__(env)\n",
    "\n",
    "        img_size = np.prod(env.observation_space[\"image\"].shape)   # 7*7*3 = 147\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0.0, high=1.0, shape=(img_size,), dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        img_flat = obs[\"image\"].astype(np.float32).flatten() / 255.0\n",
    "        return img_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGridReward(gym.Wrapper):\n",
    "    def __init__(self, env, goal_states):\n",
    "        super().__init__(env)\n",
    "        self.goal_states = set(goal_states)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, _, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        # access agent position after the transition\n",
    "        x, y = self.env.unwrapped.agent_pos\n",
    "        next_state = (x, y)\n",
    "\n",
    "        rew = 0 if next_state in self.goal_states else -1\n",
    "        done = terminated or truncated or (rew == 0)\n",
    "\n",
    "        return obs, rew, done, truncated, info\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_wrapped = MiniGridFlatImg(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_wrapped.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 0\n",
    "obs, _, _, _, _ = env_wrapped.step(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 0\n",
    "obs1, _, _, _, _ = env_wrapped.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0.0, 1.0, (147,), float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_wrapped.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_wrapped.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_wrapped_rew= MiniGridReward(env_wrapped, goal_states = [(8, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_wrapped_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = env_wrapped_rew.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(obs), \u001b[43mobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m) \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(type(obs), obs.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(sizes, activation = nn.Tanh, output_activation = nn.Identity):\n",
    "    layers = []\n",
    "    for i in range(len(sizes) - 1):\n",
    "        act = activation if i < len(sizes) -2 else output_activation #everything but last layer has activation, outherwise output\n",
    "        layers += [nn.Linear(sizes [i], sizes[i +1], act())]\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env_name = env_wrapped_rew, hidden_sizes = [32], lr = 1e-2, epochs = 50, batch_size = 50, render = False):\n",
    "\n",
    "    env = env_name\n",
    "\n",
    "    obs_dim = env.observation_space.shape[0] \n",
    "    # print(\"obs_dim:\", obs_dim)\n",
    "    n_acts = env.action_space.n\n",
    "    # print(\"n_acts:\", n_acts)\n",
    "\n",
    "    # pi(a) setting prior based on the observed distribution of actions being mostly moving forward\n",
    "    pi_a = np.array([1/6, 1/6, 2/3], dtype=np.float32)          # â† prior\n",
    "    # pi_a = np.array([1/3, 1/3, 1/3], dtype= np.float32)\n",
    "    pi_a = torch.tensor(pi_a)       \n",
    "\n",
    "\n",
    "    #generate polucy network\n",
    "    logits_net = mlp(sizes = [obs_dim] + hidden_sizes + [n_acts])\n",
    "\n",
    "    #takes policy network and returns action distribution\n",
    "    def get_policy(obs):\n",
    "        logits = logits_net(obs)\n",
    "        return Categorical(logits = logits)\n",
    "\n",
    "    #samples actions from the action distrubution from the policy network\n",
    "    def get_action(obs):\n",
    "        return get_policy(obs).sample().item()\n",
    "    \n",
    "\n",
    "    # make loss function whose gradient, for the right data, is policy gradient\n",
    "    def compute_loss(obs, act, weights):\n",
    "        \n",
    "        logp = get_policy(obs).log_prob(act)\n",
    "        # print(\"logp shape\", logp.shape)\n",
    "\n",
    "        prior_dist = torch.distributions.Categorical(probs=pi_a)\n",
    "        prior_logp = prior_dist.log_prob(act) \n",
    "\n",
    "        \n",
    " \n",
    "        decision = logp - prior_logp\n",
    "        # print(\"decison term shape\", decision.shape)\n",
    "        return -(logp * weights + decision).mean()\n",
    "\n",
    "      # make optimizer\n",
    "    optimizer = Adam(logits_net.parameters(), lr=lr)\n",
    "\n",
    "    def train_one_epoch():\n",
    "        # make some empty lists for logging.\n",
    "        batch_obs = []          # for observations\n",
    "        batch_acts = []         # for actions\n",
    "        batch_weights = []      # for R(tau) weighting in policy gradient\n",
    "        batch_rets = []         # for measuring episode returns\n",
    "        batch_lens = []         # for measuring episode lengths\n",
    "\n",
    "        # reset episode-specific variables\n",
    "        obs, info = env.reset()      # first obs comes from starting distribution\n",
    "        # print(\"obs shape:\", obs.shape, \"obs type:\", type(obs))\n",
    "        done = False            # signal from environment that episode is over\n",
    "        ep_rews = []            # list for rewards accrued throughout ep\n",
    "\n",
    "        # render first episode of each epoch\n",
    "        finished_rendering_this_epoch = False\n",
    "\n",
    "        # collect experience by acting in the environment with current policy\n",
    "        while True:\n",
    "\n",
    "            # rendering\n",
    "            if (not finished_rendering_this_epoch) and render:\n",
    "                env.render()\n",
    "            # print(\"obs shape:\", obs.shape, \"obs type:\", type(obs))\n",
    "            # save obs\n",
    "            batch_obs.append(obs.copy())\n",
    "\n",
    "            # act in the environment\n",
    "            act = get_action(torch.as_tensor(obs, dtype=torch.float32))\n",
    "            obs, rew, done, _, _ = env.step(act)\n",
    "            \n",
    "            \n",
    "\n",
    "            # save action, reward\n",
    "            batch_acts.append(act)\n",
    "            ep_rews.append(rew)\n",
    "\n",
    "            if done:\n",
    "                # if episode is over, record info about episode\n",
    "                ep_ret, ep_len = sum(ep_rews), len(ep_rews)\n",
    "                batch_rets.append(ep_ret)\n",
    "                batch_lens.append(ep_len)\n",
    "\n",
    "                # the weight for each logprob(a|s) is R(tau)\n",
    "                batch_weights += [ep_ret] * ep_len     #why is this the way the setup is, this is where i want to add rewards\n",
    "\n",
    "                # reset episode-specific variables\n",
    "                obs, info  = env.reset()\n",
    "                done = False\n",
    "                ep_rews = []\n",
    "\n",
    "                # won't render again this epoch\n",
    "                finished_rendering_this_epoch = True\n",
    "\n",
    "                # end experience loop if we have enough of it\n",
    "                if len(batch_obs) > batch_size:\n",
    "                    break\n",
    "        # take a single policy gradient update step\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = compute_loss(obs=torch.as_tensor(batch_obs, dtype=torch.float32),\n",
    "                                  act=torch.as_tensor(batch_acts, dtype=torch.int32),\n",
    "                                  weights=torch.as_tensor(batch_weights, dtype=torch.float32)\n",
    "                                  )\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        return batch_loss, batch_rets, batch_lens\n",
    "\n",
    "    # training loop\n",
    "    for i in range(epochs):\n",
    "        batch_loss, batch_rets, batch_lens = train_one_epoch()\n",
    "        print('epoch: %3d \\t loss: %.3f \\t return: %.3f \\t ep_len: %.3f'%\n",
    "                (i, batch_loss, np.mean(batch_rets), np.mean(batch_lens)))\n",
    "        \n",
    "    return logits_net\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 \t loss: -1050.640 \t return: -865.167 \t ep_len: 865.500\n",
      "epoch:   1 \t loss: -1050.020 \t return: -896.500 \t ep_len: 896.667\n",
      "epoch:   2 \t loss: -1046.993 \t return: -920.333 \t ep_len: 920.500\n",
      "epoch:   3 \t loss: -894.115 \t return: -726.625 \t ep_len: 727.250\n",
      "epoch:   4 \t loss: -1035.962 \t return: -932.667 \t ep_len: 932.833\n",
      "epoch:   5 \t loss: -996.453 \t return: -877.167 \t ep_len: 877.500\n",
      "epoch:   6 \t loss: -962.241 \t return: -819.571 \t ep_len: 820.000\n",
      "epoch:   7 \t loss: -1011.837 \t return: -910.833 \t ep_len: 911.000\n",
      "epoch:   8 \t loss: -928.835 \t return: -873.000 \t ep_len: 873.500\n",
      "epoch:   9 \t loss: -1036.035 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch:  10 \t loss: -990.820 \t return: -941.833 \t ep_len: 942.000\n",
      "epoch:  11 \t loss: -832.007 \t return: -718.571 \t ep_len: 719.143\n",
      "epoch:  12 \t loss: -1008.757 \t return: -987.333 \t ep_len: 987.500\n",
      "epoch:  13 \t loss: -980.080 \t return: -897.167 \t ep_len: 897.333\n",
      "epoch:  14 \t loss: -995.198 \t return: -967.167 \t ep_len: 967.333\n",
      "epoch:  15 \t loss: -957.504 \t return: -849.833 \t ep_len: 850.167\n",
      "epoch:  16 \t loss: -988.832 \t return: -926.833 \t ep_len: 927.000\n",
      "epoch:  17 \t loss: -1038.526 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch:  18 \t loss: -1017.616 \t return: -976.500 \t ep_len: 976.667\n",
      "epoch:  19 \t loss: -998.957 \t return: -890.500 \t ep_len: 890.667\n",
      "epoch:  20 \t loss: -1017.812 \t return: -969.667 \t ep_len: 969.833\n",
      "epoch:  21 \t loss: -926.951 \t return: -752.143 \t ep_len: 752.714\n",
      "epoch:  22 \t loss: -1003.444 \t return: -884.667 \t ep_len: 884.833\n",
      "epoch:  23 \t loss: -988.987 \t return: -912.167 \t ep_len: 912.333\n",
      "epoch:  24 \t loss: -1031.119 \t return: -987.667 \t ep_len: 987.833\n",
      "epoch:  25 \t loss: -959.495 \t return: -885.167 \t ep_len: 885.667\n",
      "epoch:  26 \t loss: -935.018 \t return: -849.143 \t ep_len: 849.429\n",
      "epoch:  27 \t loss: -1031.178 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch:  28 \t loss: -1002.255 \t return: -885.667 \t ep_len: 885.833\n",
      "epoch:  29 \t loss: -991.151 \t return: -886.500 \t ep_len: 886.833\n",
      "epoch:  30 \t loss: -969.258 \t return: -806.857 \t ep_len: 807.143\n",
      "epoch:  31 \t loss: -974.742 \t return: -862.000 \t ep_len: 862.333\n",
      "epoch:  32 \t loss: -987.201 \t return: -928.167 \t ep_len: 928.500\n",
      "epoch:  33 \t loss: -976.375 \t return: -848.000 \t ep_len: 848.333\n",
      "epoch:  34 \t loss: -1007.446 \t return: -904.333 \t ep_len: 904.500\n",
      "epoch:  35 \t loss: -936.590 \t return: -802.000 \t ep_len: 802.429\n",
      "epoch:  36 \t loss: -1031.405 \t return: -976.000 \t ep_len: 976.333\n",
      "epoch:  37 \t loss: -952.351 \t return: -842.143 \t ep_len: 842.571\n",
      "epoch:  38 \t loss: -916.715 \t return: -717.250 \t ep_len: 717.750\n",
      "epoch:  39 \t loss: -922.743 \t return: -776.000 \t ep_len: 776.571\n",
      "epoch:  40 \t loss: -959.788 \t return: -845.333 \t ep_len: 845.833\n",
      "epoch:  41 \t loss: -1045.864 \t return: -998.500 \t ep_len: 998.667\n",
      "epoch:  42 \t loss: -995.376 \t return: -919.833 \t ep_len: 920.000\n",
      "epoch:  43 \t loss: -954.648 \t return: -875.333 \t ep_len: 875.667\n",
      "epoch:  44 \t loss: -834.237 \t return: -735.571 \t ep_len: 736.143\n",
      "epoch:  45 \t loss: -992.231 \t return: -965.667 \t ep_len: 965.833\n",
      "epoch:  46 \t loss: -944.174 \t return: -877.833 \t ep_len: 878.167\n",
      "epoch:  47 \t loss: -914.746 \t return: -869.000 \t ep_len: 869.500\n",
      "epoch:  48 \t loss: -737.730 \t return: -645.250 \t ep_len: 646.000\n",
      "epoch:  49 \t loss: -905.792 \t return: -791.286 \t ep_len: 791.714\n",
      "epoch:  50 \t loss: -898.603 \t return: -776.714 \t ep_len: 777.143\n",
      "epoch:  51 \t loss: -889.634 \t return: -833.429 \t ep_len: 833.857\n",
      "epoch:  52 \t loss: -861.217 \t return: -740.000 \t ep_len: 740.429\n",
      "epoch:  53 \t loss: -796.555 \t return: -671.125 \t ep_len: 671.750\n",
      "epoch:  54 \t loss: -892.441 \t return: -839.286 \t ep_len: 839.714\n",
      "epoch:  55 \t loss: -794.785 \t return: -723.714 \t ep_len: 724.429\n",
      "epoch:  56 \t loss: -859.518 \t return: -789.714 \t ep_len: 790.286\n",
      "epoch:  57 \t loss: -833.702 \t return: -659.125 \t ep_len: 659.750\n",
      "epoch:  58 \t loss: -590.909 \t return: -522.200 \t ep_len: 523.100\n",
      "epoch:  59 \t loss: -883.448 \t return: -849.857 \t ep_len: 850.429\n",
      "epoch:  60 \t loss: -850.564 \t return: -782.429 \t ep_len: 782.857\n",
      "epoch:  61 \t loss: -898.779 \t return: -881.833 \t ep_len: 882.167\n",
      "epoch:  62 \t loss: -809.962 \t return: -723.250 \t ep_len: 723.875\n",
      "epoch:  63 \t loss: -897.464 \t return: -872.000 \t ep_len: 872.500\n",
      "epoch:  64 \t loss: -898.982 \t return: -766.286 \t ep_len: 766.714\n",
      "epoch:  65 \t loss: -738.380 \t return: -611.333 \t ep_len: 612.000\n",
      "epoch:  66 \t loss: -800.028 \t return: -768.857 \t ep_len: 769.571\n",
      "epoch:  67 \t loss: -801.585 \t return: -770.286 \t ep_len: 770.857\n",
      "epoch:  68 \t loss: -749.731 \t return: -723.286 \t ep_len: 724.000\n",
      "epoch:  69 \t loss: -797.887 \t return: -736.875 \t ep_len: 737.500\n",
      "epoch:  70 \t loss: -726.600 \t return: -656.625 \t ep_len: 657.250\n",
      "epoch:  71 \t loss: -737.014 \t return: -714.143 \t ep_len: 714.857\n",
      "epoch:  72 \t loss: -684.156 \t return: -625.556 \t ep_len: 626.333\n",
      "epoch:  73 \t loss: -693.321 \t return: -658.125 \t ep_len: 658.875\n",
      "epoch:  74 \t loss: -653.908 \t return: -505.000 \t ep_len: 505.700\n",
      "epoch:  75 \t loss: -843.102 \t return: -948.500 \t ep_len: 948.833\n",
      "epoch:  76 \t loss: -637.288 \t return: -562.889 \t ep_len: 563.667\n",
      "epoch:  77 \t loss: -748.073 \t return: -716.286 \t ep_len: 716.857\n",
      "epoch:  78 \t loss: -797.059 \t return: -823.429 \t ep_len: 823.857\n",
      "epoch:  79 \t loss: -799.480 \t return: -749.000 \t ep_len: 749.429\n",
      "epoch:  80 \t loss: -855.678 \t return: -927.500 \t ep_len: 927.667\n",
      "epoch:  81 \t loss: -776.566 \t return: -658.875 \t ep_len: 659.500\n",
      "epoch:  82 \t loss: -899.167 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch:  83 \t loss: -838.409 \t return: -876.500 \t ep_len: 877.000\n",
      "epoch:  84 \t loss: -864.798 \t return: -864.500 \t ep_len: 864.667\n",
      "epoch:  85 \t loss: -840.303 \t return: -873.333 \t ep_len: 873.667\n",
      "epoch:  86 \t loss: -728.056 \t return: -743.143 \t ep_len: 743.714\n",
      "epoch:  87 \t loss: -817.943 \t return: -909.500 \t ep_len: 909.833\n",
      "epoch:  88 \t loss: -763.040 \t return: -705.875 \t ep_len: 706.375\n",
      "epoch:  89 \t loss: -723.878 \t return: -685.750 \t ep_len: 686.500\n",
      "epoch:  90 \t loss: -876.534 \t return: -886.333 \t ep_len: 886.500\n",
      "epoch:  91 \t loss: -854.613 \t return: -827.143 \t ep_len: 827.429\n",
      "epoch:  92 \t loss: -819.052 \t return: -845.333 \t ep_len: 845.667\n",
      "epoch:  93 \t loss: -833.379 \t return: -837.143 \t ep_len: 837.429\n",
      "epoch:  94 \t loss: -800.131 \t return: -732.000 \t ep_len: 732.571\n",
      "epoch:  95 \t loss: -794.544 \t return: -789.000 \t ep_len: 789.429\n",
      "epoch:  96 \t loss: -867.298 \t return: -923.333 \t ep_len: 923.667\n",
      "epoch:  97 \t loss: -902.871 \t return: -931.000 \t ep_len: 931.333\n",
      "epoch:  98 \t loss: -914.374 \t return: -976.167 \t ep_len: 976.667\n",
      "epoch:  99 \t loss: -920.175 \t return: -969.333 \t ep_len: 969.500\n",
      "epoch: 100 \t loss: -844.423 \t return: -854.500 \t ep_len: 855.000\n",
      "epoch: 101 \t loss: -820.404 \t return: -748.875 \t ep_len: 749.500\n",
      "epoch: 102 \t loss: -795.214 \t return: -753.143 \t ep_len: 753.714\n",
      "epoch: 103 \t loss: -943.723 \t return: -969.667 \t ep_len: 970.000\n",
      "epoch: 104 \t loss: -912.784 \t return: -952.000 \t ep_len: 952.167\n",
      "epoch: 105 \t loss: -900.059 \t return: -839.500 \t ep_len: 839.833\n",
      "epoch: 106 \t loss: -932.525 \t return: -914.667 \t ep_len: 914.833\n",
      "epoch: 107 \t loss: -882.846 \t return: -842.667 \t ep_len: 843.167\n",
      "epoch: 108 \t loss: -961.496 \t return: -956.167 \t ep_len: 956.333\n",
      "epoch: 109 \t loss: -898.362 \t return: -733.000 \t ep_len: 733.500\n",
      "epoch: 110 \t loss: -970.576 \t return: -880.667 \t ep_len: 880.833\n",
      "epoch: 111 \t loss: -851.347 \t return: -660.125 \t ep_len: 660.750\n",
      "epoch: 112 \t loss: -827.583 \t return: -658.000 \t ep_len: 658.667\n",
      "epoch: 113 \t loss: -981.595 \t return: -871.833 \t ep_len: 872.000\n",
      "epoch: 114 \t loss: -933.698 \t return: -842.857 \t ep_len: 843.143\n",
      "epoch: 115 \t loss: -705.323 \t return: -590.000 \t ep_len: 590.778\n",
      "epoch: 116 \t loss: -876.387 \t return: -765.714 \t ep_len: 766.286\n",
      "epoch: 117 \t loss: -931.787 \t return: -891.000 \t ep_len: 891.333\n",
      "epoch: 118 \t loss: -904.148 \t return: -809.000 \t ep_len: 809.571\n",
      "epoch: 119 \t loss: -845.770 \t return: -691.625 \t ep_len: 692.125\n",
      "epoch: 120 \t loss: -922.399 \t return: -877.500 \t ep_len: 877.833\n",
      "epoch: 121 \t loss: -976.186 \t return: -931.333 \t ep_len: 931.667\n",
      "epoch: 122 \t loss: -928.927 \t return: -859.667 \t ep_len: 860.000\n",
      "epoch: 123 \t loss: -934.269 \t return: -870.000 \t ep_len: 870.333\n",
      "epoch: 124 \t loss: -958.488 \t return: -902.500 \t ep_len: 902.833\n",
      "epoch: 125 \t loss: -951.855 \t return: -886.500 \t ep_len: 886.833\n",
      "epoch: 126 \t loss: -930.162 \t return: -736.000 \t ep_len: 736.500\n",
      "epoch: 127 \t loss: -929.903 \t return: -854.000 \t ep_len: 854.500\n",
      "epoch: 128 \t loss: -863.579 \t return: -749.571 \t ep_len: 750.286\n",
      "epoch: 129 \t loss: -876.666 \t return: -626.250 \t ep_len: 626.875\n",
      "epoch: 130 \t loss: -908.959 \t return: -683.750 \t ep_len: 684.250\n",
      "epoch: 131 \t loss: -874.297 \t return: -742.500 \t ep_len: 743.250\n",
      "epoch: 132 \t loss: -910.534 \t return: -784.857 \t ep_len: 785.429\n",
      "epoch: 133 \t loss: -936.614 \t return: -849.857 \t ep_len: 850.286\n",
      "epoch: 134 \t loss: -785.539 \t return: -651.125 \t ep_len: 652.000\n",
      "epoch: 135 \t loss: -726.679 \t return: -603.000 \t ep_len: 603.889\n",
      "epoch: 136 \t loss: -948.839 \t return: -906.500 \t ep_len: 907.000\n",
      "epoch: 137 \t loss: -926.585 \t return: -746.875 \t ep_len: 747.250\n",
      "epoch: 138 \t loss: -940.795 \t return: -824.000 \t ep_len: 824.571\n",
      "epoch: 139 \t loss: -982.144 \t return: -852.000 \t ep_len: 852.333\n",
      "epoch: 140 \t loss: -834.855 \t return: -661.125 \t ep_len: 661.875\n",
      "epoch: 141 \t loss: -941.002 \t return: -820.714 \t ep_len: 821.143\n",
      "epoch: 142 \t loss: -818.697 \t return: -730.625 \t ep_len: 731.250\n",
      "epoch: 143 \t loss: -929.003 \t return: -727.714 \t ep_len: 728.143\n",
      "epoch: 144 \t loss: -929.678 \t return: -871.500 \t ep_len: 871.833\n",
      "epoch: 145 \t loss: -902.106 \t return: -730.143 \t ep_len: 730.571\n",
      "epoch: 146 \t loss: -820.666 \t return: -699.250 \t ep_len: 700.000\n",
      "epoch: 147 \t loss: -924.570 \t return: -910.167 \t ep_len: 910.500\n",
      "epoch: 148 \t loss: -995.793 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 149 \t loss: -870.571 \t return: -758.571 \t ep_len: 759.000\n",
      "epoch: 150 \t loss: -778.582 \t return: -655.500 \t ep_len: 656.250\n",
      "epoch: 151 \t loss: -843.483 \t return: -773.429 \t ep_len: 774.000\n",
      "epoch: 152 \t loss: -841.729 \t return: -641.444 \t ep_len: 642.000\n",
      "epoch: 153 \t loss: -888.744 \t return: -856.286 \t ep_len: 856.714\n",
      "epoch: 154 \t loss: -953.979 \t return: -876.000 \t ep_len: 876.167\n",
      "epoch: 155 \t loss: -869.859 \t return: -842.333 \t ep_len: 842.833\n",
      "epoch: 156 \t loss: -825.935 \t return: -740.571 \t ep_len: 741.143\n",
      "epoch: 157 \t loss: -679.929 \t return: -563.556 \t ep_len: 564.333\n",
      "epoch: 158 \t loss: -851.738 \t return: -761.714 \t ep_len: 762.286\n",
      "epoch: 159 \t loss: -891.741 \t return: -730.250 \t ep_len: 730.625\n",
      "epoch: 160 \t loss: -941.483 \t return: -798.000 \t ep_len: 798.286\n",
      "epoch: 161 \t loss: -804.304 \t return: -701.125 \t ep_len: 701.750\n",
      "epoch: 162 \t loss: -1021.090 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 163 \t loss: -852.739 \t return: -786.286 \t ep_len: 786.857\n",
      "epoch: 164 \t loss: -882.501 \t return: -749.571 \t ep_len: 750.143\n",
      "epoch: 165 \t loss: -1026.011 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 166 \t loss: -965.848 \t return: -884.333 \t ep_len: 884.833\n",
      "epoch: 167 \t loss: -978.596 \t return: -928.833 \t ep_len: 929.167\n",
      "epoch: 168 \t loss: -1027.109 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 169 \t loss: -875.199 \t return: -635.500 \t ep_len: 636.000\n",
      "epoch: 170 \t loss: -934.180 \t return: -795.286 \t ep_len: 795.714\n",
      "epoch: 171 \t loss: -868.455 \t return: -712.625 \t ep_len: 713.125\n",
      "epoch: 172 \t loss: -877.227 \t return: -683.125 \t ep_len: 683.750\n",
      "epoch: 173 \t loss: -942.164 \t return: -874.333 \t ep_len: 874.667\n",
      "epoch: 174 \t loss: -1002.683 \t return: -972.833 \t ep_len: 973.000\n",
      "epoch: 175 \t loss: -930.136 \t return: -871.000 \t ep_len: 871.500\n",
      "epoch: 176 \t loss: -875.900 \t return: -745.857 \t ep_len: 746.429\n",
      "epoch: 177 \t loss: -896.088 \t return: -729.714 \t ep_len: 730.143\n",
      "epoch: 178 \t loss: -889.852 \t return: -693.250 \t ep_len: 693.875\n",
      "epoch: 179 \t loss: -944.379 \t return: -811.000 \t ep_len: 811.429\n",
      "epoch: 180 \t loss: -1021.762 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 181 \t loss: -859.881 \t return: -699.250 \t ep_len: 699.750\n",
      "epoch: 182 \t loss: -978.887 \t return: -846.000 \t ep_len: 846.333\n",
      "epoch: 183 \t loss: -999.555 \t return: -909.167 \t ep_len: 909.333\n",
      "epoch: 184 \t loss: -954.736 \t return: -871.333 \t ep_len: 871.667\n",
      "epoch: 185 \t loss: -964.077 \t return: -813.714 \t ep_len: 814.000\n",
      "epoch: 186 \t loss: -861.031 \t return: -650.750 \t ep_len: 651.375\n",
      "epoch: 187 \t loss: -1008.202 \t return: -945.000 \t ep_len: 945.167\n",
      "epoch: 188 \t loss: -941.889 \t return: -853.500 \t ep_len: 854.000\n",
      "epoch: 189 \t loss: -949.777 \t return: -836.667 \t ep_len: 837.000\n",
      "epoch: 190 \t loss: -1037.675 \t return: -991.667 \t ep_len: 991.833\n",
      "epoch: 191 \t loss: -1004.073 \t return: -891.000 \t ep_len: 891.333\n",
      "epoch: 192 \t loss: -995.325 \t return: -820.857 \t ep_len: 821.143\n",
      "epoch: 193 \t loss: -914.735 \t return: -745.375 \t ep_len: 745.875\n",
      "epoch: 194 \t loss: -789.557 \t return: -620.889 \t ep_len: 621.667\n",
      "epoch: 195 \t loss: -889.300 \t return: -715.875 \t ep_len: 716.500\n",
      "epoch: 196 \t loss: -1009.991 \t return: -914.667 \t ep_len: 915.000\n",
      "epoch: 197 \t loss: -789.779 \t return: -661.125 \t ep_len: 661.875\n",
      "epoch: 198 \t loss: -1035.298 \t return: -953.500 \t ep_len: 953.667\n",
      "epoch: 199 \t loss: -976.523 \t return: -848.833 \t ep_len: 849.167\n",
      "epoch: 200 \t loss: -915.713 \t return: -734.429 \t ep_len: 735.000\n",
      "epoch: 201 \t loss: -992.667 \t return: -842.667 \t ep_len: 843.000\n",
      "epoch: 202 \t loss: -1016.867 \t return: -917.333 \t ep_len: 917.833\n",
      "epoch: 203 \t loss: -997.659 \t return: -894.000 \t ep_len: 894.333\n",
      "epoch: 204 \t loss: -1009.429 \t return: -868.333 \t ep_len: 868.667\n",
      "epoch: 205 \t loss: -935.433 \t return: -716.429 \t ep_len: 717.000\n",
      "epoch: 206 \t loss: -931.302 \t return: -803.286 \t ep_len: 804.000\n",
      "epoch: 207 \t loss: -1029.856 \t return: -929.333 \t ep_len: 929.667\n",
      "epoch: 208 \t loss: -1028.863 \t return: -884.833 \t ep_len: 885.167\n",
      "epoch: 209 \t loss: -946.657 \t return: -775.571 \t ep_len: 776.000\n",
      "epoch: 210 \t loss: -990.147 \t return: -903.333 \t ep_len: 903.833\n",
      "epoch: 211 \t loss: -1049.461 \t return: -966.000 \t ep_len: 966.333\n",
      "epoch: 212 \t loss: -996.410 \t return: -849.667 \t ep_len: 850.000\n",
      "epoch: 213 \t loss: -977.567 \t return: -797.143 \t ep_len: 797.571\n",
      "epoch: 214 \t loss: -774.979 \t return: -635.125 \t ep_len: 635.875\n",
      "epoch: 215 \t loss: -1052.902 \t return: -973.000 \t ep_len: 973.167\n",
      "epoch: 216 \t loss: -906.677 \t return: -719.857 \t ep_len: 720.429\n",
      "epoch: 217 \t loss: -1036.526 \t return: -951.667 \t ep_len: 952.000\n",
      "epoch: 218 \t loss: -982.098 \t return: -828.714 \t ep_len: 829.143\n",
      "epoch: 219 \t loss: -930.711 \t return: -806.143 \t ep_len: 806.857\n",
      "epoch: 220 \t loss: -938.898 \t return: -791.286 \t ep_len: 791.714\n",
      "epoch: 221 \t loss: -1041.346 \t return: -954.833 \t ep_len: 955.167\n",
      "epoch: 222 \t loss: -897.322 \t return: -808.429 \t ep_len: 809.143\n",
      "epoch: 223 \t loss: -991.182 \t return: -842.429 \t ep_len: 842.857\n",
      "epoch: 224 \t loss: -931.669 \t return: -753.857 \t ep_len: 754.286\n",
      "epoch: 225 \t loss: -1033.247 \t return: -882.333 \t ep_len: 882.500\n",
      "epoch: 226 \t loss: -910.266 \t return: -707.500 \t ep_len: 708.125\n",
      "epoch: 227 \t loss: -1060.748 \t return: -982.667 \t ep_len: 982.833\n",
      "epoch: 228 \t loss: -808.388 \t return: -613.556 \t ep_len: 614.222\n",
      "epoch: 229 \t loss: -845.048 \t return: -625.500 \t ep_len: 626.125\n",
      "epoch: 230 \t loss: -803.909 \t return: -669.625 \t ep_len: 670.375\n",
      "epoch: 231 \t loss: -926.520 \t return: -801.000 \t ep_len: 801.429\n",
      "epoch: 232 \t loss: -792.883 \t return: -601.111 \t ep_len: 601.778\n",
      "epoch: 233 \t loss: -816.221 \t return: -713.500 \t ep_len: 714.375\n",
      "epoch: 234 \t loss: -1023.314 \t return: -958.167 \t ep_len: 958.333\n",
      "epoch: 235 \t loss: -887.391 \t return: -735.857 \t ep_len: 736.571\n",
      "epoch: 236 \t loss: -866.643 \t return: -696.000 \t ep_len: 696.750\n",
      "epoch: 237 \t loss: -909.511 \t return: -825.857 \t ep_len: 826.429\n",
      "epoch: 238 \t loss: -934.242 \t return: -714.286 \t ep_len: 714.714\n",
      "epoch: 239 \t loss: -1009.358 \t return: -896.333 \t ep_len: 896.500\n",
      "epoch: 240 \t loss: -917.599 \t return: -822.143 \t ep_len: 822.857\n",
      "epoch: 241 \t loss: -900.775 \t return: -746.250 \t ep_len: 747.000\n",
      "epoch: 242 \t loss: -877.071 \t return: -719.250 \t ep_len: 720.000\n",
      "epoch: 243 \t loss: -800.632 \t return: -661.250 \t ep_len: 662.000\n",
      "epoch: 244 \t loss: -856.181 \t return: -740.000 \t ep_len: 740.571\n",
      "epoch: 245 \t loss: -713.787 \t return: -622.111 \t ep_len: 623.000\n",
      "epoch: 246 \t loss: -855.619 \t return: -655.500 \t ep_len: 656.125\n",
      "epoch: 247 \t loss: -836.762 \t return: -518.300 \t ep_len: 518.900\n",
      "epoch: 248 \t loss: -781.456 \t return: -637.250 \t ep_len: 638.000\n",
      "epoch: 249 \t loss: -817.754 \t return: -649.222 \t ep_len: 649.778\n",
      "epoch: 250 \t loss: -857.260 \t return: -750.000 \t ep_len: 750.571\n",
      "epoch: 251 \t loss: -823.803 \t return: -732.857 \t ep_len: 733.571\n",
      "epoch: 252 \t loss: -785.412 \t return: -690.750 \t ep_len: 691.375\n",
      "epoch: 253 \t loss: -864.571 \t return: -735.571 \t ep_len: 736.286\n",
      "epoch: 254 \t loss: -727.784 \t return: -581.333 \t ep_len: 582.111\n",
      "epoch: 255 \t loss: -792.661 \t return: -741.571 \t ep_len: 742.143\n",
      "epoch: 256 \t loss: -648.062 \t return: -516.545 \t ep_len: 517.364\n",
      "epoch: 257 \t loss: -737.718 \t return: -595.556 \t ep_len: 596.222\n",
      "epoch: 258 \t loss: -618.335 \t return: -490.727 \t ep_len: 491.545\n",
      "epoch: 259 \t loss: -773.007 \t return: -638.000 \t ep_len: 638.750\n",
      "epoch: 260 \t loss: -728.903 \t return: -626.625 \t ep_len: 627.250\n",
      "epoch: 261 \t loss: -843.464 \t return: -870.333 \t ep_len: 870.667\n",
      "epoch: 262 \t loss: -728.435 \t return: -527.455 \t ep_len: 528.091\n",
      "epoch: 263 \t loss: -811.474 \t return: -837.167 \t ep_len: 837.500\n",
      "epoch: 264 \t loss: -682.643 \t return: -628.625 \t ep_len: 629.250\n",
      "epoch: 265 \t loss: -806.409 \t return: -900.333 \t ep_len: 900.667\n",
      "epoch: 266 \t loss: -779.140 \t return: -848.833 \t ep_len: 849.333\n",
      "epoch: 267 \t loss: -617.034 \t return: -558.556 \t ep_len: 559.444\n",
      "epoch: 268 \t loss: -634.369 \t return: -557.333 \t ep_len: 558.111\n",
      "epoch: 269 \t loss: -794.162 \t return: -747.571 \t ep_len: 748.143\n",
      "epoch: 270 \t loss: -535.543 \t return: -455.273 \t ep_len: 456.182\n",
      "epoch: 271 \t loss: -675.657 \t return: -680.500 \t ep_len: 681.125\n",
      "epoch: 272 \t loss: -676.752 \t return: -712.625 \t ep_len: 713.375\n",
      "epoch: 273 \t loss: -705.453 \t return: -627.625 \t ep_len: 628.250\n",
      "epoch: 274 \t loss: -662.914 \t return: -657.250 \t ep_len: 658.125\n",
      "epoch: 275 \t loss: -706.055 \t return: -736.857 \t ep_len: 737.429\n",
      "epoch: 276 \t loss: -800.863 \t return: -943.333 \t ep_len: 943.667\n",
      "epoch: 277 \t loss: -668.680 \t return: -614.333 \t ep_len: 615.000\n",
      "epoch: 278 \t loss: -736.447 \t return: -780.000 \t ep_len: 780.429\n",
      "epoch: 279 \t loss: -717.329 \t return: -747.429 \t ep_len: 747.857\n",
      "epoch: 280 \t loss: -667.940 \t return: -762.429 \t ep_len: 763.143\n",
      "epoch: 281 \t loss: -639.609 \t return: -759.143 \t ep_len: 759.857\n",
      "epoch: 282 \t loss: -618.490 \t return: -639.889 \t ep_len: 640.556\n",
      "epoch: 283 \t loss: -760.172 \t return: -855.667 \t ep_len: 855.833\n",
      "epoch: 284 \t loss: -623.443 \t return: -636.000 \t ep_len: 636.625\n",
      "epoch: 285 \t loss: -594.224 \t return: -643.500 \t ep_len: 644.125\n",
      "epoch: 286 \t loss: -529.042 \t return: -552.200 \t ep_len: 552.900\n",
      "epoch: 287 \t loss: -622.264 \t return: -659.125 \t ep_len: 659.625\n",
      "epoch: 288 \t loss: -680.936 \t return: -898.667 \t ep_len: 899.167\n",
      "epoch: 289 \t loss: -605.739 \t return: -656.111 \t ep_len: 656.889\n",
      "epoch: 290 \t loss: -603.017 \t return: -683.500 \t ep_len: 684.125\n",
      "epoch: 291 \t loss: -507.759 \t return: -566.222 \t ep_len: 567.000\n",
      "epoch: 292 \t loss: -629.186 \t return: -869.167 \t ep_len: 869.500\n",
      "epoch: 293 \t loss: -534.785 \t return: -581.800 \t ep_len: 582.500\n",
      "epoch: 294 \t loss: -501.613 \t return: -588.111 \t ep_len: 588.889\n",
      "epoch: 295 \t loss: -622.182 \t return: -840.000 \t ep_len: 840.500\n",
      "epoch: 296 \t loss: -556.148 \t return: -785.286 \t ep_len: 785.857\n",
      "epoch: 297 \t loss: -585.485 \t return: -849.500 \t ep_len: 850.000\n",
      "epoch: 298 \t loss: -488.375 \t return: -734.375 \t ep_len: 734.875\n",
      "epoch: 299 \t loss: -468.798 \t return: -671.625 \t ep_len: 672.250\n",
      "epoch: 300 \t loss: -459.420 \t return: -864.500 \t ep_len: 865.167\n",
      "epoch: 301 \t loss: -423.485 \t return: -783.857 \t ep_len: 784.429\n",
      "epoch: 302 \t loss: -432.144 \t return: -744.143 \t ep_len: 744.714\n",
      "epoch: 303 \t loss: -436.070 \t return: -845.167 \t ep_len: 845.500\n",
      "epoch: 304 \t loss: -386.278 \t return: -726.250 \t ep_len: 726.875\n",
      "epoch: 305 \t loss: -339.162 \t return: -657.625 \t ep_len: 658.375\n",
      "epoch: 306 \t loss: -395.542 \t return: -747.750 \t ep_len: 748.250\n",
      "epoch: 307 \t loss: -380.768 \t return: -801.714 \t ep_len: 802.143\n",
      "epoch: 308 \t loss: -346.781 \t return: -627.222 \t ep_len: 627.778\n",
      "epoch: 309 \t loss: -334.119 \t return: -759.000 \t ep_len: 759.429\n",
      "epoch: 310 \t loss: -300.158 \t return: -725.714 \t ep_len: 726.286\n",
      "epoch: 311 \t loss: -242.908 \t return: -592.800 \t ep_len: 593.500\n",
      "epoch: 312 \t loss: -305.708 \t return: -851.500 \t ep_len: 851.833\n",
      "epoch: 313 \t loss: -281.325 \t return: -737.857 \t ep_len: 738.429\n",
      "epoch: 314 \t loss: -305.692 \t return: -914.667 \t ep_len: 915.000\n",
      "epoch: 315 \t loss: -318.693 \t return: -996.667 \t ep_len: 996.833\n",
      "epoch: 316 \t loss: -306.175 \t return: -905.333 \t ep_len: 905.500\n",
      "epoch: 317 \t loss: -294.072 \t return: -937.667 \t ep_len: 938.000\n",
      "epoch: 318 \t loss: -287.670 \t return: -920.667 \t ep_len: 920.833\n",
      "epoch: 319 \t loss: -288.017 \t return: -829.857 \t ep_len: 830.143\n",
      "epoch: 320 \t loss: -255.493 \t return: -739.857 \t ep_len: 740.429\n",
      "epoch: 321 \t loss: -297.433 \t return: -957.333 \t ep_len: 957.500\n",
      "epoch: 322 \t loss: -298.584 \t return: -983.500 \t ep_len: 983.667\n",
      "epoch: 323 \t loss: -304.693 \t return: -872.500 \t ep_len: 872.667\n",
      "epoch: 324 \t loss: -306.087 \t return: -825.000 \t ep_len: 825.286\n",
      "epoch: 325 \t loss: -327.165 \t return: -785.429 \t ep_len: 785.714\n",
      "epoch: 326 \t loss: -291.055 \t return: -653.444 \t ep_len: 654.111\n",
      "epoch: 327 \t loss: -323.390 \t return: -698.000 \t ep_len: 698.625\n",
      "epoch: 328 \t loss: -346.958 \t return: -676.250 \t ep_len: 677.000\n",
      "epoch: 329 \t loss: -376.459 \t return: -723.429 \t ep_len: 724.000\n",
      "epoch: 330 \t loss: -341.314 \t return: -502.000 \t ep_len: 502.700\n",
      "epoch: 331 \t loss: -433.711 \t return: -692.000 \t ep_len: 692.500\n",
      "epoch: 332 \t loss: -458.508 \t return: -709.500 \t ep_len: 710.125\n",
      "epoch: 333 \t loss: -481.445 \t return: -694.250 \t ep_len: 694.875\n",
      "epoch: 334 \t loss: -426.496 \t return: -645.750 \t ep_len: 646.500\n",
      "epoch: 335 \t loss: -505.990 \t return: -715.429 \t ep_len: 715.857\n",
      "epoch: 336 \t loss: -519.537 \t return: -724.714 \t ep_len: 725.429\n",
      "epoch: 337 \t loss: -447.132 \t return: -570.800 \t ep_len: 571.500\n",
      "epoch: 338 \t loss: -491.199 \t return: -681.125 \t ep_len: 681.750\n",
      "epoch: 339 \t loss: -422.883 \t return: -524.400 \t ep_len: 525.200\n",
      "epoch: 340 \t loss: -528.640 \t return: -651.000 \t ep_len: 651.625\n",
      "epoch: 341 \t loss: -390.624 \t return: -451.083 \t ep_len: 452.083\n",
      "epoch: 342 \t loss: -545.301 \t return: -634.000 \t ep_len: 634.556\n",
      "epoch: 343 \t loss: -573.548 \t return: -813.571 \t ep_len: 813.857\n",
      "epoch: 344 \t loss: -462.761 \t return: -590.444 \t ep_len: 591.333\n",
      "epoch: 345 \t loss: -461.293 \t return: -568.667 \t ep_len: 569.444\n",
      "epoch: 346 \t loss: -520.877 \t return: -616.000 \t ep_len: 616.667\n",
      "epoch: 347 \t loss: -419.526 \t return: -455.917 \t ep_len: 456.750\n",
      "epoch: 348 \t loss: -604.922 \t return: -752.143 \t ep_len: 752.571\n",
      "epoch: 349 \t loss: -620.774 \t return: -837.667 \t ep_len: 838.167\n",
      "epoch: 350 \t loss: -540.796 \t return: -652.889 \t ep_len: 653.556\n",
      "epoch: 351 \t loss: -556.948 \t return: -674.125 \t ep_len: 674.875\n",
      "epoch: 352 \t loss: -503.345 \t return: -646.750 \t ep_len: 647.625\n",
      "epoch: 353 \t loss: -546.861 \t return: -646.444 \t ep_len: 647.222\n",
      "epoch: 354 \t loss: -531.199 \t return: -640.750 \t ep_len: 641.500\n",
      "epoch: 355 \t loss: -571.089 \t return: -785.429 \t ep_len: 786.143\n",
      "epoch: 356 \t loss: -556.897 \t return: -640.125 \t ep_len: 640.750\n",
      "epoch: 357 \t loss: -548.056 \t return: -638.500 \t ep_len: 639.250\n",
      "epoch: 358 \t loss: -672.333 \t return: -871.833 \t ep_len: 872.167\n",
      "epoch: 359 \t loss: -612.101 \t return: -766.429 \t ep_len: 766.857\n",
      "epoch: 360 \t loss: -558.465 \t return: -627.625 \t ep_len: 628.375\n",
      "epoch: 361 \t loss: -573.063 \t return: -641.500 \t ep_len: 642.125\n",
      "epoch: 362 \t loss: -512.714 \t return: -574.889 \t ep_len: 575.667\n",
      "epoch: 363 \t loss: -655.768 \t return: -920.167 \t ep_len: 920.667\n",
      "epoch: 364 \t loss: -528.518 \t return: -571.556 \t ep_len: 572.222\n",
      "epoch: 365 \t loss: -650.751 \t return: -846.833 \t ep_len: 847.167\n",
      "epoch: 366 \t loss: -677.447 \t return: -857.500 \t ep_len: 857.833\n",
      "epoch: 367 \t loss: -637.853 \t return: -849.333 \t ep_len: 849.667\n",
      "epoch: 368 \t loss: -559.804 \t return: -649.222 \t ep_len: 649.889\n",
      "epoch: 369 \t loss: -603.485 \t return: -691.875 \t ep_len: 692.375\n",
      "epoch: 370 \t loss: -670.968 \t return: -935.500 \t ep_len: 935.833\n",
      "epoch: 371 \t loss: -591.441 \t return: -837.857 \t ep_len: 838.571\n",
      "epoch: 372 \t loss: -597.433 \t return: -845.833 \t ep_len: 846.167\n",
      "epoch: 373 \t loss: -591.284 \t return: -840.714 \t ep_len: 841.000\n",
      "epoch: 374 \t loss: -604.580 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 375 \t loss: -539.640 \t return: -953.500 \t ep_len: 953.667\n",
      "epoch: 376 \t loss: -536.499 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 377 \t loss: -430.620 \t return: -834.714 \t ep_len: 835.143\n",
      "epoch: 378 \t loss: -457.173 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 379 \t loss: -432.112 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 380 \t loss: -425.283 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 381 \t loss: -361.591 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 382 \t loss: -330.054 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 383 \t loss: -316.876 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 384 \t loss: -294.117 \t return: -987.667 \t ep_len: 987.833\n",
      "epoch: 385 \t loss: -277.364 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 386 \t loss: -269.629 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 387 \t loss: -255.693 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 388 \t loss: -220.227 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 389 \t loss: -205.126 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 390 \t loss: -180.295 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 391 \t loss: -179.542 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 392 \t loss: -138.731 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 393 \t loss: -129.201 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 394 \t loss: -136.939 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 395 \t loss: -111.697 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 396 \t loss: -104.943 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 397 \t loss: -86.780 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 398 \t loss: -94.274 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 399 \t loss: -101.970 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 400 \t loss: -114.359 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 401 \t loss: -106.614 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 402 \t loss: -103.632 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 403 \t loss: -121.146 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 404 \t loss: -105.099 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 405 \t loss: -104.440 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 406 \t loss: -108.552 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 407 \t loss: -101.022 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 408 \t loss: -117.347 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 409 \t loss: -105.137 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 410 \t loss: -104.147 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 411 \t loss: -99.855 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 412 \t loss: -93.653 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 413 \t loss: -76.185 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 414 \t loss: -97.008 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 415 \t loss: -88.363 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 416 \t loss: -78.137 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 417 \t loss: -76.957 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 418 \t loss: -93.012 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 419 \t loss: -85.016 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 420 \t loss: -84.674 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 421 \t loss: -98.887 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 422 \t loss: -98.542 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 423 \t loss: -87.532 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 424 \t loss: -84.481 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 425 \t loss: -82.128 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 426 \t loss: -100.183 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 427 \t loss: -95.480 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 428 \t loss: -97.870 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 429 \t loss: -96.817 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 430 \t loss: -109.764 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 431 \t loss: -135.618 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 432 \t loss: -119.514 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 433 \t loss: -114.522 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 434 \t loss: -122.015 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 435 \t loss: -97.928 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 436 \t loss: -95.834 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 437 \t loss: -114.355 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 438 \t loss: -105.035 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 439 \t loss: -101.351 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 440 \t loss: -125.292 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 441 \t loss: -111.877 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 442 \t loss: -121.649 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 443 \t loss: -112.654 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 444 \t loss: -91.287 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 445 \t loss: -79.716 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 446 \t loss: -83.273 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 447 \t loss: -90.558 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 448 \t loss: -101.092 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 449 \t loss: -79.599 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 450 \t loss: -86.501 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 451 \t loss: -64.273 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 452 \t loss: -85.544 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 453 \t loss: -93.738 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 454 \t loss: -89.689 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 455 \t loss: -72.908 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 456 \t loss: -66.967 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 457 \t loss: -67.949 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 458 \t loss: -70.295 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 459 \t loss: -69.282 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 460 \t loss: -55.060 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 461 \t loss: -35.840 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 462 \t loss: -52.136 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 463 \t loss: -45.233 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 464 \t loss: -48.269 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 465 \t loss: -51.255 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 466 \t loss: -49.139 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 467 \t loss: -45.005 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 468 \t loss: -47.264 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 469 \t loss: -52.556 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 470 \t loss: -71.431 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 471 \t loss: -44.061 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 472 \t loss: -53.239 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 473 \t loss: -53.294 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 474 \t loss: -43.473 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 475 \t loss: -59.954 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 476 \t loss: -53.274 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 477 \t loss: -55.865 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 478 \t loss: -63.197 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 479 \t loss: -44.521 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 480 \t loss: -50.473 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 481 \t loss: -64.651 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 482 \t loss: -57.516 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 483 \t loss: -57.956 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 484 \t loss: -56.983 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 485 \t loss: -45.951 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 486 \t loss: -48.425 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 487 \t loss: -54.941 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 488 \t loss: -35.835 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 489 \t loss: -40.680 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 490 \t loss: -39.399 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 491 \t loss: -50.214 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 492 \t loss: -51.602 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 493 \t loss: -59.548 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 494 \t loss: -50.492 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 495 \t loss: -59.696 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 496 \t loss: -56.785 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 497 \t loss: -53.839 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 498 \t loss: -39.412 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 499 \t loss: -48.254 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 500 \t loss: -42.647 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 501 \t loss: -39.886 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 502 \t loss: -43.508 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 503 \t loss: -41.953 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 504 \t loss: -53.902 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 505 \t loss: -53.143 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 506 \t loss: -50.611 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 507 \t loss: -51.675 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 508 \t loss: -51.353 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 509 \t loss: -50.640 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 510 \t loss: -58.796 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 511 \t loss: -49.262 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 512 \t loss: -53.779 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 513 \t loss: -64.521 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 514 \t loss: -62.872 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 515 \t loss: -65.254 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 516 \t loss: -68.302 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 517 \t loss: -62.702 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 518 \t loss: -78.932 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 519 \t loss: -77.304 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 520 \t loss: -74.215 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 521 \t loss: -82.521 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 522 \t loss: -75.945 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 523 \t loss: -78.198 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 524 \t loss: -67.471 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 525 \t loss: -63.239 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 526 \t loss: -84.460 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 527 \t loss: -70.911 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 528 \t loss: -68.562 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 529 \t loss: -82.096 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 530 \t loss: -64.896 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 531 \t loss: -80.328 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 532 \t loss: -78.241 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 533 \t loss: -74.266 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 534 \t loss: -82.754 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 535 \t loss: -84.111 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 536 \t loss: -86.254 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 537 \t loss: -97.322 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 538 \t loss: -139.977 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 539 \t loss: -105.709 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 540 \t loss: -117.378 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 541 \t loss: -134.786 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 542 \t loss: -131.350 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 543 \t loss: -146.222 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 544 \t loss: -143.677 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 545 \t loss: -142.105 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 546 \t loss: -132.763 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 547 \t loss: -134.334 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 548 \t loss: -149.496 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 549 \t loss: -157.788 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 550 \t loss: -159.647 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 551 \t loss: -150.984 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 552 \t loss: -148.492 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 553 \t loss: -134.317 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 554 \t loss: -140.135 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 555 \t loss: -145.919 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 556 \t loss: -138.453 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 557 \t loss: -124.476 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 558 \t loss: -141.764 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 559 \t loss: -153.560 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 560 \t loss: -171.911 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 561 \t loss: -182.819 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 562 \t loss: -152.278 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 563 \t loss: -168.882 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 564 \t loss: -166.213 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 565 \t loss: -182.562 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 566 \t loss: -166.761 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 567 \t loss: -186.377 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 568 \t loss: -185.668 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 569 \t loss: -200.930 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 570 \t loss: -211.470 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 571 \t loss: -218.225 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 572 \t loss: -253.810 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 573 \t loss: -213.341 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 574 \t loss: -245.547 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 575 \t loss: -231.525 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 576 \t loss: -221.419 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 577 \t loss: -200.973 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 578 \t loss: -173.726 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 579 \t loss: -179.731 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 580 \t loss: -184.367 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 581 \t loss: -176.760 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 582 \t loss: -179.607 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 583 \t loss: -188.576 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 584 \t loss: -176.827 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 585 \t loss: -201.629 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 586 \t loss: -188.944 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 587 \t loss: -193.440 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 588 \t loss: -197.467 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 589 \t loss: -189.375 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 590 \t loss: -187.010 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 591 \t loss: -172.050 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 592 \t loss: -163.397 \t return: -950.000 \t ep_len: 950.167\n",
      "epoch: 593 \t loss: -165.356 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 594 \t loss: -181.482 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 595 \t loss: -153.772 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 596 \t loss: -160.818 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 597 \t loss: -158.334 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 598 \t loss: -144.779 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 599 \t loss: -152.587 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 600 \t loss: -143.243 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 601 \t loss: -141.620 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 602 \t loss: -146.532 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 603 \t loss: -150.139 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 604 \t loss: -144.558 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 605 \t loss: -125.322 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 606 \t loss: -119.176 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 607 \t loss: -118.628 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 608 \t loss: -112.225 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 609 \t loss: -108.722 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 610 \t loss: -87.361 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 611 \t loss: -80.963 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 612 \t loss: -77.772 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 613 \t loss: -99.133 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 614 \t loss: -101.776 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 615 \t loss: -108.387 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 616 \t loss: -145.147 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 617 \t loss: -172.452 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 618 \t loss: -169.036 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 619 \t loss: -198.453 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 620 \t loss: -205.898 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 621 \t loss: -225.058 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 622 \t loss: -217.896 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 623 \t loss: -249.078 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 624 \t loss: -254.078 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 625 \t loss: -256.602 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 626 \t loss: -312.002 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 627 \t loss: -336.484 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 628 \t loss: -357.703 \t return: -988.833 \t ep_len: 989.000\n",
      "epoch: 629 \t loss: -367.843 \t return: -907.167 \t ep_len: 907.333\n",
      "epoch: 630 \t loss: -390.307 \t return: -949.167 \t ep_len: 949.500\n",
      "epoch: 631 \t loss: -375.912 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 632 \t loss: -357.877 \t return: -981.333 \t ep_len: 981.500\n",
      "epoch: 633 \t loss: -367.349 \t return: -974.000 \t ep_len: 974.167\n",
      "epoch: 634 \t loss: -372.976 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 635 \t loss: -405.547 \t return: -998.833 \t ep_len: 999.000\n",
      "epoch: 636 \t loss: -411.176 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 637 \t loss: -403.582 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 638 \t loss: -398.022 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 639 \t loss: -377.831 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 640 \t loss: -396.767 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 641 \t loss: -374.174 \t return: -984.333 \t ep_len: 984.500\n",
      "epoch: 642 \t loss: -416.471 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 643 \t loss: -438.135 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 644 \t loss: -438.138 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 645 \t loss: -415.108 \t return: -954.000 \t ep_len: 954.167\n",
      "epoch: 646 \t loss: -404.944 \t return: -996.667 \t ep_len: 996.833\n",
      "epoch: 647 \t loss: -382.506 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 648 \t loss: -358.507 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 649 \t loss: -383.539 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 650 \t loss: -364.476 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 651 \t loss: -329.957 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 652 \t loss: -377.145 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 653 \t loss: -368.975 \t return: -961.500 \t ep_len: 961.667\n",
      "epoch: 654 \t loss: -410.508 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 655 \t loss: -425.806 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 656 \t loss: -466.873 \t return: -990.833 \t ep_len: 991.000\n",
      "epoch: 657 \t loss: -458.549 \t return: -900.667 \t ep_len: 900.833\n",
      "epoch: 658 \t loss: -533.933 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 659 \t loss: -525.388 \t return: -858.667 \t ep_len: 859.000\n",
      "epoch: 660 \t loss: -581.616 \t return: -950.500 \t ep_len: 950.667\n",
      "epoch: 661 \t loss: -626.791 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 662 \t loss: -619.803 \t return: -939.500 \t ep_len: 939.833\n",
      "epoch: 663 \t loss: -639.371 \t return: -908.833 \t ep_len: 909.000\n",
      "epoch: 664 \t loss: -693.833 \t return: -985.333 \t ep_len: 985.500\n",
      "epoch: 665 \t loss: -643.268 \t return: -835.167 \t ep_len: 835.500\n",
      "epoch: 666 \t loss: -620.828 \t return: -728.714 \t ep_len: 729.286\n",
      "epoch: 667 \t loss: -610.470 \t return: -747.750 \t ep_len: 748.250\n",
      "epoch: 668 \t loss: -674.792 \t return: -878.167 \t ep_len: 878.667\n",
      "epoch: 669 \t loss: -713.533 \t return: -918.500 \t ep_len: 918.667\n",
      "epoch: 670 \t loss: -725.148 \t return: -953.000 \t ep_len: 953.167\n",
      "epoch: 671 \t loss: -702.381 \t return: -837.500 \t ep_len: 837.833\n",
      "epoch: 672 \t loss: -609.258 \t return: -722.857 \t ep_len: 723.571\n",
      "epoch: 673 \t loss: -695.977 \t return: -772.429 \t ep_len: 773.000\n",
      "epoch: 674 \t loss: -712.253 \t return: -856.667 \t ep_len: 857.333\n",
      "epoch: 675 \t loss: -754.401 \t return: -908.167 \t ep_len: 908.333\n",
      "epoch: 676 \t loss: -747.473 \t return: -790.429 \t ep_len: 790.857\n",
      "epoch: 677 \t loss: -813.726 \t return: -994.833 \t ep_len: 995.000\n",
      "epoch: 678 \t loss: -736.291 \t return: -832.571 \t ep_len: 833.143\n",
      "epoch: 679 \t loss: -656.035 \t return: -639.250 \t ep_len: 640.000\n",
      "epoch: 680 \t loss: -762.494 \t return: -895.833 \t ep_len: 896.167\n",
      "epoch: 681 \t loss: -730.014 \t return: -757.571 \t ep_len: 758.143\n",
      "epoch: 682 \t loss: -748.087 \t return: -829.286 \t ep_len: 829.857\n",
      "epoch: 683 \t loss: -657.587 \t return: -663.375 \t ep_len: 664.125\n",
      "epoch: 684 \t loss: -752.351 \t return: -748.714 \t ep_len: 749.143\n",
      "epoch: 685 \t loss: -673.863 \t return: -660.875 \t ep_len: 661.500\n",
      "epoch: 686 \t loss: -664.342 \t return: -642.125 \t ep_len: 642.750\n",
      "epoch: 687 \t loss: -705.430 \t return: -722.857 \t ep_len: 723.429\n",
      "epoch: 688 \t loss: -637.586 \t return: -624.875 \t ep_len: 625.500\n",
      "epoch: 689 \t loss: -720.211 \t return: -743.500 \t ep_len: 744.375\n",
      "epoch: 690 \t loss: -744.602 \t return: -784.000 \t ep_len: 784.571\n",
      "epoch: 691 \t loss: -720.774 \t return: -653.875 \t ep_len: 654.500\n",
      "epoch: 692 \t loss: -685.698 \t return: -700.625 \t ep_len: 701.375\n",
      "epoch: 693 \t loss: -695.934 \t return: -673.125 \t ep_len: 673.750\n",
      "epoch: 694 \t loss: -587.690 \t return: -588.667 \t ep_len: 589.556\n",
      "epoch: 695 \t loss: -628.915 \t return: -638.250 \t ep_len: 639.000\n",
      "epoch: 696 \t loss: -739.867 \t return: -837.000 \t ep_len: 837.500\n",
      "epoch: 697 \t loss: -641.830 \t return: -633.875 \t ep_len: 634.625\n",
      "epoch: 698 \t loss: -670.742 \t return: -669.250 \t ep_len: 669.750\n",
      "epoch: 699 \t loss: -691.954 \t return: -784.571 \t ep_len: 785.143\n",
      "epoch: 700 \t loss: -641.612 \t return: -761.000 \t ep_len: 761.571\n",
      "epoch: 701 \t loss: -647.174 \t return: -514.909 \t ep_len: 515.545\n",
      "epoch: 702 \t loss: -687.631 \t return: -804.000 \t ep_len: 804.571\n",
      "epoch: 703 \t loss: -650.578 \t return: -678.000 \t ep_len: 678.625\n",
      "epoch: 704 \t loss: -670.533 \t return: -773.000 \t ep_len: 773.429\n",
      "epoch: 705 \t loss: -599.736 \t return: -722.125 \t ep_len: 722.625\n",
      "epoch: 706 \t loss: -533.369 \t return: -641.625 \t ep_len: 642.500\n",
      "epoch: 707 \t loss: -560.256 \t return: -664.000 \t ep_len: 664.625\n",
      "epoch: 708 \t loss: -512.423 \t return: -648.750 \t ep_len: 649.500\n",
      "epoch: 709 \t loss: -505.788 \t return: -704.125 \t ep_len: 704.625\n",
      "epoch: 710 \t loss: -447.296 \t return: -643.875 \t ep_len: 644.500\n",
      "epoch: 711 \t loss: -354.711 \t return: -549.900 \t ep_len: 550.700\n",
      "epoch: 712 \t loss: -437.037 \t return: -857.833 \t ep_len: 858.333\n",
      "epoch: 713 \t loss: -303.643 \t return: -557.444 \t ep_len: 558.333\n",
      "epoch: 714 \t loss: -385.184 \t return: -761.000 \t ep_len: 761.571\n",
      "epoch: 715 \t loss: -351.352 \t return: -724.143 \t ep_len: 724.714\n",
      "epoch: 716 \t loss: -350.497 \t return: -736.500 \t ep_len: 737.125\n",
      "epoch: 717 \t loss: -343.581 \t return: -645.375 \t ep_len: 646.125\n",
      "epoch: 718 \t loss: -389.158 \t return: -904.333 \t ep_len: 904.667\n",
      "epoch: 719 \t loss: -365.727 \t return: -842.857 \t ep_len: 843.286\n",
      "epoch: 720 \t loss: -347.812 \t return: -841.333 \t ep_len: 841.667\n",
      "epoch: 721 \t loss: -308.988 \t return: -725.000 \t ep_len: 725.375\n",
      "epoch: 722 \t loss: -281.762 \t return: -727.375 \t ep_len: 727.875\n",
      "epoch: 723 \t loss: -308.430 \t return: -841.500 \t ep_len: 841.833\n",
      "epoch: 724 \t loss: -278.776 \t return: -761.000 \t ep_len: 761.429\n",
      "epoch: 725 \t loss: -239.795 \t return: -638.000 \t ep_len: 638.500\n",
      "epoch: 726 \t loss: -265.588 \t return: -854.714 \t ep_len: 855.000\n",
      "epoch: 727 \t loss: -293.562 \t return: -975.000 \t ep_len: 975.333\n",
      "epoch: 728 \t loss: -263.970 \t return: -766.000 \t ep_len: 766.429\n",
      "epoch: 729 \t loss: -254.880 \t return: -836.833 \t ep_len: 837.167\n",
      "epoch: 730 \t loss: -247.161 \t return: -932.833 \t ep_len: 933.000\n",
      "epoch: 731 \t loss: -214.827 \t return: -879.000 \t ep_len: 879.333\n",
      "epoch: 732 \t loss: -205.922 \t return: -718.000 \t ep_len: 718.625\n",
      "epoch: 733 \t loss: -248.753 \t return: -944.667 \t ep_len: 944.833\n",
      "epoch: 734 \t loss: -221.917 \t return: -719.250 \t ep_len: 719.875\n",
      "epoch: 735 \t loss: -240.002 \t return: -749.125 \t ep_len: 749.625\n",
      "epoch: 736 \t loss: -227.829 \t return: -813.571 \t ep_len: 813.857\n",
      "epoch: 737 \t loss: -204.293 \t return: -573.556 \t ep_len: 574.222\n",
      "epoch: 738 \t loss: -218.272 \t return: -676.375 \t ep_len: 676.875\n",
      "epoch: 739 \t loss: -264.117 \t return: -779.143 \t ep_len: 779.571\n",
      "epoch: 740 \t loss: -262.657 \t return: -606.444 \t ep_len: 607.111\n",
      "epoch: 741 \t loss: -246.914 \t return: -617.889 \t ep_len: 618.667\n",
      "epoch: 742 \t loss: -204.145 \t return: -518.000 \t ep_len: 518.900\n",
      "epoch: 743 \t loss: -260.692 \t return: -501.000 \t ep_len: 501.900\n",
      "epoch: 744 \t loss: -341.022 \t return: -643.500 \t ep_len: 644.125\n",
      "epoch: 745 \t loss: -404.791 \t return: -770.286 \t ep_len: 770.857\n",
      "epoch: 746 \t loss: -446.458 \t return: -663.111 \t ep_len: 663.556\n",
      "epoch: 747 \t loss: -372.348 \t return: -578.000 \t ep_len: 578.800\n",
      "epoch: 748 \t loss: -406.219 \t return: -631.111 \t ep_len: 631.667\n",
      "epoch: 749 \t loss: -339.310 \t return: -612.000 \t ep_len: 612.667\n",
      "epoch: 750 \t loss: -405.145 \t return: -759.571 \t ep_len: 760.000\n",
      "epoch: 751 \t loss: -283.997 \t return: -574.667 \t ep_len: 575.444\n",
      "epoch: 752 \t loss: -312.663 \t return: -733.500 \t ep_len: 734.125\n",
      "epoch: 753 \t loss: -272.010 \t return: -659.875 \t ep_len: 660.500\n",
      "epoch: 754 \t loss: -305.005 \t return: -602.111 \t ep_len: 602.667\n",
      "epoch: 755 \t loss: -226.887 \t return: -455.000 \t ep_len: 455.909\n",
      "epoch: 756 \t loss: -310.077 \t return: -743.286 \t ep_len: 744.000\n",
      "epoch: 757 \t loss: -343.404 \t return: -731.714 \t ep_len: 732.286\n",
      "epoch: 758 \t loss: -346.571 \t return: -499.600 \t ep_len: 500.500\n",
      "epoch: 759 \t loss: -357.099 \t return: -523.100 \t ep_len: 523.800\n",
      "epoch: 760 \t loss: -454.533 \t return: -641.250 \t ep_len: 641.875\n",
      "epoch: 761 \t loss: -488.264 \t return: -646.500 \t ep_len: 647.125\n",
      "epoch: 762 \t loss: -471.272 \t return: -587.000 \t ep_len: 587.667\n",
      "epoch: 763 \t loss: -346.841 \t return: -421.000 \t ep_len: 422.000\n",
      "epoch: 764 \t loss: -527.424 \t return: -765.286 \t ep_len: 766.000\n",
      "epoch: 765 \t loss: -501.973 \t return: -564.200 \t ep_len: 565.000\n",
      "epoch: 766 \t loss: -586.951 \t return: -811.000 \t ep_len: 811.429\n",
      "epoch: 767 \t loss: -475.782 \t return: -527.600 \t ep_len: 528.400\n",
      "epoch: 768 \t loss: -525.767 \t return: -707.750 \t ep_len: 708.375\n",
      "epoch: 769 \t loss: -575.222 \t return: -850.000 \t ep_len: 850.429\n",
      "epoch: 770 \t loss: -433.179 \t return: -507.727 \t ep_len: 508.636\n",
      "epoch: 771 \t loss: -373.935 \t return: -388.923 \t ep_len: 389.769\n",
      "epoch: 772 \t loss: -512.020 \t return: -762.714 \t ep_len: 763.286\n",
      "epoch: 773 \t loss: -468.490 \t return: -527.182 \t ep_len: 528.000\n",
      "epoch: 774 \t loss: -398.384 \t return: -501.900 \t ep_len: 502.800\n",
      "epoch: 775 \t loss: -440.601 \t return: -510.300 \t ep_len: 511.200\n",
      "epoch: 776 \t loss: -583.818 \t return: -590.300 \t ep_len: 590.800\n",
      "epoch: 777 \t loss: -543.050 \t return: -597.444 \t ep_len: 598.000\n",
      "epoch: 778 \t loss: -544.121 \t return: -564.667 \t ep_len: 565.333\n",
      "epoch: 779 \t loss: -427.940 \t return: -520.100 \t ep_len: 520.900\n",
      "epoch: 780 \t loss: -419.535 \t return: -496.083 \t ep_len: 496.833\n",
      "epoch: 781 \t loss: -365.750 \t return: -441.000 \t ep_len: 441.833\n",
      "epoch: 782 \t loss: -410.326 \t return: -397.077 \t ep_len: 397.846\n",
      "epoch: 783 \t loss: -382.269 \t return: -570.300 \t ep_len: 571.200\n",
      "epoch: 784 \t loss: -374.723 \t return: -388.769 \t ep_len: 389.615\n",
      "epoch: 785 \t loss: -325.908 \t return: -341.867 \t ep_len: 342.800\n",
      "epoch: 786 \t loss: -396.342 \t return: -419.833 \t ep_len: 420.667\n",
      "epoch: 787 \t loss: -406.910 \t return: -416.154 \t ep_len: 417.077\n",
      "epoch: 788 \t loss: -564.265 \t return: -590.667 \t ep_len: 591.444\n",
      "epoch: 789 \t loss: -513.476 \t return: -509.000 \t ep_len: 509.800\n",
      "epoch: 790 \t loss: -465.954 \t return: -420.167 \t ep_len: 421.000\n",
      "epoch: 791 \t loss: -529.145 \t return: -541.100 \t ep_len: 541.900\n",
      "epoch: 792 \t loss: -573.449 \t return: -477.000 \t ep_len: 477.727\n",
      "epoch: 793 \t loss: -638.077 \t return: -565.556 \t ep_len: 566.111\n",
      "epoch: 794 \t loss: -482.185 \t return: -452.692 \t ep_len: 453.615\n",
      "epoch: 795 \t loss: -505.932 \t return: -541.200 \t ep_len: 542.000\n",
      "epoch: 796 \t loss: -539.493 \t return: -531.000 \t ep_len: 531.700\n",
      "epoch: 797 \t loss: -353.473 \t return: -356.125 \t ep_len: 357.062\n",
      "epoch: 798 \t loss: -516.575 \t return: -526.000 \t ep_len: 526.700\n",
      "epoch: 799 \t loss: -389.392 \t return: -482.909 \t ep_len: 483.818\n",
      "epoch: 800 \t loss: -252.350 \t return: -296.765 \t ep_len: 297.706\n",
      "epoch: 801 \t loss: -400.642 \t return: -500.364 \t ep_len: 501.091\n",
      "epoch: 802 \t loss: -470.085 \t return: -681.875 \t ep_len: 682.500\n",
      "epoch: 803 \t loss: -334.086 \t return: -426.538 \t ep_len: 427.462\n",
      "epoch: 804 \t loss: -375.531 \t return: -468.667 \t ep_len: 469.583\n",
      "epoch: 805 \t loss: -357.878 \t return: -391.769 \t ep_len: 392.692\n",
      "epoch: 806 \t loss: -362.022 \t return: -437.417 \t ep_len: 438.333\n",
      "epoch: 807 \t loss: -353.438 \t return: -479.273 \t ep_len: 480.182\n",
      "epoch: 808 \t loss: -411.416 \t return: -510.636 \t ep_len: 511.545\n",
      "epoch: 809 \t loss: -303.491 \t return: -420.750 \t ep_len: 421.750\n",
      "epoch: 810 \t loss: -433.437 \t return: -506.400 \t ep_len: 507.100\n",
      "epoch: 811 \t loss: -385.911 \t return: -467.909 \t ep_len: 468.727\n",
      "epoch: 812 \t loss: -301.218 \t return: -471.091 \t ep_len: 472.000\n",
      "epoch: 813 \t loss: -474.763 \t return: -657.375 \t ep_len: 658.000\n",
      "epoch: 814 \t loss: -410.762 \t return: -513.100 \t ep_len: 513.800\n",
      "epoch: 815 \t loss: -405.172 \t return: -489.636 \t ep_len: 490.364\n",
      "epoch: 816 \t loss: -462.555 \t return: -670.875 \t ep_len: 671.500\n",
      "epoch: 817 \t loss: -322.163 \t return: -467.273 \t ep_len: 468.182\n",
      "epoch: 818 \t loss: -429.393 \t return: -557.700 \t ep_len: 558.500\n",
      "epoch: 819 \t loss: -455.111 \t return: -529.000 \t ep_len: 529.636\n",
      "epoch: 820 \t loss: -465.658 \t return: -733.714 \t ep_len: 734.286\n",
      "epoch: 821 \t loss: -452.735 \t return: -639.250 \t ep_len: 640.000\n",
      "epoch: 822 \t loss: -408.325 \t return: -501.500 \t ep_len: 502.200\n",
      "epoch: 823 \t loss: -512.652 \t return: -647.778 \t ep_len: 648.333\n",
      "epoch: 824 \t loss: -407.766 \t return: -476.273 \t ep_len: 477.091\n",
      "epoch: 825 \t loss: -395.739 \t return: -568.889 \t ep_len: 569.778\n",
      "epoch: 826 \t loss: -497.025 \t return: -706.125 \t ep_len: 706.750\n",
      "epoch: 827 \t loss: -496.482 \t return: -631.111 \t ep_len: 631.889\n",
      "epoch: 828 \t loss: -447.008 \t return: -648.875 \t ep_len: 649.750\n",
      "epoch: 829 \t loss: -483.967 \t return: -635.444 \t ep_len: 636.222\n",
      "epoch: 830 \t loss: -577.781 \t return: -839.667 \t ep_len: 840.167\n",
      "epoch: 831 \t loss: -514.144 \t return: -768.571 \t ep_len: 769.000\n",
      "epoch: 832 \t loss: -416.467 \t return: -548.300 \t ep_len: 549.100\n",
      "epoch: 833 \t loss: -466.956 \t return: -638.500 \t ep_len: 639.125\n",
      "epoch: 834 \t loss: -465.290 \t return: -646.750 \t ep_len: 647.500\n",
      "epoch: 835 \t loss: -418.246 \t return: -522.800 \t ep_len: 523.600\n",
      "epoch: 836 \t loss: -480.218 \t return: -656.125 \t ep_len: 656.750\n",
      "epoch: 837 \t loss: -372.918 \t return: -459.000 \t ep_len: 459.917\n",
      "epoch: 838 \t loss: -420.643 \t return: -455.923 \t ep_len: 456.692\n",
      "epoch: 839 \t loss: -350.224 \t return: -465.364 \t ep_len: 466.273\n",
      "epoch: 840 \t loss: -481.433 \t return: -741.125 \t ep_len: 741.625\n",
      "epoch: 841 \t loss: -429.988 \t return: -468.545 \t ep_len: 469.273\n",
      "epoch: 842 \t loss: -473.579 \t return: -593.889 \t ep_len: 594.556\n",
      "epoch: 843 \t loss: -387.637 \t return: -383.692 \t ep_len: 384.692\n",
      "epoch: 844 \t loss: -390.440 \t return: -404.231 \t ep_len: 405.077\n",
      "epoch: 845 \t loss: -449.126 \t return: -461.727 \t ep_len: 462.545\n",
      "epoch: 846 \t loss: -476.421 \t return: -567.778 \t ep_len: 568.556\n",
      "epoch: 847 \t loss: -376.685 \t return: -361.667 \t ep_len: 362.600\n",
      "epoch: 848 \t loss: -507.755 \t return: -595.667 \t ep_len: 596.333\n",
      "epoch: 849 \t loss: -569.613 \t return: -556.778 \t ep_len: 557.333\n",
      "epoch: 850 \t loss: -442.315 \t return: -515.182 \t ep_len: 516.091\n",
      "epoch: 851 \t loss: -520.123 \t return: -676.000 \t ep_len: 676.750\n",
      "epoch: 852 \t loss: -460.912 \t return: -626.750 \t ep_len: 627.625\n",
      "epoch: 853 \t loss: -439.177 \t return: -576.778 \t ep_len: 577.667\n",
      "epoch: 854 \t loss: -504.964 \t return: -516.455 \t ep_len: 517.273\n",
      "epoch: 855 \t loss: -508.882 \t return: -544.000 \t ep_len: 544.700\n",
      "epoch: 856 \t loss: -437.585 \t return: -405.769 \t ep_len: 406.692\n",
      "epoch: 857 \t loss: -536.093 \t return: -654.875 \t ep_len: 655.375\n",
      "epoch: 858 \t loss: -409.227 \t return: -420.385 \t ep_len: 421.231\n",
      "epoch: 859 \t loss: -452.978 \t return: -520.100 \t ep_len: 520.900\n",
      "epoch: 860 \t loss: -527.752 \t return: -876.000 \t ep_len: 876.500\n",
      "epoch: 861 \t loss: -516.702 \t return: -767.143 \t ep_len: 767.571\n",
      "epoch: 862 \t loss: -375.610 \t return: -470.636 \t ep_len: 471.455\n",
      "epoch: 863 \t loss: -390.160 \t return: -627.125 \t ep_len: 628.000\n",
      "epoch: 864 \t loss: -373.628 \t return: -402.308 \t ep_len: 403.154\n",
      "epoch: 865 \t loss: -387.113 \t return: -514.600 \t ep_len: 515.400\n",
      "epoch: 866 \t loss: -393.808 \t return: -476.818 \t ep_len: 477.818\n",
      "epoch: 867 \t loss: -288.786 \t return: -375.400 \t ep_len: 376.400\n",
      "epoch: 868 \t loss: -350.557 \t return: -632.375 \t ep_len: 633.250\n",
      "epoch: 869 \t loss: -431.427 \t return: -666.250 \t ep_len: 666.750\n",
      "epoch: 870 \t loss: -331.502 \t return: -532.200 \t ep_len: 532.900\n",
      "epoch: 871 \t loss: -297.774 \t return: -560.111 \t ep_len: 560.889\n",
      "epoch: 872 \t loss: -350.555 \t return: -584.556 \t ep_len: 585.222\n",
      "epoch: 873 \t loss: -351.753 \t return: -661.375 \t ep_len: 662.000\n",
      "epoch: 874 \t loss: -287.654 \t return: -519.200 \t ep_len: 520.000\n",
      "epoch: 875 \t loss: -313.475 \t return: -576.600 \t ep_len: 577.200\n",
      "epoch: 876 \t loss: -229.786 \t return: -507.400 \t ep_len: 508.200\n",
      "epoch: 877 \t loss: -258.088 \t return: -625.875 \t ep_len: 626.500\n",
      "epoch: 878 \t loss: -286.837 \t return: -685.875 \t ep_len: 686.500\n",
      "epoch: 879 \t loss: -300.766 \t return: -812.286 \t ep_len: 812.857\n",
      "epoch: 880 \t loss: -270.444 \t return: -768.429 \t ep_len: 768.857\n",
      "epoch: 881 \t loss: -240.292 \t return: -744.000 \t ep_len: 744.429\n",
      "epoch: 882 \t loss: -164.275 \t return: -389.231 \t ep_len: 390.077\n",
      "epoch: 883 \t loss: -233.272 \t return: -849.857 \t ep_len: 850.286\n",
      "epoch: 884 \t loss: -227.188 \t return: -654.000 \t ep_len: 654.500\n",
      "epoch: 885 \t loss: -194.680 \t return: -646.375 \t ep_len: 647.000\n",
      "epoch: 886 \t loss: -225.785 \t return: -726.714 \t ep_len: 727.286\n",
      "epoch: 887 \t loss: -209.650 \t return: -732.857 \t ep_len: 733.429\n",
      "epoch: 888 \t loss: -231.737 \t return: -731.125 \t ep_len: 731.500\n",
      "epoch: 889 \t loss: -194.096 \t return: -550.200 \t ep_len: 551.000\n",
      "epoch: 890 \t loss: -180.316 \t return: -584.778 \t ep_len: 585.667\n",
      "epoch: 891 \t loss: -221.996 \t return: -721.375 \t ep_len: 722.000\n",
      "epoch: 892 \t loss: -220.996 \t return: -733.714 \t ep_len: 734.286\n",
      "epoch: 893 \t loss: -233.627 \t return: -852.571 \t ep_len: 853.000\n",
      "epoch: 894 \t loss: -217.999 \t return: -594.444 \t ep_len: 595.222\n",
      "epoch: 895 \t loss: -208.941 \t return: -670.375 \t ep_len: 670.875\n",
      "epoch: 896 \t loss: -210.924 \t return: -568.444 \t ep_len: 569.222\n",
      "epoch: 897 \t loss: -203.784 \t return: -624.778 \t ep_len: 625.444\n",
      "epoch: 898 \t loss: -146.475 \t return: -386.231 \t ep_len: 387.231\n",
      "epoch: 899 \t loss: -249.755 \t return: -862.667 \t ep_len: 863.333\n",
      "epoch: 900 \t loss: -222.884 \t return: -505.800 \t ep_len: 506.500\n",
      "epoch: 901 \t loss: -205.153 \t return: -471.273 \t ep_len: 472.000\n",
      "epoch: 902 \t loss: -229.695 \t return: -566.000 \t ep_len: 566.700\n",
      "epoch: 903 \t loss: -256.379 \t return: -528.727 \t ep_len: 529.455\n",
      "epoch: 904 \t loss: -252.581 \t return: -489.818 \t ep_len: 490.545\n",
      "epoch: 905 \t loss: -288.555 \t return: -633.625 \t ep_len: 634.125\n",
      "epoch: 906 \t loss: -252.523 \t return: -569.444 \t ep_len: 570.222\n",
      "epoch: 907 \t loss: -319.242 \t return: -832.571 \t ep_len: 833.000\n",
      "epoch: 908 \t loss: -203.276 \t return: -391.462 \t ep_len: 392.385\n",
      "epoch: 909 \t loss: -267.101 \t return: -503.500 \t ep_len: 504.300\n",
      "epoch: 910 \t loss: -267.912 \t return: -661.111 \t ep_len: 662.000\n",
      "epoch: 911 \t loss: -217.433 \t return: -365.571 \t ep_len: 366.500\n",
      "epoch: 912 \t loss: -268.537 \t return: -493.909 \t ep_len: 494.818\n",
      "epoch: 913 \t loss: -238.555 \t return: -504.455 \t ep_len: 505.364\n",
      "epoch: 914 \t loss: -231.307 \t return: -467.167 \t ep_len: 468.083\n",
      "epoch: 915 \t loss: -285.322 \t return: -598.111 \t ep_len: 598.889\n",
      "epoch: 916 \t loss: -302.487 \t return: -583.778 \t ep_len: 584.444\n",
      "epoch: 917 \t loss: -309.828 \t return: -443.231 \t ep_len: 444.000\n",
      "epoch: 918 \t loss: -313.757 \t return: -581.889 \t ep_len: 582.667\n",
      "epoch: 919 \t loss: -310.794 \t return: -463.667 \t ep_len: 464.500\n",
      "epoch: 920 \t loss: -224.266 \t return: -356.733 \t ep_len: 357.667\n",
      "epoch: 921 \t loss: -237.662 \t return: -376.857 \t ep_len: 377.786\n",
      "epoch: 922 \t loss: -274.262 \t return: -516.182 \t ep_len: 517.000\n",
      "epoch: 923 \t loss: -276.441 \t return: -536.100 \t ep_len: 537.100\n",
      "epoch: 924 \t loss: -302.261 \t return: -571.444 \t ep_len: 572.111\n",
      "epoch: 925 \t loss: -288.964 \t return: -421.692 \t ep_len: 422.538\n",
      "epoch: 926 \t loss: -298.833 \t return: -616.444 \t ep_len: 617.333\n",
      "epoch: 927 \t loss: -308.803 \t return: -501.545 \t ep_len: 502.455\n",
      "epoch: 928 \t loss: -300.370 \t return: -596.111 \t ep_len: 597.000\n",
      "epoch: 929 \t loss: -275.076 \t return: -372.067 \t ep_len: 372.933\n",
      "epoch: 930 \t loss: -303.739 \t return: -474.333 \t ep_len: 475.167\n",
      "epoch: 931 \t loss: -267.438 \t return: -340.133 \t ep_len: 341.000\n",
      "epoch: 932 \t loss: -340.800 \t return: -397.500 \t ep_len: 398.357\n",
      "epoch: 933 \t loss: -363.921 \t return: -691.250 \t ep_len: 692.125\n",
      "epoch: 934 \t loss: -388.744 \t return: -532.273 \t ep_len: 532.909\n",
      "epoch: 935 \t loss: -199.932 \t return: -313.875 \t ep_len: 314.875\n",
      "epoch: 936 \t loss: -357.728 \t return: -594.667 \t ep_len: 595.556\n",
      "epoch: 937 \t loss: -246.253 \t return: -391.692 \t ep_len: 392.615\n",
      "epoch: 938 \t loss: -346.398 \t return: -577.000 \t ep_len: 577.700\n",
      "epoch: 939 \t loss: -196.704 \t return: -310.588 \t ep_len: 311.588\n",
      "epoch: 940 \t loss: -241.620 \t return: -365.643 \t ep_len: 366.643\n",
      "epoch: 941 \t loss: -227.406 \t return: -297.824 \t ep_len: 298.765\n",
      "epoch: 942 \t loss: -327.309 \t return: -402.846 \t ep_len: 403.769\n",
      "epoch: 943 \t loss: -301.867 \t return: -371.286 \t ep_len: 372.214\n",
      "epoch: 944 \t loss: -335.509 \t return: -433.154 \t ep_len: 434.077\n",
      "epoch: 945 \t loss: -375.061 \t return: -572.000 \t ep_len: 572.667\n",
      "epoch: 946 \t loss: -299.996 \t return: -425.769 \t ep_len: 426.692\n",
      "epoch: 947 \t loss: -335.886 \t return: -518.500 \t ep_len: 519.300\n",
      "epoch: 948 \t loss: -279.168 \t return: -389.615 \t ep_len: 390.538\n",
      "epoch: 949 \t loss: -270.671 \t return: -456.545 \t ep_len: 457.545\n",
      "epoch: 950 \t loss: -267.925 \t return: -326.688 \t ep_len: 327.562\n",
      "epoch: 951 \t loss: -304.597 \t return: -526.000 \t ep_len: 526.900\n",
      "epoch: 952 \t loss: -346.663 \t return: -503.400 \t ep_len: 504.300\n",
      "epoch: 953 \t loss: -397.729 \t return: -629.125 \t ep_len: 629.875\n",
      "epoch: 954 \t loss: -322.082 \t return: -384.077 \t ep_len: 385.000\n",
      "epoch: 955 \t loss: -296.416 \t return: -417.083 \t ep_len: 418.000\n",
      "epoch: 956 \t loss: -374.427 \t return: -414.077 \t ep_len: 414.846\n",
      "epoch: 957 \t loss: -376.467 \t return: -380.000 \t ep_len: 380.867\n",
      "epoch: 958 \t loss: -442.093 \t return: -663.778 \t ep_len: 664.444\n",
      "epoch: 959 \t loss: -369.652 \t return: -474.182 \t ep_len: 475.091\n",
      "epoch: 960 \t loss: -335.992 \t return: -435.167 \t ep_len: 436.083\n",
      "epoch: 961 \t loss: -457.960 \t return: -621.667 \t ep_len: 622.333\n",
      "epoch: 962 \t loss: -394.896 \t return: -464.333 \t ep_len: 465.250\n",
      "epoch: 963 \t loss: -417.886 \t return: -478.909 \t ep_len: 479.818\n",
      "epoch: 964 \t loss: -433.501 \t return: -555.444 \t ep_len: 556.333\n",
      "epoch: 965 \t loss: -468.110 \t return: -517.600 \t ep_len: 518.400\n",
      "epoch: 966 \t loss: -429.590 \t return: -445.500 \t ep_len: 446.417\n",
      "epoch: 967 \t loss: -417.249 \t return: -437.615 \t ep_len: 438.615\n",
      "epoch: 968 \t loss: -334.564 \t return: -348.625 \t ep_len: 349.625\n",
      "epoch: 969 \t loss: -462.027 \t return: -529.900 \t ep_len: 530.600\n",
      "epoch: 970 \t loss: -351.848 \t return: -382.929 \t ep_len: 383.857\n",
      "epoch: 971 \t loss: -349.482 \t return: -425.538 \t ep_len: 426.462\n",
      "epoch: 972 \t loss: -313.835 \t return: -398.615 \t ep_len: 399.615\n",
      "epoch: 973 \t loss: -413.657 \t return: -587.000 \t ep_len: 587.778\n",
      "epoch: 974 \t loss: -304.071 \t return: -422.333 \t ep_len: 423.250\n",
      "epoch: 975 \t loss: -428.888 \t return: -515.700 \t ep_len: 516.400\n",
      "epoch: 976 \t loss: -360.029 \t return: -433.083 \t ep_len: 433.917\n",
      "epoch: 977 \t loss: -349.849 \t return: -467.182 \t ep_len: 468.091\n",
      "epoch: 978 \t loss: -272.376 \t return: -313.000 \t ep_len: 313.938\n",
      "epoch: 979 \t loss: -370.584 \t return: -538.300 \t ep_len: 539.000\n",
      "epoch: 980 \t loss: -405.585 \t return: -464.636 \t ep_len: 465.364\n",
      "epoch: 981 \t loss: -374.849 \t return: -403.615 \t ep_len: 404.462\n",
      "epoch: 982 \t loss: -293.993 \t return: -388.000 \t ep_len: 388.929\n",
      "epoch: 983 \t loss: -296.846 \t return: -330.250 \t ep_len: 331.125\n",
      "epoch: 984 \t loss: -404.422 \t return: -588.200 \t ep_len: 588.900\n",
      "epoch: 985 \t loss: -278.239 \t return: -439.833 \t ep_len: 440.833\n",
      "epoch: 986 \t loss: -287.607 \t return: -412.385 \t ep_len: 413.308\n",
      "epoch: 987 \t loss: -252.925 \t return: -368.938 \t ep_len: 369.938\n",
      "epoch: 988 \t loss: -306.679 \t return: -341.938 \t ep_len: 342.938\n",
      "epoch: 989 \t loss: -297.226 \t return: -438.923 \t ep_len: 439.846\n",
      "epoch: 990 \t loss: -273.346 \t return: -437.615 \t ep_len: 438.538\n",
      "epoch: 991 \t loss: -262.451 \t return: -348.067 \t ep_len: 349.067\n",
      "epoch: 992 \t loss: -331.765 \t return: -458.417 \t ep_len: 459.333\n",
      "epoch: 993 \t loss: -289.948 \t return: -391.923 \t ep_len: 392.846\n",
      "epoch: 994 \t loss: -367.998 \t return: -526.000 \t ep_len: 526.800\n",
      "epoch: 995 \t loss: -253.120 \t return: -365.714 \t ep_len: 366.714\n",
      "epoch: 996 \t loss: -378.699 \t return: -396.357 \t ep_len: 397.286\n",
      "epoch: 997 \t loss: -385.056 \t return: -542.091 \t ep_len: 542.909\n",
      "epoch: 998 \t loss: -377.568 \t return: -449.000 \t ep_len: 449.846\n",
      "epoch: 999 \t loss: -367.239 \t return: -416.286 \t ep_len: 417.143\n",
      "epoch: 1000 \t loss: -297.311 \t return: -341.733 \t ep_len: 342.667\n",
      "epoch: 1001 \t loss: -383.547 \t return: -515.300 \t ep_len: 516.100\n",
      "epoch: 1002 \t loss: -256.647 \t return: -296.765 \t ep_len: 297.706\n",
      "epoch: 1003 \t loss: -289.083 \t return: -346.467 \t ep_len: 347.400\n",
      "epoch: 1004 \t loss: -410.896 \t return: -497.000 \t ep_len: 497.833\n",
      "epoch: 1005 \t loss: -335.703 \t return: -425.000 \t ep_len: 426.000\n",
      "epoch: 1006 \t loss: -413.689 \t return: -467.545 \t ep_len: 468.364\n",
      "epoch: 1007 \t loss: -314.388 \t return: -336.333 \t ep_len: 337.333\n",
      "epoch: 1008 \t loss: -368.380 \t return: -369.929 \t ep_len: 370.786\n",
      "epoch: 1009 \t loss: -311.249 \t return: -378.067 \t ep_len: 379.000\n",
      "epoch: 1010 \t loss: -375.044 \t return: -428.833 \t ep_len: 429.750\n",
      "epoch: 1011 \t loss: -300.074 \t return: -323.562 \t ep_len: 324.500\n",
      "epoch: 1012 \t loss: -316.517 \t return: -358.429 \t ep_len: 359.357\n",
      "epoch: 1013 \t loss: -342.660 \t return: -378.929 \t ep_len: 379.857\n",
      "epoch: 1014 \t loss: -487.626 \t return: -562.400 \t ep_len: 563.200\n",
      "epoch: 1015 \t loss: -298.291 \t return: -355.667 \t ep_len: 356.667\n",
      "epoch: 1016 \t loss: -325.178 \t return: -333.000 \t ep_len: 333.938\n",
      "epoch: 1017 \t loss: -485.146 \t return: -443.077 \t ep_len: 443.923\n",
      "epoch: 1018 \t loss: -417.556 \t return: -459.909 \t ep_len: 460.818\n",
      "epoch: 1019 \t loss: -356.255 \t return: -393.077 \t ep_len: 394.077\n",
      "epoch: 1020 \t loss: -376.062 \t return: -392.385 \t ep_len: 393.385\n",
      "epoch: 1021 \t loss: -351.114 \t return: -393.846 \t ep_len: 394.846\n",
      "epoch: 1022 \t loss: -519.204 \t return: -486.750 \t ep_len: 487.500\n",
      "epoch: 1023 \t loss: -343.316 \t return: -371.375 \t ep_len: 372.375\n",
      "epoch: 1024 \t loss: -356.964 \t return: -334.467 \t ep_len: 335.400\n",
      "epoch: 1025 \t loss: -369.631 \t return: -377.929 \t ep_len: 378.857\n",
      "epoch: 1026 \t loss: -274.322 \t return: -304.471 \t ep_len: 305.471\n",
      "epoch: 1027 \t loss: -258.098 \t return: -232.364 \t ep_len: 233.318\n",
      "epoch: 1028 \t loss: -295.132 \t return: -363.400 \t ep_len: 364.400\n",
      "epoch: 1029 \t loss: -364.231 \t return: -348.067 \t ep_len: 349.000\n",
      "epoch: 1030 \t loss: -417.142 \t return: -359.643 \t ep_len: 360.500\n",
      "epoch: 1031 \t loss: -235.304 \t return: -237.619 \t ep_len: 238.619\n",
      "epoch: 1032 \t loss: -273.172 \t return: -262.150 \t ep_len: 263.100\n",
      "epoch: 1033 \t loss: -340.041 \t return: -332.800 \t ep_len: 333.733\n",
      "epoch: 1034 \t loss: -419.332 \t return: -450.308 \t ep_len: 451.231\n",
      "epoch: 1035 \t loss: -399.800 \t return: -337.938 \t ep_len: 338.875\n",
      "epoch: 1036 \t loss: -325.175 \t return: -365.500 \t ep_len: 366.500\n",
      "epoch: 1037 \t loss: -321.805 \t return: -315.062 \t ep_len: 316.062\n",
      "epoch: 1038 \t loss: -436.518 \t return: -338.706 \t ep_len: 339.529\n",
      "epoch: 1039 \t loss: -246.746 \t return: -250.952 \t ep_len: 251.952\n",
      "epoch: 1040 \t loss: -328.470 \t return: -341.467 \t ep_len: 342.467\n",
      "epoch: 1041 \t loss: -430.097 \t return: -414.846 \t ep_len: 415.769\n",
      "epoch: 1042 \t loss: -332.647 \t return: -315.812 \t ep_len: 316.750\n",
      "epoch: 1043 \t loss: -428.636 \t return: -482.833 \t ep_len: 483.667\n",
      "epoch: 1044 \t loss: -282.736 \t return: -347.312 \t ep_len: 348.312\n",
      "epoch: 1045 \t loss: -338.003 \t return: -349.667 \t ep_len: 350.667\n",
      "epoch: 1046 \t loss: -351.318 \t return: -412.929 \t ep_len: 413.857\n",
      "epoch: 1047 \t loss: -332.902 \t return: -376.071 \t ep_len: 377.071\n",
      "epoch: 1048 \t loss: -328.794 \t return: -376.357 \t ep_len: 377.286\n",
      "epoch: 1049 \t loss: -313.990 \t return: -361.867 \t ep_len: 362.800\n",
      "epoch: 1050 \t loss: -206.795 \t return: -257.810 \t ep_len: 258.810\n",
      "epoch: 1051 \t loss: -241.708 \t return: -331.118 \t ep_len: 332.118\n",
      "epoch: 1052 \t loss: -194.158 \t return: -266.579 \t ep_len: 267.579\n",
      "epoch: 1053 \t loss: -295.907 \t return: -464.545 \t ep_len: 465.455\n",
      "epoch: 1054 \t loss: -244.246 \t return: -429.417 \t ep_len: 430.417\n",
      "epoch: 1055 \t loss: -338.046 \t return: -580.000 \t ep_len: 580.778\n",
      "epoch: 1056 \t loss: -296.504 \t return: -496.182 \t ep_len: 497.091\n",
      "epoch: 1057 \t loss: -293.847 \t return: -565.889 \t ep_len: 566.778\n",
      "epoch: 1058 \t loss: -327.693 \t return: -560.444 \t ep_len: 561.222\n",
      "epoch: 1059 \t loss: -255.588 \t return: -391.462 \t ep_len: 392.385\n",
      "epoch: 1060 \t loss: -244.860 \t return: -328.312 \t ep_len: 329.312\n",
      "epoch: 1061 \t loss: -235.831 \t return: -389.923 \t ep_len: 390.846\n",
      "epoch: 1062 \t loss: -250.645 \t return: -398.769 \t ep_len: 399.692\n",
      "epoch: 1063 \t loss: -233.549 \t return: -299.059 \t ep_len: 300.000\n",
      "epoch: 1064 \t loss: -284.476 \t return: -352.562 \t ep_len: 353.500\n",
      "epoch: 1065 \t loss: -284.639 \t return: -345.933 \t ep_len: 346.933\n",
      "epoch: 1066 \t loss: -279.812 \t return: -360.714 \t ep_len: 361.714\n",
      "epoch: 1067 \t loss: -304.766 \t return: -403.000 \t ep_len: 403.923\n",
      "epoch: 1068 \t loss: -333.305 \t return: -426.917 \t ep_len: 427.833\n",
      "epoch: 1069 \t loss: -254.709 \t return: -354.800 \t ep_len: 355.800\n",
      "epoch: 1070 \t loss: -235.653 \t return: -274.368 \t ep_len: 275.368\n",
      "epoch: 1071 \t loss: -460.395 \t return: -568.000 \t ep_len: 568.667\n",
      "epoch: 1072 \t loss: -387.529 \t return: -399.769 \t ep_len: 400.615\n",
      "epoch: 1073 \t loss: -293.002 \t return: -266.316 \t ep_len: 267.316\n",
      "epoch: 1074 \t loss: -340.780 \t return: -307.353 \t ep_len: 308.294\n",
      "epoch: 1075 \t loss: -285.643 \t return: -295.294 \t ep_len: 296.294\n",
      "epoch: 1076 \t loss: -429.499 \t return: -366.500 \t ep_len: 367.429\n",
      "epoch: 1077 \t loss: -297.444 \t return: -282.000 \t ep_len: 283.000\n",
      "epoch: 1078 \t loss: -349.283 \t return: -405.692 \t ep_len: 406.615\n",
      "epoch: 1079 \t loss: -361.667 \t return: -342.125 \t ep_len: 343.125\n",
      "epoch: 1080 \t loss: -272.380 \t return: -304.118 \t ep_len: 305.118\n",
      "epoch: 1081 \t loss: -218.154 \t return: -249.600 \t ep_len: 250.600\n",
      "epoch: 1082 \t loss: -314.902 \t return: -404.357 \t ep_len: 405.357\n",
      "epoch: 1083 \t loss: -355.119 \t return: -388.571 \t ep_len: 389.500\n",
      "epoch: 1084 \t loss: -325.903 \t return: -326.111 \t ep_len: 327.056\n",
      "epoch: 1085 \t loss: -336.010 \t return: -373.000 \t ep_len: 373.929\n",
      "epoch: 1086 \t loss: -264.825 \t return: -270.050 \t ep_len: 271.050\n",
      "epoch: 1087 \t loss: -195.286 \t return: -258.000 \t ep_len: 259.000\n",
      "epoch: 1088 \t loss: -275.199 \t return: -267.211 \t ep_len: 268.211\n",
      "epoch: 1089 \t loss: -284.984 \t return: -305.368 \t ep_len: 306.368\n",
      "epoch: 1090 \t loss: -334.560 \t return: -362.357 \t ep_len: 363.286\n",
      "epoch: 1091 \t loss: -236.056 \t return: -237.905 \t ep_len: 238.905\n",
      "epoch: 1092 \t loss: -328.870 \t return: -320.941 \t ep_len: 321.882\n",
      "epoch: 1093 \t loss: -317.253 \t return: -351.667 \t ep_len: 352.667\n",
      "epoch: 1094 \t loss: -271.903 \t return: -373.214 \t ep_len: 374.214\n",
      "epoch: 1095 \t loss: -247.448 \t return: -268.211 \t ep_len: 269.211\n",
      "epoch: 1096 \t loss: -285.557 \t return: -267.895 \t ep_len: 268.842\n",
      "epoch: 1097 \t loss: -295.098 \t return: -343.200 \t ep_len: 344.133\n",
      "epoch: 1098 \t loss: -424.116 \t return: -423.833 \t ep_len: 424.750\n",
      "epoch: 1099 \t loss: -295.641 \t return: -335.600 \t ep_len: 336.600\n",
      "epoch: 1100 \t loss: -308.282 \t return: -252.857 \t ep_len: 253.810\n",
      "epoch: 1101 \t loss: -281.957 \t return: -302.500 \t ep_len: 303.500\n",
      "epoch: 1102 \t loss: -267.944 \t return: -279.667 \t ep_len: 280.667\n",
      "epoch: 1103 \t loss: -371.269 \t return: -390.308 \t ep_len: 391.308\n",
      "epoch: 1104 \t loss: -403.490 \t return: -383.000 \t ep_len: 384.000\n",
      "epoch: 1105 \t loss: -333.321 \t return: -298.722 \t ep_len: 299.667\n",
      "epoch: 1106 \t loss: -406.990 \t return: -362.667 \t ep_len: 363.600\n",
      "epoch: 1107 \t loss: -289.019 \t return: -252.950 \t ep_len: 253.900\n",
      "epoch: 1108 \t loss: -271.942 \t return: -264.421 \t ep_len: 265.421\n",
      "epoch: 1109 \t loss: -413.106 \t return: -407.077 \t ep_len: 407.923\n",
      "epoch: 1110 \t loss: -447.447 \t return: -454.167 \t ep_len: 455.083\n",
      "epoch: 1111 \t loss: -346.519 \t return: -288.722 \t ep_len: 289.611\n",
      "epoch: 1112 \t loss: -271.916 \t return: -267.700 \t ep_len: 268.650\n",
      "epoch: 1113 \t loss: -285.076 \t return: -324.235 \t ep_len: 325.235\n",
      "epoch: 1114 \t loss: -276.790 \t return: -333.688 \t ep_len: 334.688\n",
      "epoch: 1115 \t loss: -247.338 \t return: -226.909 \t ep_len: 227.909\n",
      "epoch: 1116 \t loss: -210.111 \t return: -254.800 \t ep_len: 255.800\n",
      "epoch: 1117 \t loss: -288.423 \t return: -309.056 \t ep_len: 310.000\n",
      "epoch: 1118 \t loss: -389.974 \t return: -478.167 \t ep_len: 479.083\n",
      "epoch: 1119 \t loss: -217.912 \t return: -266.050 \t ep_len: 267.050\n",
      "epoch: 1120 \t loss: -214.868 \t return: -302.000 \t ep_len: 303.000\n",
      "epoch: 1121 \t loss: -308.455 \t return: -387.769 \t ep_len: 388.692\n",
      "epoch: 1122 \t loss: -316.044 \t return: -388.000 \t ep_len: 388.933\n",
      "epoch: 1123 \t loss: -235.375 \t return: -320.062 \t ep_len: 321.062\n",
      "epoch: 1124 \t loss: -287.034 \t return: -456.364 \t ep_len: 457.364\n",
      "epoch: 1125 \t loss: -317.751 \t return: -309.500 \t ep_len: 310.444\n",
      "epoch: 1126 \t loss: -338.292 \t return: -384.615 \t ep_len: 385.462\n",
      "epoch: 1127 \t loss: -198.140 \t return: -212.792 \t ep_len: 213.750\n",
      "epoch: 1128 \t loss: -284.858 \t return: -359.500 \t ep_len: 360.500\n",
      "epoch: 1129 \t loss: -252.812 \t return: -297.882 \t ep_len: 298.824\n",
      "epoch: 1130 \t loss: -428.902 \t return: -573.500 \t ep_len: 574.200\n",
      "epoch: 1131 \t loss: -263.514 \t return: -302.176 \t ep_len: 303.176\n",
      "epoch: 1132 \t loss: -258.486 \t return: -226.636 \t ep_len: 227.591\n",
      "epoch: 1133 \t loss: -282.836 \t return: -339.400 \t ep_len: 340.333\n",
      "epoch: 1134 \t loss: -228.170 \t return: -293.824 \t ep_len: 294.824\n",
      "epoch: 1135 \t loss: -208.880 \t return: -242.286 \t ep_len: 243.286\n",
      "epoch: 1136 \t loss: -246.160 \t return: -270.619 \t ep_len: 271.619\n",
      "epoch: 1137 \t loss: -236.596 \t return: -296.176 \t ep_len: 297.176\n",
      "epoch: 1138 \t loss: -375.891 \t return: -360.000 \t ep_len: 361.000\n",
      "epoch: 1139 \t loss: -270.365 \t return: -275.316 \t ep_len: 276.316\n",
      "epoch: 1140 \t loss: -337.734 \t return: -305.333 \t ep_len: 306.333\n",
      "epoch: 1141 \t loss: -267.104 \t return: -237.667 \t ep_len: 238.667\n",
      "epoch: 1142 \t loss: -302.776 \t return: -291.778 \t ep_len: 292.778\n",
      "epoch: 1143 \t loss: -335.260 \t return: -257.600 \t ep_len: 258.600\n",
      "epoch: 1144 \t loss: -297.023 \t return: -249.048 \t ep_len: 250.048\n",
      "epoch: 1145 \t loss: -342.481 \t return: -302.833 \t ep_len: 303.833\n",
      "epoch: 1146 \t loss: -340.716 \t return: -279.056 \t ep_len: 280.000\n",
      "epoch: 1147 \t loss: -274.016 \t return: -262.737 \t ep_len: 263.737\n",
      "epoch: 1148 \t loss: -364.375 \t return: -334.000 \t ep_len: 334.938\n",
      "epoch: 1149 \t loss: -419.239 \t return: -308.588 \t ep_len: 309.529\n",
      "epoch: 1150 \t loss: -414.307 \t return: -372.857 \t ep_len: 373.857\n",
      "epoch: 1151 \t loss: -326.647 \t return: -275.895 \t ep_len: 276.895\n",
      "epoch: 1152 \t loss: -346.237 \t return: -281.684 \t ep_len: 282.684\n",
      "epoch: 1153 \t loss: -297.381 \t return: -257.150 \t ep_len: 258.150\n",
      "epoch: 1154 \t loss: -244.404 \t return: -236.304 \t ep_len: 237.304\n",
      "epoch: 1155 \t loss: -381.404 \t return: -343.250 \t ep_len: 344.250\n",
      "epoch: 1156 \t loss: -275.027 \t return: -279.444 \t ep_len: 280.444\n",
      "epoch: 1157 \t loss: -301.313 \t return: -262.545 \t ep_len: 263.500\n",
      "epoch: 1158 \t loss: -387.888 \t return: -334.375 \t ep_len: 335.312\n",
      "epoch: 1159 \t loss: -351.749 \t return: -334.533 \t ep_len: 335.533\n",
      "epoch: 1160 \t loss: -239.036 \t return: -228.667 \t ep_len: 229.667\n",
      "epoch: 1161 \t loss: -233.239 \t return: -200.080 \t ep_len: 201.080\n",
      "epoch: 1162 \t loss: -357.205 \t return: -301.588 \t ep_len: 302.529\n",
      "epoch: 1163 \t loss: -300.610 \t return: -249.700 \t ep_len: 250.650\n",
      "epoch: 1164 \t loss: -271.930 \t return: -236.227 \t ep_len: 237.227\n",
      "epoch: 1165 \t loss: -190.358 \t return: -202.000 \t ep_len: 203.000\n",
      "epoch: 1166 \t loss: -316.566 \t return: -360.000 \t ep_len: 361.000\n",
      "epoch: 1167 \t loss: -386.309 \t return: -345.200 \t ep_len: 346.200\n",
      "epoch: 1168 \t loss: -246.698 \t return: -279.389 \t ep_len: 280.389\n",
      "epoch: 1169 \t loss: -247.935 \t return: -214.500 \t ep_len: 215.500\n",
      "epoch: 1170 \t loss: -370.143 \t return: -298.294 \t ep_len: 299.235\n",
      "epoch: 1171 \t loss: -175.472 \t return: -176.621 \t ep_len: 177.621\n",
      "epoch: 1172 \t loss: -331.918 \t return: -249.050 \t ep_len: 250.050\n",
      "epoch: 1173 \t loss: -443.696 \t return: -317.000 \t ep_len: 317.938\n",
      "epoch: 1174 \t loss: -284.410 \t return: -304.588 \t ep_len: 305.588\n",
      "epoch: 1175 \t loss: -431.915 \t return: -290.400 \t ep_len: 291.300\n",
      "epoch: 1176 \t loss: -203.189 \t return: -191.852 \t ep_len: 192.852\n",
      "epoch: 1177 \t loss: -348.645 \t return: -276.737 \t ep_len: 277.737\n",
      "epoch: 1178 \t loss: -346.753 \t return: -277.889 \t ep_len: 278.833\n",
      "epoch: 1179 \t loss: -296.283 \t return: -264.737 \t ep_len: 265.737\n",
      "epoch: 1180 \t loss: -426.388 \t return: -345.933 \t ep_len: 346.867\n",
      "epoch: 1181 \t loss: -338.048 \t return: -276.158 \t ep_len: 277.158\n",
      "epoch: 1182 \t loss: -159.786 \t return: -152.000 \t ep_len: 153.000\n",
      "epoch: 1183 \t loss: -394.225 \t return: -321.938 \t ep_len: 322.875\n",
      "epoch: 1184 \t loss: -376.058 \t return: -358.200 \t ep_len: 359.200\n",
      "epoch: 1185 \t loss: -202.583 \t return: -195.963 \t ep_len: 196.963\n",
      "epoch: 1186 \t loss: -205.305 \t return: -223.478 \t ep_len: 224.478\n",
      "epoch: 1187 \t loss: -258.215 \t return: -268.526 \t ep_len: 269.526\n",
      "epoch: 1188 \t loss: -403.734 \t return: -307.824 \t ep_len: 308.824\n",
      "epoch: 1189 \t loss: -238.899 \t return: -265.700 \t ep_len: 266.700\n",
      "epoch: 1190 \t loss: -279.820 \t return: -264.158 \t ep_len: 265.158\n",
      "epoch: 1191 \t loss: -285.294 \t return: -318.562 \t ep_len: 319.562\n",
      "epoch: 1192 \t loss: -241.656 \t return: -243.143 \t ep_len: 244.143\n",
      "epoch: 1193 \t loss: -211.443 \t return: -204.808 \t ep_len: 205.808\n",
      "epoch: 1194 \t loss: -340.731 \t return: -267.842 \t ep_len: 268.789\n",
      "epoch: 1195 \t loss: -330.148 \t return: -296.882 \t ep_len: 297.882\n",
      "epoch: 1196 \t loss: -284.056 \t return: -257.650 \t ep_len: 258.650\n",
      "epoch: 1197 \t loss: -251.752 \t return: -203.897 \t ep_len: 204.862\n",
      "epoch: 1198 \t loss: -278.522 \t return: -217.957 \t ep_len: 218.913\n",
      "epoch: 1199 \t loss: -186.480 \t return: -225.667 \t ep_len: 226.667\n",
      "epoch: 1200 \t loss: -237.176 \t return: -187.571 \t ep_len: 188.536\n",
      "epoch: 1201 \t loss: -229.654 \t return: -250.524 \t ep_len: 251.524\n",
      "epoch: 1202 \t loss: -346.218 \t return: -289.895 \t ep_len: 290.842\n",
      "epoch: 1203 \t loss: -182.061 \t return: -201.231 \t ep_len: 202.231\n",
      "epoch: 1204 \t loss: -196.393 \t return: -208.083 \t ep_len: 209.083\n",
      "epoch: 1205 \t loss: -246.152 \t return: -250.524 \t ep_len: 251.524\n",
      "epoch: 1206 \t loss: -243.929 \t return: -264.632 \t ep_len: 265.632\n",
      "epoch: 1207 \t loss: -221.967 \t return: -264.421 \t ep_len: 265.421\n",
      "epoch: 1208 \t loss: -222.515 \t return: -228.773 \t ep_len: 229.773\n",
      "epoch: 1209 \t loss: -213.450 \t return: -253.200 \t ep_len: 254.200\n",
      "epoch: 1210 \t loss: -267.902 \t return: -301.529 \t ep_len: 302.471\n",
      "epoch: 1211 \t loss: -199.528 \t return: -279.500 \t ep_len: 280.500\n",
      "epoch: 1212 \t loss: -222.001 \t return: -266.500 \t ep_len: 267.450\n",
      "epoch: 1213 \t loss: -208.024 \t return: -314.941 \t ep_len: 315.941\n",
      "epoch: 1214 \t loss: -172.356 \t return: -244.273 \t ep_len: 245.273\n",
      "epoch: 1215 \t loss: -302.079 \t return: -423.769 \t ep_len: 424.538\n",
      "epoch: 1216 \t loss: -196.591 \t return: -303.333 \t ep_len: 304.278\n",
      "epoch: 1217 \t loss: -161.985 \t return: -246.238 \t ep_len: 247.238\n",
      "epoch: 1218 \t loss: -208.091 \t return: -319.000 \t ep_len: 320.000\n",
      "epoch: 1219 \t loss: -180.391 \t return: -279.444 \t ep_len: 280.389\n",
      "epoch: 1220 \t loss: -195.084 \t return: -271.789 \t ep_len: 272.737\n",
      "epoch: 1221 \t loss: -147.025 \t return: -253.800 \t ep_len: 254.800\n",
      "epoch: 1222 \t loss: -194.615 \t return: -305.833 \t ep_len: 306.833\n",
      "epoch: 1223 \t loss: -267.957 \t return: -338.133 \t ep_len: 339.000\n",
      "epoch: 1224 \t loss: -225.051 \t return: -260.150 \t ep_len: 261.150\n",
      "epoch: 1225 \t loss: -171.930 \t return: -249.667 \t ep_len: 250.667\n",
      "epoch: 1226 \t loss: -194.170 \t return: -302.588 \t ep_len: 303.588\n",
      "epoch: 1227 \t loss: -186.052 \t return: -246.143 \t ep_len: 247.143\n",
      "epoch: 1228 \t loss: -266.348 \t return: -388.643 \t ep_len: 389.643\n",
      "epoch: 1229 \t loss: -272.025 \t return: -338.400 \t ep_len: 339.400\n",
      "epoch: 1230 \t loss: -191.439 \t return: -269.947 \t ep_len: 270.947\n",
      "epoch: 1231 \t loss: -158.900 \t return: -211.042 \t ep_len: 212.042\n",
      "epoch: 1232 \t loss: -188.097 \t return: -227.045 \t ep_len: 228.045\n",
      "epoch: 1233 \t loss: -234.537 \t return: -284.950 \t ep_len: 285.950\n",
      "epoch: 1234 \t loss: -222.662 \t return: -264.263 \t ep_len: 265.211\n",
      "epoch: 1235 \t loss: -227.085 \t return: -239.619 \t ep_len: 240.571\n",
      "epoch: 1236 \t loss: -162.108 \t return: -249.800 \t ep_len: 250.800\n",
      "epoch: 1237 \t loss: -248.187 \t return: -304.176 \t ep_len: 305.176\n",
      "epoch: 1238 \t loss: -187.299 \t return: -213.833 \t ep_len: 214.833\n",
      "epoch: 1239 \t loss: -299.749 \t return: -377.714 \t ep_len: 378.714\n",
      "epoch: 1240 \t loss: -173.597 \t return: -234.409 \t ep_len: 235.409\n",
      "epoch: 1241 \t loss: -172.639 \t return: -244.000 \t ep_len: 245.000\n",
      "epoch: 1242 \t loss: -163.755 \t return: -209.292 \t ep_len: 210.292\n",
      "epoch: 1243 \t loss: -235.958 \t return: -301.000 \t ep_len: 302.000\n",
      "epoch: 1244 \t loss: -278.384 \t return: -294.471 \t ep_len: 295.412\n",
      "epoch: 1245 \t loss: -185.642 \t return: -217.435 \t ep_len: 218.435\n",
      "epoch: 1246 \t loss: -215.982 \t return: -217.583 \t ep_len: 218.583\n",
      "epoch: 1247 \t loss: -213.588 \t return: -256.900 \t ep_len: 257.900\n",
      "epoch: 1248 \t loss: -214.239 \t return: -235.909 \t ep_len: 236.909\n",
      "epoch: 1249 \t loss: -264.529 \t return: -318.812 \t ep_len: 319.812\n",
      "epoch: 1250 \t loss: -181.520 \t return: -193.154 \t ep_len: 194.154\n",
      "epoch: 1251 \t loss: -167.858 \t return: -225.609 \t ep_len: 226.609\n",
      "epoch: 1252 \t loss: -189.546 \t return: -210.250 \t ep_len: 211.250\n",
      "epoch: 1253 \t loss: -233.441 \t return: -243.762 \t ep_len: 244.762\n",
      "epoch: 1254 \t loss: -260.675 \t return: -257.000 \t ep_len: 258.000\n",
      "epoch: 1255 \t loss: -228.821 \t return: -227.182 \t ep_len: 228.182\n",
      "epoch: 1256 \t loss: -259.576 \t return: -336.750 \t ep_len: 337.750\n",
      "epoch: 1257 \t loss: -247.058 \t return: -250.900 \t ep_len: 251.900\n",
      "epoch: 1258 \t loss: -238.450 \t return: -266.579 \t ep_len: 267.579\n",
      "epoch: 1259 \t loss: -269.787 \t return: -324.294 \t ep_len: 325.294\n",
      "epoch: 1260 \t loss: -220.181 \t return: -254.250 \t ep_len: 255.250\n",
      "epoch: 1261 \t loss: -171.734 \t return: -238.273 \t ep_len: 239.273\n",
      "epoch: 1262 \t loss: -218.284 \t return: -218.783 \t ep_len: 219.739\n",
      "epoch: 1263 \t loss: -208.238 \t return: -244.125 \t ep_len: 245.083\n",
      "epoch: 1264 \t loss: -243.361 \t return: -271.700 \t ep_len: 272.700\n",
      "epoch: 1265 \t loss: -278.432 \t return: -361.071 \t ep_len: 362.000\n",
      "epoch: 1266 \t loss: -230.460 \t return: -299.529 \t ep_len: 300.529\n",
      "epoch: 1267 \t loss: -229.737 \t return: -339.267 \t ep_len: 340.267\n",
      "epoch: 1268 \t loss: -227.202 \t return: -315.875 \t ep_len: 316.812\n",
      "epoch: 1269 \t loss: -189.081 \t return: -275.450 \t ep_len: 276.450\n",
      "epoch: 1270 \t loss: -288.412 \t return: -356.500 \t ep_len: 357.429\n",
      "epoch: 1271 \t loss: -193.525 \t return: -250.300 \t ep_len: 251.300\n",
      "epoch: 1272 \t loss: -224.768 \t return: -286.611 \t ep_len: 287.611\n",
      "epoch: 1273 \t loss: -240.814 \t return: -273.667 \t ep_len: 274.667\n",
      "epoch: 1274 \t loss: -183.159 \t return: -245.381 \t ep_len: 246.381\n",
      "epoch: 1275 \t loss: -198.729 \t return: -250.800 \t ep_len: 251.750\n",
      "epoch: 1276 \t loss: -275.829 \t return: -464.250 \t ep_len: 465.250\n",
      "epoch: 1277 \t loss: -198.479 \t return: -298.824 \t ep_len: 299.824\n",
      "epoch: 1278 \t loss: -291.493 \t return: -389.769 \t ep_len: 390.615\n",
      "epoch: 1279 \t loss: -176.895 \t return: -215.625 \t ep_len: 216.625\n",
      "epoch: 1280 \t loss: -198.162 \t return: -252.095 \t ep_len: 253.095\n",
      "epoch: 1281 \t loss: -275.342 \t return: -295.882 \t ep_len: 296.882\n",
      "epoch: 1282 \t loss: -217.855 \t return: -257.150 \t ep_len: 258.100\n",
      "epoch: 1283 \t loss: -173.134 \t return: -196.462 \t ep_len: 197.462\n",
      "epoch: 1284 \t loss: -159.810 \t return: -201.346 \t ep_len: 202.346\n",
      "epoch: 1285 \t loss: -218.957 \t return: -217.087 \t ep_len: 218.087\n",
      "epoch: 1286 \t loss: -147.052 \t return: -185.519 \t ep_len: 186.519\n",
      "epoch: 1287 \t loss: -167.588 \t return: -197.115 \t ep_len: 198.115\n",
      "epoch: 1288 \t loss: -146.247 \t return: -175.767 \t ep_len: 176.767\n",
      "epoch: 1289 \t loss: -176.538 \t return: -192.154 \t ep_len: 193.154\n",
      "epoch: 1290 \t loss: -231.409 \t return: -277.421 \t ep_len: 278.421\n",
      "epoch: 1291 \t loss: -174.313 \t return: -209.333 \t ep_len: 210.333\n",
      "epoch: 1292 \t loss: -172.338 \t return: -189.185 \t ep_len: 190.185\n",
      "epoch: 1293 \t loss: -213.125 \t return: -210.583 \t ep_len: 211.583\n",
      "epoch: 1294 \t loss: -164.683 \t return: -183.552 \t ep_len: 184.552\n",
      "epoch: 1295 \t loss: -223.832 \t return: -213.208 \t ep_len: 214.208\n",
      "epoch: 1296 \t loss: -160.494 \t return: -208.042 \t ep_len: 209.042\n",
      "epoch: 1297 \t loss: -178.736 \t return: -199.615 \t ep_len: 200.615\n",
      "epoch: 1298 \t loss: -152.474 \t return: -172.931 \t ep_len: 173.931\n",
      "epoch: 1299 \t loss: -307.426 \t return: -279.556 \t ep_len: 280.556\n",
      "epoch: 1300 \t loss: -156.878 \t return: -168.000 \t ep_len: 169.000\n",
      "epoch: 1301 \t loss: -228.738 \t return: -250.524 \t ep_len: 251.524\n",
      "epoch: 1302 \t loss: -211.677 \t return: -233.273 \t ep_len: 234.273\n",
      "epoch: 1303 \t loss: -183.690 \t return: -227.545 \t ep_len: 228.545\n",
      "epoch: 1304 \t loss: -185.244 \t return: -184.571 \t ep_len: 185.571\n",
      "epoch: 1305 \t loss: -234.848 \t return: -259.300 \t ep_len: 260.300\n",
      "epoch: 1306 \t loss: -176.431 \t return: -209.667 \t ep_len: 210.667\n",
      "epoch: 1307 \t loss: -226.590 \t return: -192.538 \t ep_len: 193.538\n",
      "epoch: 1308 \t loss: -184.236 \t return: -200.000 \t ep_len: 201.000\n",
      "epoch: 1309 \t loss: -161.610 \t return: -207.417 \t ep_len: 208.417\n",
      "epoch: 1310 \t loss: -161.430 \t return: -185.185 \t ep_len: 186.185\n",
      "epoch: 1311 \t loss: -199.496 \t return: -202.160 \t ep_len: 203.160\n",
      "epoch: 1312 \t loss: -225.631 \t return: -253.700 \t ep_len: 254.700\n",
      "epoch: 1313 \t loss: -229.404 \t return: -220.739 \t ep_len: 221.739\n",
      "epoch: 1314 \t loss: -272.764 \t return: -254.783 \t ep_len: 255.739\n",
      "epoch: 1315 \t loss: -241.070 \t return: -186.966 \t ep_len: 187.966\n",
      "epoch: 1316 \t loss: -283.735 \t return: -277.857 \t ep_len: 278.857\n",
      "epoch: 1317 \t loss: -145.069 \t return: -141.622 \t ep_len: 142.622\n",
      "epoch: 1318 \t loss: -180.338 \t return: -195.077 \t ep_len: 196.077\n",
      "epoch: 1319 \t loss: -251.691 \t return: -250.550 \t ep_len: 251.500\n",
      "epoch: 1320 \t loss: -229.411 \t return: -180.862 \t ep_len: 181.862\n",
      "epoch: 1321 \t loss: -235.907 \t return: -196.154 \t ep_len: 197.115\n",
      "epoch: 1322 \t loss: -209.995 \t return: -174.517 \t ep_len: 175.517\n",
      "epoch: 1323 \t loss: -209.590 \t return: -189.074 \t ep_len: 190.074\n",
      "epoch: 1324 \t loss: -253.481 \t return: -244.333 \t ep_len: 245.333\n",
      "epoch: 1325 \t loss: -194.375 \t return: -174.276 \t ep_len: 175.276\n",
      "epoch: 1326 \t loss: -208.263 \t return: -161.194 \t ep_len: 162.194\n",
      "epoch: 1327 \t loss: -179.498 \t return: -186.667 \t ep_len: 187.667\n",
      "epoch: 1328 \t loss: -276.430 \t return: -280.889 \t ep_len: 281.889\n",
      "epoch: 1329 \t loss: -228.621 \t return: -242.095 \t ep_len: 243.095\n",
      "epoch: 1330 \t loss: -217.559 \t return: -245.773 \t ep_len: 246.773\n",
      "epoch: 1331 \t loss: -183.910 \t return: -187.741 \t ep_len: 188.741\n",
      "epoch: 1332 \t loss: -340.998 \t return: -265.500 \t ep_len: 266.450\n",
      "epoch: 1333 \t loss: -168.840 \t return: -178.786 \t ep_len: 179.786\n",
      "epoch: 1334 \t loss: -219.008 \t return: -200.320 \t ep_len: 201.320\n",
      "epoch: 1335 \t loss: -262.283 \t return: -199.640 \t ep_len: 200.600\n",
      "epoch: 1336 \t loss: -285.315 \t return: -291.800 \t ep_len: 292.800\n",
      "epoch: 1337 \t loss: -157.583 \t return: -179.964 \t ep_len: 180.964\n",
      "epoch: 1338 \t loss: -208.179 \t return: -263.737 \t ep_len: 264.737\n",
      "epoch: 1339 \t loss: -276.773 \t return: -228.045 \t ep_len: 229.045\n",
      "epoch: 1340 \t loss: -216.526 \t return: -187.310 \t ep_len: 188.310\n",
      "epoch: 1341 \t loss: -220.535 \t return: -192.000 \t ep_len: 193.000\n",
      "epoch: 1342 \t loss: -274.246 \t return: -297.056 \t ep_len: 298.056\n",
      "epoch: 1343 \t loss: -215.927 \t return: -221.783 \t ep_len: 222.783\n",
      "epoch: 1344 \t loss: -318.430 \t return: -240.318 \t ep_len: 241.273\n",
      "epoch: 1345 \t loss: -166.380 \t return: -183.679 \t ep_len: 184.679\n",
      "epoch: 1346 \t loss: -246.983 \t return: -233.870 \t ep_len: 234.870\n",
      "epoch: 1347 \t loss: -214.697 \t return: -184.069 \t ep_len: 185.069\n",
      "epoch: 1348 \t loss: -210.528 \t return: -208.625 \t ep_len: 209.625\n",
      "epoch: 1349 \t loss: -196.529 \t return: -194.222 \t ep_len: 195.222\n",
      "epoch: 1350 \t loss: -203.766 \t return: -217.217 \t ep_len: 218.217\n",
      "epoch: 1351 \t loss: -201.300 \t return: -166.100 \t ep_len: 167.100\n",
      "epoch: 1352 \t loss: -212.401 \t return: -218.000 \t ep_len: 219.000\n",
      "epoch: 1353 \t loss: -239.466 \t return: -233.273 \t ep_len: 234.273\n",
      "epoch: 1354 \t loss: -218.072 \t return: -219.565 \t ep_len: 220.565\n",
      "epoch: 1355 \t loss: -242.587 \t return: -254.700 \t ep_len: 255.700\n",
      "epoch: 1356 \t loss: -169.623 \t return: -185.815 \t ep_len: 186.815\n",
      "epoch: 1357 \t loss: -256.716 \t return: -264.526 \t ep_len: 265.526\n",
      "epoch: 1358 \t loss: -193.114 \t return: -221.087 \t ep_len: 222.087\n",
      "epoch: 1359 \t loss: -190.021 \t return: -200.577 \t ep_len: 201.577\n",
      "epoch: 1360 \t loss: -205.339 \t return: -203.400 \t ep_len: 204.400\n",
      "epoch: 1361 \t loss: -172.117 \t return: -195.038 \t ep_len: 196.038\n",
      "epoch: 1362 \t loss: -206.562 \t return: -178.250 \t ep_len: 179.250\n",
      "epoch: 1363 \t loss: -259.655 \t return: -249.700 \t ep_len: 250.700\n",
      "epoch: 1364 \t loss: -164.415 \t return: -205.840 \t ep_len: 206.840\n",
      "epoch: 1365 \t loss: -277.019 \t return: -277.167 \t ep_len: 278.167\n",
      "epoch: 1366 \t loss: -191.647 \t return: -227.000 \t ep_len: 228.000\n",
      "epoch: 1367 \t loss: -180.088 \t return: -189.519 \t ep_len: 190.519\n",
      "epoch: 1368 \t loss: -216.748 \t return: -207.750 \t ep_len: 208.750\n",
      "epoch: 1369 \t loss: -290.156 \t return: -267.200 \t ep_len: 268.150\n",
      "epoch: 1370 \t loss: -152.009 \t return: -207.520 \t ep_len: 208.520\n",
      "epoch: 1371 \t loss: -202.975 \t return: -219.957 \t ep_len: 220.957\n",
      "epoch: 1372 \t loss: -184.931 \t return: -231.455 \t ep_len: 232.455\n",
      "epoch: 1373 \t loss: -168.021 \t return: -201.360 \t ep_len: 202.360\n",
      "epoch: 1374 \t loss: -262.690 \t return: -237.810 \t ep_len: 238.810\n",
      "epoch: 1375 \t loss: -199.981 \t return: -201.115 \t ep_len: 202.115\n",
      "epoch: 1376 \t loss: -276.315 \t return: -257.750 \t ep_len: 258.700\n",
      "epoch: 1377 \t loss: -149.328 \t return: -184.963 \t ep_len: 185.963\n",
      "epoch: 1378 \t loss: -134.849 \t return: -146.500 \t ep_len: 147.500\n",
      "epoch: 1379 \t loss: -136.387 \t return: -161.161 \t ep_len: 162.161\n",
      "epoch: 1380 \t loss: -190.252 \t return: -229.955 \t ep_len: 230.955\n",
      "epoch: 1381 \t loss: -188.116 \t return: -203.074 \t ep_len: 204.074\n",
      "epoch: 1382 \t loss: -284.166 \t return: -208.280 \t ep_len: 209.240\n",
      "epoch: 1383 \t loss: -172.929 \t return: -181.034 \t ep_len: 182.034\n",
      "epoch: 1384 \t loss: -269.216 \t return: -293.412 \t ep_len: 294.412\n",
      "epoch: 1385 \t loss: -191.810 \t return: -232.826 \t ep_len: 233.826\n",
      "epoch: 1386 \t loss: -160.063 \t return: -199.200 \t ep_len: 200.200\n",
      "epoch: 1387 \t loss: -168.054 \t return: -207.417 \t ep_len: 208.417\n",
      "epoch: 1388 \t loss: -173.445 \t return: -179.103 \t ep_len: 180.103\n",
      "epoch: 1389 \t loss: -203.562 \t return: -186.857 \t ep_len: 187.857\n",
      "epoch: 1390 \t loss: -234.232 \t return: -245.087 \t ep_len: 246.087\n",
      "epoch: 1391 \t loss: -114.293 \t return: -166.833 \t ep_len: 167.833\n",
      "epoch: 1392 \t loss: -158.555 \t return: -177.448 \t ep_len: 178.448\n",
      "epoch: 1393 \t loss: -147.015 \t return: -210.833 \t ep_len: 211.833\n",
      "epoch: 1394 \t loss: -183.129 \t return: -217.478 \t ep_len: 218.478\n",
      "epoch: 1395 \t loss: -148.033 \t return: -172.933 \t ep_len: 173.933\n",
      "epoch: 1396 \t loss: -183.624 \t return: -192.423 \t ep_len: 193.423\n",
      "epoch: 1397 \t loss: -151.471 \t return: -181.464 \t ep_len: 182.464\n",
      "epoch: 1398 \t loss: -176.975 \t return: -207.667 \t ep_len: 208.667\n",
      "epoch: 1399 \t loss: -193.995 \t return: -210.481 \t ep_len: 211.481\n",
      "epoch: 1400 \t loss: -146.277 \t return: -200.720 \t ep_len: 201.720\n",
      "epoch: 1401 \t loss: -138.741 \t return: -169.226 \t ep_len: 170.226\n",
      "epoch: 1402 \t loss: -152.057 \t return: -196.111 \t ep_len: 197.111\n",
      "epoch: 1403 \t loss: -203.680 \t return: -196.207 \t ep_len: 197.207\n",
      "epoch: 1404 \t loss: -98.137 \t return: -132.000 \t ep_len: 133.000\n",
      "epoch: 1405 \t loss: -156.138 \t return: -192.074 \t ep_len: 193.074\n",
      "epoch: 1406 \t loss: -148.163 \t return: -164.562 \t ep_len: 165.562\n",
      "epoch: 1407 \t loss: -214.965 \t return: -230.087 \t ep_len: 231.087\n",
      "epoch: 1408 \t loss: -135.873 \t return: -186.429 \t ep_len: 187.429\n",
      "epoch: 1409 \t loss: -209.362 \t return: -282.611 \t ep_len: 283.611\n",
      "epoch: 1410 \t loss: -150.357 \t return: -167.806 \t ep_len: 168.806\n",
      "epoch: 1411 \t loss: -157.575 \t return: -187.643 \t ep_len: 188.643\n",
      "epoch: 1412 \t loss: -178.217 \t return: -202.520 \t ep_len: 203.520\n",
      "epoch: 1413 \t loss: -198.057 \t return: -222.261 \t ep_len: 223.261\n",
      "epoch: 1414 \t loss: -209.666 \t return: -226.864 \t ep_len: 227.864\n",
      "epoch: 1415 \t loss: -174.702 \t return: -197.567 \t ep_len: 198.533\n",
      "epoch: 1416 \t loss: -149.471 \t return: -182.893 \t ep_len: 183.893\n",
      "epoch: 1417 \t loss: -185.586 \t return: -179.536 \t ep_len: 180.536\n",
      "epoch: 1418 \t loss: -187.463 \t return: -215.667 \t ep_len: 216.667\n",
      "epoch: 1419 \t loss: -185.255 \t return: -199.480 \t ep_len: 200.480\n",
      "epoch: 1420 \t loss: -180.512 \t return: -239.571 \t ep_len: 240.571\n",
      "epoch: 1421 \t loss: -177.113 \t return: -196.000 \t ep_len: 197.000\n",
      "epoch: 1422 \t loss: -238.486 \t return: -215.458 \t ep_len: 216.458\n",
      "epoch: 1423 \t loss: -119.367 \t return: -142.556 \t ep_len: 143.556\n",
      "epoch: 1424 \t loss: -129.505 \t return: -174.483 \t ep_len: 175.483\n",
      "epoch: 1425 \t loss: -172.111 \t return: -189.111 \t ep_len: 190.111\n",
      "epoch: 1426 \t loss: -136.744 \t return: -181.429 \t ep_len: 182.429\n",
      "epoch: 1427 \t loss: -247.388 \t return: -220.087 \t ep_len: 221.087\n",
      "epoch: 1428 \t loss: -160.523 \t return: -199.440 \t ep_len: 200.440\n",
      "epoch: 1429 \t loss: -181.778 \t return: -251.600 \t ep_len: 252.600\n",
      "epoch: 1430 \t loss: -130.341 \t return: -148.914 \t ep_len: 149.914\n",
      "epoch: 1431 \t loss: -259.702 \t return: -262.684 \t ep_len: 263.684\n",
      "epoch: 1432 \t loss: -112.886 \t return: -161.129 \t ep_len: 162.129\n",
      "epoch: 1433 \t loss: -127.846 \t return: -156.812 \t ep_len: 157.812\n",
      "epoch: 1434 \t loss: -173.249 \t return: -199.080 \t ep_len: 200.080\n",
      "epoch: 1435 \t loss: -132.318 \t return: -146.914 \t ep_len: 147.914\n",
      "epoch: 1436 \t loss: -185.372 \t return: -176.828 \t ep_len: 177.793\n",
      "epoch: 1437 \t loss: -199.254 \t return: -217.280 \t ep_len: 218.280\n",
      "epoch: 1438 \t loss: -164.612 \t return: -178.759 \t ep_len: 179.759\n",
      "epoch: 1439 \t loss: -115.623 \t return: -156.125 \t ep_len: 157.125\n",
      "epoch: 1440 \t loss: -129.781 \t return: -138.816 \t ep_len: 139.816\n",
      "epoch: 1441 \t loss: -195.196 \t return: -193.333 \t ep_len: 194.333\n",
      "epoch: 1442 \t loss: -161.849 \t return: -163.500 \t ep_len: 164.500\n",
      "epoch: 1443 \t loss: -143.877 \t return: -164.290 \t ep_len: 165.290\n",
      "epoch: 1444 \t loss: -191.501 \t return: -220.435 \t ep_len: 221.435\n",
      "epoch: 1445 \t loss: -217.584 \t return: -177.893 \t ep_len: 178.893\n",
      "epoch: 1446 \t loss: -174.620 \t return: -174.276 \t ep_len: 175.276\n",
      "epoch: 1447 \t loss: -116.071 \t return: -153.118 \t ep_len: 154.118\n",
      "epoch: 1448 \t loss: -129.487 \t return: -166.633 \t ep_len: 167.633\n",
      "epoch: 1449 \t loss: -98.865 \t return: -133.051 \t ep_len: 134.051\n",
      "epoch: 1450 \t loss: -222.534 \t return: -245.476 \t ep_len: 246.476\n",
      "epoch: 1451 \t loss: -140.581 \t return: -176.733 \t ep_len: 177.733\n",
      "epoch: 1452 \t loss: -150.560 \t return: -167.333 \t ep_len: 168.333\n",
      "epoch: 1453 \t loss: -169.260 \t return: -185.571 \t ep_len: 186.571\n",
      "epoch: 1454 \t loss: -248.764 \t return: -241.810 \t ep_len: 242.810\n",
      "epoch: 1455 \t loss: -112.493 \t return: -131.737 \t ep_len: 132.737\n",
      "epoch: 1456 \t loss: -153.537 \t return: -181.586 \t ep_len: 182.586\n",
      "epoch: 1457 \t loss: -136.051 \t return: -153.364 \t ep_len: 154.364\n",
      "epoch: 1458 \t loss: -178.328 \t return: -192.615 \t ep_len: 193.615\n",
      "epoch: 1459 \t loss: -190.013 \t return: -182.607 \t ep_len: 183.607\n",
      "epoch: 1460 \t loss: -104.950 \t return: -142.889 \t ep_len: 143.889\n",
      "epoch: 1461 \t loss: -158.688 \t return: -186.000 \t ep_len: 187.000\n",
      "epoch: 1462 \t loss: -149.803 \t return: -203.080 \t ep_len: 204.080\n",
      "epoch: 1463 \t loss: -155.911 \t return: -191.615 \t ep_len: 192.615\n",
      "epoch: 1464 \t loss: -135.217 \t return: -172.138 \t ep_len: 173.138\n",
      "epoch: 1465 \t loss: -157.430 \t return: -186.000 \t ep_len: 187.000\n",
      "epoch: 1466 \t loss: -115.011 \t return: -155.375 \t ep_len: 156.375\n",
      "epoch: 1467 \t loss: -131.090 \t return: -175.931 \t ep_len: 176.931\n",
      "epoch: 1468 \t loss: -114.986 \t return: -155.812 \t ep_len: 156.812\n",
      "epoch: 1469 \t loss: -127.047 \t return: -155.812 \t ep_len: 156.812\n",
      "epoch: 1470 \t loss: -110.090 \t return: -128.872 \t ep_len: 129.872\n",
      "epoch: 1471 \t loss: -159.291 \t return: -190.214 \t ep_len: 191.214\n",
      "epoch: 1472 \t loss: -157.466 \t return: -208.320 \t ep_len: 209.320\n",
      "epoch: 1473 \t loss: -92.675 \t return: -138.444 \t ep_len: 139.444\n",
      "epoch: 1474 \t loss: -146.120 \t return: -172.552 \t ep_len: 173.552\n",
      "epoch: 1475 \t loss: -139.025 \t return: -163.452 \t ep_len: 164.452\n",
      "epoch: 1476 \t loss: -100.495 \t return: -141.886 \t ep_len: 142.886\n",
      "epoch: 1477 \t loss: -150.614 \t return: -185.926 \t ep_len: 186.926\n",
      "epoch: 1478 \t loss: -138.623 \t return: -181.607 \t ep_len: 182.607\n",
      "epoch: 1479 \t loss: -126.003 \t return: -151.364 \t ep_len: 152.364\n",
      "epoch: 1480 \t loss: -144.932 \t return: -142.114 \t ep_len: 143.114\n",
      "epoch: 1481 \t loss: -105.388 \t return: -149.118 \t ep_len: 150.118\n",
      "epoch: 1482 \t loss: -130.526 \t return: -146.529 \t ep_len: 147.529\n",
      "epoch: 1483 \t loss: -123.976 \t return: -177.552 \t ep_len: 178.552\n",
      "epoch: 1484 \t loss: -161.022 \t return: -185.889 \t ep_len: 186.889\n",
      "epoch: 1485 \t loss: -113.476 \t return: -156.061 \t ep_len: 157.061\n",
      "epoch: 1486 \t loss: -143.381 \t return: -167.133 \t ep_len: 168.133\n",
      "epoch: 1487 \t loss: -122.345 \t return: -132.237 \t ep_len: 133.237\n",
      "epoch: 1488 \t loss: -114.843 \t return: -132.342 \t ep_len: 133.342\n",
      "epoch: 1489 \t loss: -212.336 \t return: -200.160 \t ep_len: 201.120\n",
      "epoch: 1490 \t loss: -112.980 \t return: -128.385 \t ep_len: 129.385\n",
      "epoch: 1491 \t loss: -169.794 \t return: -162.562 \t ep_len: 163.562\n",
      "epoch: 1492 \t loss: -97.066 \t return: -143.829 \t ep_len: 144.829\n",
      "epoch: 1493 \t loss: -136.863 \t return: -159.879 \t ep_len: 160.879\n",
      "epoch: 1494 \t loss: -146.287 \t return: -184.143 \t ep_len: 185.143\n",
      "epoch: 1495 \t loss: -100.434 \t return: -134.405 \t ep_len: 135.405\n",
      "epoch: 1496 \t loss: -188.680 \t return: -199.885 \t ep_len: 200.885\n",
      "epoch: 1497 \t loss: -208.297 \t return: -168.935 \t ep_len: 169.935\n",
      "epoch: 1498 \t loss: -122.287 \t return: -151.091 \t ep_len: 152.091\n",
      "epoch: 1499 \t loss: -126.907 \t return: -156.706 \t ep_len: 157.706\n"
     ]
    }
   ],
   "source": [
    "policy = train(env_name = env_wrapped_rew, hidden_sizes = [32], lr = 1e-2, epochs = 1500, batch_size = 5000, render = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=147, out_features=32, bias=True)\n",
       "  (1): Linear(in_features=32, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138.88888888888889"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5000/36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomStart(gym.Wrapper):\n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset(**kwargs)   # â† still a dict here\n",
    "        base = self.unwrapped                  # MiniGridEnv\n",
    "\n",
    "        # sample a free floor tile\n",
    "        while True:\n",
    "            x = base.np_random.integers(1, base.width  - 1)\n",
    "            y = base.np_random.integers(1, base.height - 1)\n",
    "            if base.grid.get(x, y) is None:\n",
    "                base.agent_pos = (x, y)\n",
    "                base.agent_dir = base.np_random.integers(0, 4)\n",
    "                break\n",
    "\n",
    "        # regenerate dict-obs; *do not* flatten here\n",
    "        obs = base.gen_obs()\n",
    "        return obs, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_base   = LargeSimpleEnv(render_mode=\"human\")\n",
    "env_rs     = RandomStart(env_base)       # randomise first\n",
    "env_flat   = MiniGridFlatImg(env_rs)     # then flatten\n",
    "env_wr     = MiniGridReward(env_flat, goal_states=[(8, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to always start at the behinning at the start of each episode\n",
    "# # create the base env *with* a render mode\n",
    "# env_base = SimpleEnv(render_mode=\"human\")      # window pops up\n",
    "# # or render_mode=\"rgb_array\"  # returns an image you can display in a notebook\n",
    "\n",
    "# # wrap exactly as before\n",
    "# env_flat_vis  = MiniGridFlatImg(env_base)\n",
    "# env_wrapped_rew_vis = MiniGridReward(env_flat_vis, goal_states=[(8, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[188], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m             env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m finished with reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(ep_rews)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mplay_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_wr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[188], line 22\u001b[0m, in \u001b[0;36mplay_policy\u001b[0;34m(env, policy, num_episodes)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m     21\u001b[0m     action \u001b[38;5;241m=\u001b[39m get_action(torch\u001b[38;5;241m.\u001b[39mas_tensor(obs, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m---> 22\u001b[0m     obs, rew, done, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     ep_rews\u001b[38;5;241m.\u001b[39mappend(rew)\n\u001b[1;32m     24\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n",
      "Cell \u001b[0;32mIn[48], line 7\u001b[0m, in \u001b[0;36mMiniGridReward.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m----> 7\u001b[0m     obs, _, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# access agent position after the transition\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39munwrapped\u001b[38;5;241m.\u001b[39magent_pos\n",
      "File \u001b[0;32m~/miniconda3/envs/IBP/lib/python3.11/site-packages/gymnasium/core.py:550\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[1;32m    548\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 550\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(observation), reward, terminated, truncated, info\n",
      "File \u001b[0;32m~/miniconda3/envs/IBP/lib/python3.11/site-packages/gymnasium/core.py:322\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[1;32m    320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/IBP/lib/python3.11/site-packages/minigrid/minigrid_env.py:591\u001b[0m, in \u001b[0;36mMiniGridEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    588\u001b[0m     truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 591\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_obs()\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs, reward, terminated, truncated, {}\n",
      "File \u001b[0;32m~/miniconda3/envs/IBP/lib/python3.11/site-packages/minigrid/minigrid_env.py:781\u001b[0m, in \u001b[0;36mMiniGridEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow\u001b[38;5;241m.\u001b[39mblit(bg, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    780\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mpump()\n\u001b[0;32m--> 781\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mflip()\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#takes policy network and returns action distribution\n",
    "def get_policy(obs):\n",
    "    logits = policy(obs)\n",
    "    return Categorical(logits = logits)\n",
    "\n",
    "#samples actions from the action distrubution from the policy network\n",
    "def get_action(obs):\n",
    "    return get_policy(obs).sample().item()\n",
    "\n",
    "\n",
    "\n",
    "def play_policy(env, policy, num_episodes=1):\n",
    "    \"\"\"\n",
    "    Play the policy in the environment for a number of episodes.\n",
    "    \"\"\"\n",
    "    for episode in range(num_episodes):\n",
    "        obs, info = env.reset()\n",
    "        done = False\n",
    "        ep_rews = []\n",
    "        while not done:\n",
    "            action = get_action(torch.as_tensor(obs, dtype=torch.float32))\n",
    "            obs, rew, done, _, _ = env.step(action)\n",
    "            ep_rews.append(rew)\n",
    "            env.render()\n",
    "        print(f\"Episode {episode + 1} finished with reward: {sum(ep_rews)}\")\n",
    "\n",
    "play_policy(env_wr, policy, num_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = env.unwrapped.grid.get(1, 8)\n",
    "cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Generalizability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LargeSimpleEnv(MiniGridEnv):\n",
    "    def __init__(\n",
    "            self, \n",
    "            size=20, \n",
    "            agent_start_pos=(1, 8), \n",
    "            agent_start_dir=0, \n",
    "            max_steps=1000, \n",
    "            **kwargs,\n",
    "    ):\n",
    "        self.agent_start_pos = agent_start_pos\n",
    "        self.agent_start_dir = agent_start_dir\n",
    "        self.goal_pos = (8, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
    "\n",
    "        super().__init__(\n",
    "            mission_space=mission_space,\n",
    "            grid_size=size,\n",
    "            max_steps=max_steps,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "    @staticmethod\n",
    "    def _gen_mission():\n",
    "        return \"Find the shortest path\"\n",
    "\n",
    "    def _gen_grid(self, width, height):\n",
    "        #create gird\n",
    "        self.grid = Grid(width, height)\n",
    "        #place barrier\n",
    "        self.grid.wall_rect(0, 0, width, height)\n",
    "        #place goal\n",
    "        self.put_obj(Goal(), 8, 1)\n",
    "        #place walls horizontal walls\n",
    "        for i in range(1, width // 2):\n",
    "            self.grid.set(i, width - 4, Wall())\n",
    "            self.grid.set(i + width // 2 - 1, width - 7, Wall())\n",
    "            self.grid.set(i, width - 10, Wall())\n",
    "            self.grid.set(i + width // 2 - 1, width - 13, Wall())\n",
    "        # place vertical walls\n",
    "        for i in range(1, 6 ):            # three vertical walls\n",
    "                self.grid.set(4, i, Wall())\n",
    "                self.grid.set(12, i, Wall())\n",
    "        for i in range(1, 4):\n",
    "            self.grid.set(12, i+ 15, Wall())\n",
    "        #place agent\n",
    "        if self.agent_start_pos is not None:\n",
    "            self.agent_pos = self.agent_start_pos #check this\n",
    "            self.agent_dir = self.agent_start_dir\n",
    "        else:\n",
    "            self.place_agent()\n",
    "\n",
    "        self.mission = \"find the shortest path\"\n",
    "    \n",
    "    def count_states(self):\n",
    "        free_cells = sum(1 for x in range(self.grid.width)\n",
    "                      for y in range(self.grid.height)\n",
    "                      if not self.grid.get(x, y)) * 4\n",
    "        return free_cells \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'image': array([[[1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [2, 5, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0]],\n",
       "  \n",
       "         [[1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0]],\n",
       "  \n",
       "         [[1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0]],\n",
       "  \n",
       "         [[1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0]],\n",
       "  \n",
       "         [[1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0]],\n",
       "  \n",
       "         [[2, 5, 0],\n",
       "          [2, 5, 0],\n",
       "          [2, 5, 0],\n",
       "          [2, 5, 0],\n",
       "          [2, 5, 0],\n",
       "          [2, 5, 0],\n",
       "          [2, 5, 0]],\n",
       "  \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]]], dtype=uint8),\n",
       "  'direction': 0,\n",
       "  'mission': 'find the shortest path'},\n",
       " {})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large = LargeSimpleEnv(render_mode=\"human\")\n",
    "large.reset()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
