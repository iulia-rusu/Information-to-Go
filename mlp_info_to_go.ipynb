{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __future__ import should always be first\n",
    "from __future__ import annotations\n",
    "\n",
    "# Standard library imports\n",
    "from collections import defaultdict\n",
    "\n",
    "# Third-party imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Gymnasium & Minigrid imports\n",
    "import gymnasium as gym  # Correct way to import Gymnasium\n",
    "from gymnasium.spaces import Dict, Discrete, Box\n",
    "from minigrid.core.constants import COLOR_NAMES\n",
    "from minigrid.core.constants import DIR_TO_VEC\n",
    "from minigrid.core.grid import Grid\n",
    "from minigrid.core.actions import Actions\n",
    "from minigrid.core.mission import MissionSpace\n",
    "from minigrid.core.world_object import Door, Goal, Key, Wall\n",
    "from minigrid.manual_control import ManualControl\n",
    "from minigrid.minigrid_env import MiniGridEnv\n",
    "from gymnasium.utils.play import play\n",
    "import pandas as pd\n",
    "# Visualization imports\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleEnv(MiniGridEnv):\n",
    "    def __init__(\n",
    "            self, \n",
    "            size=10, \n",
    "            agent_start_pos=(1, 8), \n",
    "            agent_start_dir=0, \n",
    "            max_steps=1000, \n",
    "            **kwargs,\n",
    "    ):\n",
    "        self.agent_start_pos = agent_start_pos\n",
    "        self.agent_start_dir = agent_start_dir\n",
    "        self.goal_pos = (8, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
    "\n",
    "        super().__init__(\n",
    "            mission_space=mission_space,\n",
    "            grid_size=size,\n",
    "            max_steps=max_steps,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "    @staticmethod\n",
    "    def _gen_mission():\n",
    "        return \"Find the shortest path\"\n",
    "\n",
    "    def _gen_grid(self, width, height):\n",
    "        #create gird\n",
    "        self.grid = Grid(width, height)\n",
    "        #place barrier\n",
    "        self.grid.wall_rect(0, 0, width, height)\n",
    "        #place goal\n",
    "        self.put_obj(Goal(), 8, 1)\n",
    "        #place walls\n",
    "        for i in range(1, width // 2):\n",
    "            self.grid.set(i, width - 4, Wall())\n",
    "            self.grid.set(i + width // 2 - 1, width - 7, Wall())\n",
    "        #place agent\n",
    "        if self.agent_start_pos is not None:\n",
    "            self.agent_pos = self.agent_start_pos #check this\n",
    "            self.agent_dir = self.agent_start_dir\n",
    "        else:\n",
    "            self.place_agent()\n",
    "\n",
    "        self.mission = \"find the shortest path\"\n",
    "    \n",
    "    def count_states(self):\n",
    "        free_cells = sum(1 for x in range(self.grid.width)\n",
    "                      for y in range(self.grid.height)\n",
    "                      if not self.grid.get(x, y)) * 4\n",
    "        return free_cells \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SimpleEnv(render_mode= None)\n",
    "env.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs shape after step: (7, 7, 3)\n"
     ]
    }
   ],
   "source": [
    "action = 0\n",
    "obs, _, _, _, _ = env.step(action)\n",
    "print(\"Obs shape after step:\", obs[\"image\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs shape after step: (7, 7, 3)\n"
     ]
    }
   ],
   "source": [
    "action = 0\n",
    "obs1, _, _, _, _ = env.step(action)\n",
    "print(\"Obs shape after step:\", obs[\"image\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False,  True,  True],\n",
       "        [False,  True,  True]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[\"image\"] == obs1[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict('direction': Discrete(4), 'image': Box(0, 255, (7, 7, 3), uint8), 'mission': MissionSpace(<function SimpleEnv._gen_mission at 0x16c611440>, None))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGridFlatImg(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Keep only the 7x7 RGB image from a MiniGrid Dict observation.\n",
    "    Output: 147-dim float32 vector in [0, 1].\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        # initialise the parent ObservationWrapper so it can do its bookkeeping\n",
    "        super().__init__(env)\n",
    "\n",
    "        img_size = np.prod(env.observation_space[\"image\"].shape)   # 7*7*3 = 147\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0.0, high=1.0, shape=(img_size,), dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        img_flat = obs[\"image\"].astype(np.float32).flatten() / 255.0\n",
    "        return img_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGridReward(gym.Wrapper):\n",
    "    def __init__(self, env, goal_states):\n",
    "        super().__init__(env)\n",
    "        self.goal_states = set(goal_states)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, _, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        # access agent position after the transition\n",
    "        x, y = self.env.unwrapped.agent_pos\n",
    "        next_state = (x, y)\n",
    "\n",
    "        rew = 0 if next_state in self.goal_states else -1\n",
    "        done = terminated or truncated or (rew == 0)\n",
    "\n",
    "        return obs, rew, done, truncated, info\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_wrapped = MiniGridFlatImg(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_wrapped.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 0\n",
    "obs, _, _, _, _ = env_wrapped.step(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 0\n",
    "obs1, _, _, _, _ = env_wrapped.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0.0, 1.0, (147,), float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_wrapped.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_wrapped.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_wrapped_rew= MiniGridReward(env_wrapped, goal_states = [(8, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_wrapped_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = env_wrapped_rew.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(obs), \u001b[43mobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m) \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(type(obs), obs.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(sizes, activation = nn.Tanh, output_activation = nn.Identity):\n",
    "    layers = []\n",
    "    for i in range(len(sizes) - 1):\n",
    "        act = activation if i < len(sizes) -2 else output_activation #everything but last layer has activation, outherwise output\n",
    "        layers += [nn.Linear(sizes [i], sizes[i +1], act())]\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env_name = env_wrapped_rew, hidden_sizes = [32], lr = 1e-2, epochs = 50, batch_size = 50, render = False):\n",
    "\n",
    "    env = env_name\n",
    "\n",
    "    obs_dim = env.observation_space.shape[0] \n",
    "    # print(\"obs_dim:\", obs_dim)\n",
    "    n_acts = env.action_space.n\n",
    "    # print(\"n_acts:\", n_acts)\n",
    "\n",
    "\n",
    "\n",
    "    #generate polucy network\n",
    "    logits_net = mlp(sizes = [obs_dim] + hidden_sizes + [n_acts])\n",
    "\n",
    "    #takes policy network and returns action distribution\n",
    "    def get_policy(obs):\n",
    "        logits = logits_net(obs)\n",
    "        return Categorical(logits = logits)\n",
    "\n",
    "    #samples actions from the action distrubution from the policy network\n",
    "    def get_action(obs):\n",
    "        return get_policy(obs).sample().item()\n",
    "    \n",
    "\n",
    "    # make loss function whose gradient, for the right data, is policy gradient\n",
    "    def compute_loss(obs, act, weights):\n",
    "        logp = get_policy(obs).log_prob(act)\n",
    "        return -(logp * weights).mean()\n",
    "\n",
    "      # make optimizer\n",
    "    optimizer = Adam(logits_net.parameters(), lr=lr)\n",
    "\n",
    "    def train_one_epoch():\n",
    "        # make some empty lists for logging.\n",
    "        batch_obs = []          # for observations\n",
    "        batch_acts = []         # for actions\n",
    "        batch_weights = []      # for R(tau) weighting in policy gradient\n",
    "        batch_rets = []         # for measuring episode returns\n",
    "        batch_lens = []         # for measuring episode lengths\n",
    "\n",
    "        # reset episode-specific variables\n",
    "        obs, info = env.reset()      # first obs comes from starting distribution\n",
    "        # print(\"obs shape:\", obs.shape, \"obs type:\", type(obs))\n",
    "        done = False            # signal from environment that episode is over\n",
    "        ep_rews = []            # list for rewards accrued throughout ep\n",
    "\n",
    "        # render first episode of each epoch\n",
    "        finished_rendering_this_epoch = False\n",
    "\n",
    "        # collect experience by acting in the environment with current policy\n",
    "        while True:\n",
    "\n",
    "            # rendering\n",
    "            if (not finished_rendering_this_epoch) and render:\n",
    "                env.render()\n",
    "            # print(\"obs shape:\", obs.shape, \"obs type:\", type(obs))\n",
    "            # save obs\n",
    "            batch_obs.append(obs.copy())\n",
    "\n",
    "            # act in the environment\n",
    "            act = get_action(torch.as_tensor(obs, dtype=torch.float32))\n",
    "            obs, rew, done, _, _ = env.step(act)\n",
    "            \n",
    "\n",
    "            # save action, reward\n",
    "            batch_acts.append(act)\n",
    "            ep_rews.append(rew)\n",
    "\n",
    "            if done:\n",
    "                # if episode is over, record info about episode\n",
    "                ep_ret, ep_len = sum(ep_rews), len(ep_rews)\n",
    "                batch_rets.append(ep_ret)\n",
    "                batch_lens.append(ep_len)\n",
    "\n",
    "                # the weight for each logprob(a|s) is R(tau)\n",
    "                batch_weights += [ep_ret] * ep_len     #why is this the way the setup is, this is where i want to add rewards\n",
    "\n",
    "                # reset episode-specific variables\n",
    "                obs, info  = env.reset()\n",
    "                done = False\n",
    "                ep_rews = []\n",
    "\n",
    "                # won't render again this epoch\n",
    "                finished_rendering_this_epoch = True\n",
    "\n",
    "                # end experience loop if we have enough of it\n",
    "                if len(batch_obs) > batch_size:\n",
    "                    break\n",
    "        # take a single policy gradient update step\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = compute_loss(obs=torch.as_tensor(batch_obs, dtype=torch.float32),\n",
    "                                  act=torch.as_tensor(batch_acts, dtype=torch.int32),\n",
    "                                  weights=torch.as_tensor(batch_weights, dtype=torch.float32)\n",
    "                                  )\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        return batch_loss, batch_rets, batch_lens\n",
    "\n",
    "    # training loop\n",
    "    for i in range(epochs):\n",
    "        batch_loss, batch_rets, batch_lens = train_one_epoch()\n",
    "        print('epoch: %3d \\t loss: %.3f \\t return: %.3f \\t ep_len: %.3f'%\n",
    "                (i, batch_loss, np.mean(batch_rets), np.mean(batch_lens)))\n",
    "        \n",
    "    return logits_net\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_wrapped_rew.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 \t loss: -916.581 \t return: -713.375 \t ep_len: 713.875\n",
      "epoch:   1 \t loss: -1083.559 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch:   2 \t loss: -1034.143 \t return: -902.167 \t ep_len: 902.333\n",
      "epoch:   3 \t loss: -951.360 \t return: -790.000 \t ep_len: 790.429\n",
      "epoch:   4 \t loss: -944.680 \t return: -800.714 \t ep_len: 801.143\n",
      "epoch:   5 \t loss: -923.436 \t return: -827.000 \t ep_len: 827.571\n",
      "epoch:   6 \t loss: -798.241 \t return: -642.667 \t ep_len: 643.333\n",
      "epoch:   7 \t loss: -1023.132 \t return: -893.667 \t ep_len: 893.833\n",
      "epoch:   8 \t loss: -1009.061 \t return: -843.857 \t ep_len: 844.143\n",
      "epoch:   9 \t loss: -985.804 \t return: -834.714 \t ep_len: 835.143\n",
      "epoch:  10 \t loss: -1008.750 \t return: -933.333 \t ep_len: 933.500\n",
      "epoch:  11 \t loss: -1024.364 \t return: -955.833 \t ep_len: 956.000\n",
      "epoch:  12 \t loss: -974.409 \t return: -893.500 \t ep_len: 894.000\n",
      "epoch:  13 \t loss: -1003.632 \t return: -945.333 \t ep_len: 945.667\n",
      "epoch:  14 \t loss: -927.076 \t return: -841.667 \t ep_len: 842.167\n",
      "epoch:  15 \t loss: -989.590 \t return: -892.333 \t ep_len: 892.667\n",
      "epoch:  16 \t loss: -955.751 \t return: -863.000 \t ep_len: 863.500\n",
      "epoch:  17 \t loss: -947.678 \t return: -803.857 \t ep_len: 804.286\n",
      "epoch:  18 \t loss: -939.444 \t return: -844.000 \t ep_len: 844.571\n",
      "epoch:  19 \t loss: -988.735 \t return: -885.167 \t ep_len: 885.500\n",
      "epoch:  20 \t loss: -953.204 \t return: -804.857 \t ep_len: 805.286\n",
      "epoch:  21 \t loss: -992.089 \t return: -850.571 \t ep_len: 850.857\n",
      "epoch:  22 \t loss: -972.144 \t return: -833.667 \t ep_len: 834.000\n",
      "epoch:  23 \t loss: -917.750 \t return: -804.143 \t ep_len: 804.714\n",
      "epoch:  24 \t loss: -1019.912 \t return: -843.333 \t ep_len: 844.000\n",
      "epoch:  25 \t loss: -913.985 \t return: -751.429 \t ep_len: 752.000\n",
      "epoch:  26 \t loss: -919.636 \t return: -743.625 \t ep_len: 744.250\n",
      "epoch:  27 \t loss: -996.031 \t return: -824.000 \t ep_len: 824.286\n",
      "epoch:  28 \t loss: -1044.490 \t return: -958.000 \t ep_len: 958.167\n",
      "epoch:  29 \t loss: -795.196 \t return: -632.625 \t ep_len: 633.375\n",
      "epoch:  30 \t loss: -1034.848 \t return: -927.667 \t ep_len: 927.833\n",
      "epoch:  31 \t loss: -1049.594 \t return: -961.333 \t ep_len: 961.500\n",
      "epoch:  32 \t loss: -936.550 \t return: -715.500 \t ep_len: 716.125\n",
      "epoch:  33 \t loss: -928.921 \t return: -714.750 \t ep_len: 715.375\n",
      "epoch:  34 \t loss: -895.504 \t return: -739.125 \t ep_len: 739.875\n",
      "epoch:  35 \t loss: -994.974 \t return: -831.000 \t ep_len: 831.286\n",
      "epoch:  36 \t loss: -836.884 \t return: -654.000 \t ep_len: 654.625\n",
      "epoch:  37 \t loss: -872.433 \t return: -743.000 \t ep_len: 743.714\n",
      "epoch:  38 \t loss: -957.647 \t return: -737.571 \t ep_len: 738.143\n",
      "epoch:  39 \t loss: -892.112 \t return: -719.857 \t ep_len: 720.571\n",
      "epoch:  40 \t loss: -1069.671 \t return: -992.833 \t ep_len: 993.000\n",
      "epoch:  41 \t loss: -865.396 \t return: -714.286 \t ep_len: 714.857\n",
      "epoch:  42 \t loss: -857.760 \t return: -743.857 \t ep_len: 744.714\n",
      "epoch:  43 \t loss: -887.346 \t return: -715.143 \t ep_len: 715.714\n",
      "epoch:  44 \t loss: -949.019 \t return: -758.000 \t ep_len: 758.571\n",
      "epoch:  45 \t loss: -942.131 \t return: -813.429 \t ep_len: 814.000\n",
      "epoch:  46 \t loss: -843.619 \t return: -668.500 \t ep_len: 669.250\n",
      "epoch:  47 \t loss: -1025.193 \t return: -930.333 \t ep_len: 930.667\n",
      "epoch:  48 \t loss: -1039.633 \t return: -855.429 \t ep_len: 855.857\n",
      "epoch:  49 \t loss: -945.598 \t return: -855.333 \t ep_len: 855.833\n",
      "epoch:  50 \t loss: -929.064 \t return: -781.714 \t ep_len: 782.143\n",
      "epoch:  51 \t loss: -956.212 \t return: -856.286 \t ep_len: 856.857\n",
      "epoch:  52 \t loss: -877.285 \t return: -756.000 \t ep_len: 756.714\n",
      "epoch:  53 \t loss: -990.065 \t return: -852.571 \t ep_len: 852.857\n",
      "epoch:  54 \t loss: -966.967 \t return: -864.000 \t ep_len: 864.500\n",
      "epoch:  55 \t loss: -977.861 \t return: -856.833 \t ep_len: 857.333\n",
      "epoch:  56 \t loss: -877.441 \t return: -610.778 \t ep_len: 611.444\n",
      "epoch:  57 \t loss: -946.469 \t return: -728.429 \t ep_len: 728.857\n",
      "epoch:  58 \t loss: -899.408 \t return: -735.429 \t ep_len: 736.000\n",
      "epoch:  59 \t loss: -1034.262 \t return: -921.167 \t ep_len: 921.333\n",
      "epoch:  60 \t loss: -915.430 \t return: -721.500 \t ep_len: 722.000\n",
      "epoch:  61 \t loss: -923.711 \t return: -751.286 \t ep_len: 752.000\n",
      "epoch:  62 \t loss: -901.633 \t return: -777.714 \t ep_len: 778.286\n",
      "epoch:  63 \t loss: -949.571 \t return: -752.571 \t ep_len: 753.000\n",
      "epoch:  64 \t loss: -1008.819 \t return: -877.167 \t ep_len: 877.500\n",
      "epoch:  65 \t loss: -1047.882 \t return: -878.833 \t ep_len: 879.000\n",
      "epoch:  66 \t loss: -1017.305 \t return: -874.000 \t ep_len: 874.333\n",
      "epoch:  67 \t loss: -1040.097 \t return: -919.833 \t ep_len: 920.167\n",
      "epoch:  68 \t loss: -1042.760 \t return: -899.333 \t ep_len: 899.500\n",
      "epoch:  69 \t loss: -1004.813 \t return: -833.333 \t ep_len: 833.667\n",
      "epoch:  70 \t loss: -974.832 \t return: -817.429 \t ep_len: 818.000\n",
      "epoch:  71 \t loss: -990.871 \t return: -815.000 \t ep_len: 815.429\n",
      "epoch:  72 \t loss: -991.911 \t return: -863.833 \t ep_len: 864.167\n",
      "epoch:  73 \t loss: -954.951 \t return: -800.429 \t ep_len: 800.857\n",
      "epoch:  74 \t loss: -1005.533 \t return: -822.571 \t ep_len: 822.857\n",
      "epoch:  75 \t loss: -1087.295 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch:  76 \t loss: -825.180 \t return: -702.000 \t ep_len: 702.750\n",
      "epoch:  77 \t loss: -993.754 \t return: -873.500 \t ep_len: 873.833\n",
      "epoch:  78 \t loss: -969.083 \t return: -816.571 \t ep_len: 817.000\n",
      "epoch:  79 \t loss: -1029.121 \t return: -864.333 \t ep_len: 864.667\n",
      "epoch:  80 \t loss: -962.073 \t return: -718.286 \t ep_len: 718.857\n",
      "epoch:  81 \t loss: -961.578 \t return: -739.857 \t ep_len: 740.286\n",
      "epoch:  82 \t loss: -1003.895 \t return: -830.857 \t ep_len: 831.143\n",
      "epoch:  83 \t loss: -1046.059 \t return: -921.667 \t ep_len: 921.833\n",
      "epoch:  84 \t loss: -955.339 \t return: -764.286 \t ep_len: 764.714\n",
      "epoch:  85 \t loss: -1070.323 \t return: -978.000 \t ep_len: 978.167\n",
      "epoch:  86 \t loss: -1021.905 \t return: -913.333 \t ep_len: 913.667\n",
      "epoch:  87 \t loss: -1061.916 \t return: -967.667 \t ep_len: 968.000\n",
      "epoch:  88 \t loss: -989.099 \t return: -852.667 \t ep_len: 853.000\n",
      "epoch:  89 \t loss: -1032.398 \t return: -885.333 \t ep_len: 885.667\n",
      "epoch:  90 \t loss: -1016.300 \t return: -793.000 \t ep_len: 793.286\n",
      "epoch:  91 \t loss: -1017.028 \t return: -872.167 \t ep_len: 872.667\n",
      "epoch:  92 \t loss: -1013.970 \t return: -882.333 \t ep_len: 882.667\n",
      "epoch:  93 \t loss: -1052.830 \t return: -957.000 \t ep_len: 957.333\n",
      "epoch:  94 \t loss: -960.185 \t return: -743.750 \t ep_len: 744.250\n",
      "epoch:  95 \t loss: -937.083 \t return: -631.625 \t ep_len: 632.125\n",
      "epoch:  96 \t loss: -1029.028 \t return: -923.333 \t ep_len: 923.667\n",
      "epoch:  97 \t loss: -930.125 \t return: -738.625 \t ep_len: 739.125\n",
      "epoch:  98 \t loss: -973.031 \t return: -872.000 \t ep_len: 872.500\n",
      "epoch:  99 \t loss: -999.662 \t return: -839.000 \t ep_len: 839.429\n",
      "epoch: 100 \t loss: -1086.080 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 101 \t loss: -995.360 \t return: -880.000 \t ep_len: 880.333\n",
      "epoch: 102 \t loss: -996.258 \t return: -842.286 \t ep_len: 842.571\n",
      "epoch: 103 \t loss: -968.300 \t return: -853.333 \t ep_len: 853.833\n",
      "epoch: 104 \t loss: -985.827 \t return: -887.500 \t ep_len: 888.000\n",
      "epoch: 105 \t loss: -1016.676 \t return: -919.833 \t ep_len: 920.167\n",
      "epoch: 106 \t loss: -844.819 \t return: -599.556 \t ep_len: 600.222\n",
      "epoch: 107 \t loss: -960.571 \t return: -789.714 \t ep_len: 790.286\n",
      "epoch: 108 \t loss: -958.660 \t return: -837.333 \t ep_len: 837.833\n",
      "epoch: 109 \t loss: -989.654 \t return: -858.333 \t ep_len: 858.667\n",
      "epoch: 110 \t loss: -1049.008 \t return: -952.167 \t ep_len: 952.333\n",
      "epoch: 111 \t loss: -887.778 \t return: -757.714 \t ep_len: 758.429\n",
      "epoch: 112 \t loss: -1007.652 \t return: -895.000 \t ep_len: 895.333\n",
      "epoch: 113 \t loss: -897.536 \t return: -747.857 \t ep_len: 748.571\n",
      "epoch: 114 \t loss: -1012.879 \t return: -882.000 \t ep_len: 882.333\n",
      "epoch: 115 \t loss: -878.984 \t return: -691.125 \t ep_len: 691.750\n",
      "epoch: 116 \t loss: -984.147 \t return: -876.833 \t ep_len: 877.333\n",
      "epoch: 117 \t loss: -1046.122 \t return: -864.333 \t ep_len: 864.667\n",
      "epoch: 118 \t loss: -1062.819 \t return: -856.333 \t ep_len: 856.500\n",
      "epoch: 119 \t loss: -968.291 \t return: -781.143 \t ep_len: 781.571\n",
      "epoch: 120 \t loss: -811.455 \t return: -641.625 \t ep_len: 642.375\n",
      "epoch: 121 \t loss: -977.766 \t return: -823.000 \t ep_len: 823.429\n",
      "epoch: 122 \t loss: -1041.189 \t return: -929.833 \t ep_len: 930.000\n",
      "epoch: 123 \t loss: -991.695 \t return: -801.143 \t ep_len: 801.571\n",
      "epoch: 124 \t loss: -984.278 \t return: -843.000 \t ep_len: 843.333\n",
      "epoch: 125 \t loss: -961.285 \t return: -793.429 \t ep_len: 793.857\n",
      "epoch: 126 \t loss: -959.401 \t return: -844.143 \t ep_len: 844.571\n",
      "epoch: 127 \t loss: -904.890 \t return: -680.750 \t ep_len: 681.250\n",
      "epoch: 128 \t loss: -881.719 \t return: -725.000 \t ep_len: 725.750\n",
      "epoch: 129 \t loss: -1021.641 \t return: -890.833 \t ep_len: 891.167\n",
      "epoch: 130 \t loss: -985.606 \t return: -843.000 \t ep_len: 843.333\n",
      "epoch: 131 \t loss: -1041.851 \t return: -964.667 \t ep_len: 965.000\n",
      "epoch: 132 \t loss: -952.756 \t return: -729.714 \t ep_len: 730.143\n",
      "epoch: 133 \t loss: -930.869 \t return: -723.714 \t ep_len: 724.286\n",
      "epoch: 134 \t loss: -1041.734 \t return: -843.000 \t ep_len: 843.333\n",
      "epoch: 135 \t loss: -981.635 \t return: -877.333 \t ep_len: 877.833\n",
      "epoch: 136 \t loss: -942.929 \t return: -719.143 \t ep_len: 719.571\n",
      "epoch: 137 \t loss: -975.668 \t return: -863.500 \t ep_len: 863.833\n",
      "epoch: 138 \t loss: -834.944 \t return: -665.500 \t ep_len: 666.250\n",
      "epoch: 139 \t loss: -985.240 \t return: -822.429 \t ep_len: 822.857\n",
      "epoch: 140 \t loss: -982.051 \t return: -868.667 \t ep_len: 869.000\n",
      "epoch: 141 \t loss: -862.135 \t return: -713.857 \t ep_len: 714.571\n",
      "epoch: 142 \t loss: -830.513 \t return: -660.333 \t ep_len: 661.000\n",
      "epoch: 143 \t loss: -943.305 \t return: -813.714 \t ep_len: 814.286\n",
      "epoch: 144 \t loss: -956.188 \t return: -833.333 \t ep_len: 834.000\n",
      "epoch: 145 \t loss: -861.022 \t return: -699.250 \t ep_len: 700.000\n",
      "epoch: 146 \t loss: -808.146 \t return: -612.333 \t ep_len: 613.000\n",
      "epoch: 147 \t loss: -1042.631 \t return: -960.833 \t ep_len: 961.333\n",
      "epoch: 148 \t loss: -854.481 \t return: -584.556 \t ep_len: 585.222\n",
      "epoch: 149 \t loss: -891.957 \t return: -739.571 \t ep_len: 740.143\n",
      "epoch: 150 \t loss: -799.847 \t return: -566.444 \t ep_len: 567.222\n",
      "epoch: 151 \t loss: -963.700 \t return: -828.857 \t ep_len: 829.571\n",
      "epoch: 152 \t loss: -1047.918 \t return: -863.500 \t ep_len: 863.833\n",
      "epoch: 153 \t loss: -991.445 \t return: -790.286 \t ep_len: 790.714\n",
      "epoch: 154 \t loss: -838.364 \t return: -643.250 \t ep_len: 643.875\n",
      "epoch: 155 \t loss: -961.015 \t return: -726.375 \t ep_len: 726.875\n",
      "epoch: 156 \t loss: -890.833 \t return: -738.000 \t ep_len: 738.571\n",
      "epoch: 157 \t loss: -1030.224 \t return: -878.667 \t ep_len: 879.000\n",
      "epoch: 158 \t loss: -866.212 \t return: -713.375 \t ep_len: 714.000\n",
      "epoch: 159 \t loss: -987.799 \t return: -891.333 \t ep_len: 891.833\n",
      "epoch: 160 \t loss: -921.849 \t return: -739.714 \t ep_len: 740.286\n",
      "epoch: 161 \t loss: -962.378 \t return: -853.167 \t ep_len: 853.667\n",
      "epoch: 162 \t loss: -805.051 \t return: -655.375 \t ep_len: 656.125\n",
      "epoch: 163 \t loss: -984.710 \t return: -877.833 \t ep_len: 878.333\n",
      "epoch: 164 \t loss: -1049.149 \t return: -864.000 \t ep_len: 864.333\n",
      "epoch: 165 \t loss: -871.100 \t return: -651.500 \t ep_len: 652.125\n",
      "epoch: 166 \t loss: -951.028 \t return: -776.000 \t ep_len: 776.429\n",
      "epoch: 167 \t loss: -928.497 \t return: -759.714 \t ep_len: 760.286\n",
      "epoch: 168 \t loss: -878.904 \t return: -743.875 \t ep_len: 744.500\n",
      "epoch: 169 \t loss: -1005.317 \t return: -782.143 \t ep_len: 782.571\n",
      "epoch: 170 \t loss: -806.143 \t return: -679.000 \t ep_len: 679.750\n",
      "epoch: 171 \t loss: -922.454 \t return: -800.143 \t ep_len: 800.714\n",
      "epoch: 172 \t loss: -1082.096 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 173 \t loss: -984.925 \t return: -834.429 \t ep_len: 834.857\n",
      "epoch: 174 \t loss: -919.753 \t return: -744.857 \t ep_len: 745.429\n",
      "epoch: 175 \t loss: -995.970 \t return: -876.500 \t ep_len: 876.833\n",
      "epoch: 176 \t loss: -1009.771 \t return: -867.500 \t ep_len: 867.833\n",
      "epoch: 177 \t loss: -1011.141 \t return: -747.125 \t ep_len: 747.500\n",
      "epoch: 178 \t loss: -933.674 \t return: -814.429 \t ep_len: 815.000\n",
      "epoch: 179 \t loss: -1021.708 \t return: -828.286 \t ep_len: 828.571\n",
      "epoch: 180 \t loss: -896.736 \t return: -695.125 \t ep_len: 695.750\n",
      "epoch: 181 \t loss: -942.963 \t return: -801.429 \t ep_len: 802.000\n",
      "epoch: 182 \t loss: -1056.490 \t return: -966.333 \t ep_len: 966.500\n",
      "epoch: 183 \t loss: -969.575 \t return: -827.000 \t ep_len: 827.429\n",
      "epoch: 184 \t loss: -1064.585 \t return: -858.667 \t ep_len: 858.833\n",
      "epoch: 185 \t loss: -1012.792 \t return: -857.000 \t ep_len: 857.333\n",
      "epoch: 186 \t loss: -1015.597 \t return: -867.833 \t ep_len: 868.167\n",
      "epoch: 187 \t loss: -921.904 \t return: -690.250 \t ep_len: 690.750\n",
      "epoch: 188 \t loss: -943.529 \t return: -723.571 \t ep_len: 724.143\n",
      "epoch: 189 \t loss: -950.697 \t return: -789.571 \t ep_len: 790.000\n",
      "epoch: 190 \t loss: -1009.848 \t return: -903.667 \t ep_len: 904.000\n",
      "epoch: 191 \t loss: -994.018 \t return: -865.667 \t ep_len: 866.000\n",
      "epoch: 192 \t loss: -996.889 \t return: -852.500 \t ep_len: 852.833\n",
      "epoch: 193 \t loss: -1040.662 \t return: -929.833 \t ep_len: 930.000\n",
      "epoch: 194 \t loss: -961.340 \t return: -800.714 \t ep_len: 801.143\n",
      "epoch: 195 \t loss: -965.630 \t return: -777.571 \t ep_len: 778.000\n",
      "epoch: 196 \t loss: -908.260 \t return: -686.625 \t ep_len: 687.250\n",
      "epoch: 197 \t loss: -946.838 \t return: -795.857 \t ep_len: 796.429\n",
      "epoch: 198 \t loss: -969.758 \t return: -836.000 \t ep_len: 836.571\n",
      "epoch: 199 \t loss: -1042.734 \t return: -956.167 \t ep_len: 956.833\n",
      "epoch: 200 \t loss: -966.824 \t return: -755.143 \t ep_len: 755.571\n",
      "epoch: 201 \t loss: -843.601 \t return: -612.333 \t ep_len: 613.111\n",
      "epoch: 202 \t loss: -988.382 \t return: -854.333 \t ep_len: 854.667\n",
      "epoch: 203 \t loss: -873.357 \t return: -724.571 \t ep_len: 725.286\n",
      "epoch: 204 \t loss: -1017.107 \t return: -906.500 \t ep_len: 906.833\n",
      "epoch: 205 \t loss: -1017.423 \t return: -841.833 \t ep_len: 842.167\n",
      "epoch: 206 \t loss: -982.005 \t return: -862.667 \t ep_len: 863.167\n",
      "epoch: 207 \t loss: -1061.113 \t return: -968.833 \t ep_len: 969.000\n",
      "epoch: 208 \t loss: -1018.101 \t return: -869.833 \t ep_len: 870.167\n",
      "epoch: 209 \t loss: -1060.694 \t return: -972.500 \t ep_len: 973.000\n",
      "epoch: 210 \t loss: -822.867 \t return: -638.500 \t ep_len: 639.250\n",
      "epoch: 211 \t loss: -1019.524 \t return: -773.143 \t ep_len: 773.429\n",
      "epoch: 212 \t loss: -998.609 \t return: -904.000 \t ep_len: 904.500\n",
      "epoch: 213 \t loss: -1000.066 \t return: -850.143 \t ep_len: 850.429\n",
      "epoch: 214 \t loss: -854.579 \t return: -669.500 \t ep_len: 670.250\n",
      "epoch: 215 \t loss: -928.705 \t return: -752.000 \t ep_len: 752.571\n",
      "epoch: 216 \t loss: -938.719 \t return: -747.286 \t ep_len: 747.714\n",
      "epoch: 217 \t loss: -979.320 \t return: -855.167 \t ep_len: 855.667\n",
      "epoch: 218 \t loss: -854.477 \t return: -564.556 \t ep_len: 565.222\n",
      "epoch: 219 \t loss: -1009.107 \t return: -883.333 \t ep_len: 883.667\n",
      "epoch: 220 \t loss: -885.425 \t return: -763.714 \t ep_len: 764.429\n",
      "epoch: 221 \t loss: -984.998 \t return: -854.571 \t ep_len: 855.000\n",
      "epoch: 222 \t loss: -1076.834 \t return: -1000.000 \t ep_len: 1000.000\n",
      "epoch: 223 \t loss: -915.549 \t return: -696.625 \t ep_len: 697.125\n",
      "epoch: 224 \t loss: -877.744 \t return: -631.111 \t ep_len: 631.667\n",
      "epoch: 225 \t loss: -850.845 \t return: -686.875 \t ep_len: 687.625\n",
      "epoch: 226 \t loss: -639.758 \t return: -461.182 \t ep_len: 462.091\n",
      "epoch: 227 \t loss: -991.681 \t return: -856.000 \t ep_len: 856.167\n",
      "epoch: 228 \t loss: -801.399 \t return: -647.625 \t ep_len: 648.375\n",
      "epoch: 229 \t loss: -765.160 \t return: -598.600 \t ep_len: 599.300\n",
      "epoch: 230 \t loss: -762.520 \t return: -674.375 \t ep_len: 675.000\n",
      "epoch: 231 \t loss: -723.100 \t return: -588.667 \t ep_len: 589.444\n",
      "epoch: 232 \t loss: -627.327 \t return: -479.091 \t ep_len: 479.909\n",
      "epoch: 233 \t loss: -651.935 \t return: -508.909 \t ep_len: 509.727\n",
      "epoch: 234 \t loss: -557.388 \t return: -443.846 \t ep_len: 444.692\n",
      "epoch: 235 \t loss: -561.828 \t return: -472.364 \t ep_len: 473.273\n",
      "epoch: 236 \t loss: -631.717 \t return: -556.556 \t ep_len: 557.333\n",
      "epoch: 237 \t loss: -757.795 \t return: -839.000 \t ep_len: 839.429\n",
      "epoch: 238 \t loss: -614.302 \t return: -486.455 \t ep_len: 487.182\n",
      "epoch: 239 \t loss: -535.411 \t return: -445.417 \t ep_len: 446.250\n",
      "epoch: 240 \t loss: -533.407 \t return: -565.889 \t ep_len: 566.778\n",
      "epoch: 241 \t loss: -458.914 \t return: -466.000 \t ep_len: 467.000\n",
      "epoch: 242 \t loss: -487.122 \t return: -428.750 \t ep_len: 429.667\n",
      "epoch: 243 \t loss: -607.325 \t return: -628.750 \t ep_len: 629.500\n",
      "epoch: 244 \t loss: -596.405 \t return: -665.125 \t ep_len: 665.875\n",
      "epoch: 245 \t loss: -553.332 \t return: -592.444 \t ep_len: 593.222\n",
      "epoch: 246 \t loss: -575.830 \t return: -584.500 \t ep_len: 585.200\n",
      "epoch: 247 \t loss: -523.853 \t return: -508.700 \t ep_len: 509.600\n",
      "epoch: 248 \t loss: -607.712 \t return: -595.000 \t ep_len: 595.778\n",
      "epoch: 249 \t loss: -333.668 \t return: -356.429 \t ep_len: 357.429\n",
      "epoch: 250 \t loss: -505.692 \t return: -510.800 \t ep_len: 511.700\n",
      "epoch: 251 \t loss: -506.648 \t return: -474.091 \t ep_len: 475.000\n",
      "epoch: 252 \t loss: -438.072 \t return: -433.917 \t ep_len: 434.833\n",
      "epoch: 253 \t loss: -361.154 \t return: -406.154 \t ep_len: 407.077\n",
      "epoch: 254 \t loss: -440.290 \t return: -585.400 \t ep_len: 586.300\n",
      "epoch: 255 \t loss: -402.766 \t return: -502.700 \t ep_len: 503.500\n",
      "epoch: 256 \t loss: -285.363 \t return: -375.286 \t ep_len: 376.286\n",
      "epoch: 257 \t loss: -418.273 \t return: -556.200 \t ep_len: 556.900\n",
      "epoch: 258 \t loss: -413.732 \t return: -572.333 \t ep_len: 573.111\n",
      "epoch: 259 \t loss: -396.168 \t return: -590.444 \t ep_len: 591.222\n",
      "epoch: 260 \t loss: -390.221 \t return: -548.700 \t ep_len: 549.600\n",
      "epoch: 261 \t loss: -349.120 \t return: -435.333 \t ep_len: 436.250\n",
      "epoch: 262 \t loss: -357.044 \t return: -380.200 \t ep_len: 381.067\n",
      "epoch: 263 \t loss: -432.746 \t return: -419.500 \t ep_len: 420.417\n",
      "epoch: 264 \t loss: -377.045 \t return: -414.500 \t ep_len: 415.500\n",
      "epoch: 265 \t loss: -512.867 \t return: -583.111 \t ep_len: 583.778\n",
      "epoch: 266 \t loss: -479.354 \t return: -462.545 \t ep_len: 463.364\n",
      "epoch: 267 \t loss: -442.962 \t return: -395.769 \t ep_len: 396.769\n",
      "epoch: 268 \t loss: -323.087 \t return: -285.333 \t ep_len: 286.333\n",
      "epoch: 269 \t loss: -638.052 \t return: -670.000 \t ep_len: 670.625\n",
      "epoch: 270 \t loss: -477.259 \t return: -359.467 \t ep_len: 360.400\n",
      "epoch: 271 \t loss: -483.576 \t return: -454.000 \t ep_len: 455.000\n",
      "epoch: 272 \t loss: -570.330 \t return: -501.100 \t ep_len: 501.900\n",
      "epoch: 273 \t loss: -593.351 \t return: -573.667 \t ep_len: 574.556\n",
      "epoch: 274 \t loss: -304.408 \t return: -294.765 \t ep_len: 295.765\n",
      "epoch: 275 \t loss: -360.751 \t return: -330.375 \t ep_len: 331.375\n",
      "epoch: 276 \t loss: -383.244 \t return: -383.923 \t ep_len: 384.923\n",
      "epoch: 277 \t loss: -537.820 \t return: -459.500 \t ep_len: 460.417\n",
      "epoch: 278 \t loss: -510.668 \t return: -478.250 \t ep_len: 479.250\n",
      "epoch: 279 \t loss: -472.892 \t return: -423.750 \t ep_len: 424.667\n",
      "epoch: 280 \t loss: -484.934 \t return: -395.154 \t ep_len: 396.000\n",
      "epoch: 281 \t loss: -587.176 \t return: -572.200 \t ep_len: 573.000\n",
      "epoch: 282 \t loss: -427.668 \t return: -375.500 \t ep_len: 376.500\n",
      "epoch: 283 \t loss: -371.053 \t return: -318.188 \t ep_len: 319.125\n",
      "epoch: 284 \t loss: -459.982 \t return: -416.833 \t ep_len: 417.750\n",
      "epoch: 285 \t loss: -524.928 \t return: -514.100 \t ep_len: 514.900\n",
      "epoch: 286 \t loss: -495.935 \t return: -526.900 \t ep_len: 527.800\n",
      "epoch: 287 \t loss: -348.911 \t return: -304.882 \t ep_len: 305.824\n",
      "epoch: 288 \t loss: -551.519 \t return: -476.182 \t ep_len: 477.000\n",
      "epoch: 289 \t loss: -356.311 \t return: -401.846 \t ep_len: 402.846\n",
      "epoch: 290 \t loss: -450.647 \t return: -425.167 \t ep_len: 426.000\n",
      "epoch: 291 \t loss: -464.658 \t return: -427.429 \t ep_len: 428.214\n",
      "epoch: 292 \t loss: -467.146 \t return: -600.444 \t ep_len: 601.333\n",
      "epoch: 293 \t loss: -413.032 \t return: -453.818 \t ep_len: 454.727\n",
      "epoch: 294 \t loss: -345.817 \t return: -356.400 \t ep_len: 357.333\n",
      "epoch: 295 \t loss: -419.307 \t return: -445.083 \t ep_len: 446.083\n",
      "epoch: 296 \t loss: -325.562 \t return: -334.176 \t ep_len: 335.118\n",
      "epoch: 297 \t loss: -355.256 \t return: -339.875 \t ep_len: 340.875\n",
      "epoch: 298 \t loss: -345.507 \t return: -380.643 \t ep_len: 381.643\n",
      "epoch: 299 \t loss: -403.957 \t return: -385.538 \t ep_len: 386.462\n",
      "epoch: 300 \t loss: -490.171 \t return: -443.167 \t ep_len: 443.917\n",
      "epoch: 301 \t loss: -391.723 \t return: -359.929 \t ep_len: 360.857\n",
      "epoch: 302 \t loss: -346.304 \t return: -384.538 \t ep_len: 385.462\n",
      "epoch: 303 \t loss: -417.596 \t return: -410.615 \t ep_len: 411.538\n",
      "epoch: 304 \t loss: -490.875 \t return: -562.222 \t ep_len: 563.111\n",
      "epoch: 305 \t loss: -509.292 \t return: -570.667 \t ep_len: 571.556\n",
      "epoch: 306 \t loss: -329.791 \t return: -343.812 \t ep_len: 344.812\n",
      "epoch: 307 \t loss: -440.999 \t return: -383.846 \t ep_len: 384.769\n",
      "epoch: 308 \t loss: -407.609 \t return: -330.750 \t ep_len: 331.688\n",
      "epoch: 309 \t loss: -490.306 \t return: -351.267 \t ep_len: 352.133\n",
      "epoch: 310 \t loss: -516.321 \t return: -518.000 \t ep_len: 518.900\n",
      "epoch: 311 \t loss: -481.197 \t return: -421.077 \t ep_len: 422.000\n",
      "epoch: 312 \t loss: -425.913 \t return: -424.250 \t ep_len: 425.167\n",
      "epoch: 313 \t loss: -389.708 \t return: -343.812 \t ep_len: 344.812\n",
      "epoch: 314 \t loss: -428.696 \t return: -405.077 \t ep_len: 406.077\n",
      "epoch: 315 \t loss: -543.968 \t return: -460.364 \t ep_len: 461.273\n",
      "epoch: 316 \t loss: -475.797 \t return: -444.167 \t ep_len: 445.083\n",
      "epoch: 317 \t loss: -476.999 \t return: -397.154 \t ep_len: 398.000\n",
      "epoch: 318 \t loss: -515.766 \t return: -544.200 \t ep_len: 545.100\n",
      "epoch: 319 \t loss: -445.375 \t return: -334.467 \t ep_len: 335.400\n",
      "epoch: 320 \t loss: -408.224 \t return: -439.583 \t ep_len: 440.500\n",
      "epoch: 321 \t loss: -398.987 \t return: -417.000 \t ep_len: 418.000\n",
      "epoch: 322 \t loss: -504.001 \t return: -525.400 \t ep_len: 526.300\n",
      "epoch: 323 \t loss: -474.690 \t return: -374.786 \t ep_len: 375.643\n",
      "epoch: 324 \t loss: -485.250 \t return: -387.692 \t ep_len: 388.615\n",
      "epoch: 325 \t loss: -443.818 \t return: -395.000 \t ep_len: 396.000\n",
      "epoch: 326 \t loss: -382.629 \t return: -341.400 \t ep_len: 342.400\n",
      "epoch: 327 \t loss: -423.865 \t return: -342.200 \t ep_len: 343.133\n",
      "epoch: 328 \t loss: -520.834 \t return: -432.308 \t ep_len: 433.154\n",
      "epoch: 329 \t loss: -472.296 \t return: -366.133 \t ep_len: 367.067\n",
      "epoch: 330 \t loss: -512.767 \t return: -516.500 \t ep_len: 517.300\n",
      "epoch: 331 \t loss: -333.302 \t return: -286.056 \t ep_len: 287.000\n",
      "epoch: 332 \t loss: -275.162 \t return: -301.353 \t ep_len: 302.353\n",
      "epoch: 333 \t loss: -404.312 \t return: -365.214 \t ep_len: 366.143\n",
      "epoch: 334 \t loss: -368.628 \t return: -336.467 \t ep_len: 337.467\n",
      "epoch: 335 \t loss: -482.273 \t return: -410.385 \t ep_len: 411.231\n",
      "epoch: 336 \t loss: -372.220 \t return: -389.077 \t ep_len: 390.000\n",
      "epoch: 337 \t loss: -356.163 \t return: -378.143 \t ep_len: 379.143\n",
      "epoch: 338 \t loss: -291.297 \t return: -280.778 \t ep_len: 281.778\n",
      "epoch: 339 \t loss: -366.311 \t return: -376.000 \t ep_len: 377.000\n",
      "epoch: 340 \t loss: -393.433 \t return: -359.071 \t ep_len: 360.000\n",
      "epoch: 341 \t loss: -571.724 \t return: -544.100 \t ep_len: 544.800\n",
      "epoch: 342 \t loss: -356.990 \t return: -302.053 \t ep_len: 303.053\n",
      "epoch: 343 \t loss: -364.351 \t return: -321.562 \t ep_len: 322.562\n",
      "epoch: 344 \t loss: -374.300 \t return: -357.067 \t ep_len: 358.000\n",
      "epoch: 345 \t loss: -504.822 \t return: -456.750 \t ep_len: 457.583\n",
      "epoch: 346 \t loss: -342.948 \t return: -290.222 \t ep_len: 291.167\n",
      "epoch: 347 \t loss: -480.765 \t return: -393.385 \t ep_len: 394.308\n",
      "epoch: 348 \t loss: -397.400 \t return: -397.429 \t ep_len: 398.357\n",
      "epoch: 349 \t loss: -396.009 \t return: -396.000 \t ep_len: 396.923\n",
      "epoch: 350 \t loss: -351.679 \t return: -319.375 \t ep_len: 320.375\n",
      "epoch: 351 \t loss: -541.873 \t return: -531.500 \t ep_len: 532.400\n",
      "epoch: 352 \t loss: -522.766 \t return: -381.000 \t ep_len: 381.929\n",
      "epoch: 353 \t loss: -455.684 \t return: -357.214 \t ep_len: 358.143\n",
      "epoch: 354 \t loss: -357.898 \t return: -341.733 \t ep_len: 342.733\n",
      "epoch: 355 \t loss: -409.895 \t return: -314.562 \t ep_len: 315.500\n",
      "epoch: 356 \t loss: -492.001 \t return: -465.273 \t ep_len: 466.273\n",
      "epoch: 357 \t loss: -385.413 \t return: -403.385 \t ep_len: 404.385\n",
      "epoch: 358 \t loss: -387.047 \t return: -285.444 \t ep_len: 286.444\n",
      "epoch: 359 \t loss: -469.714 \t return: -287.556 \t ep_len: 288.500\n",
      "epoch: 360 \t loss: -580.662 \t return: -474.182 \t ep_len: 475.000\n",
      "epoch: 361 \t loss: -603.338 \t return: -436.077 \t ep_len: 436.846\n",
      "epoch: 362 \t loss: -461.169 \t return: -345.000 \t ep_len: 345.933\n",
      "epoch: 363 \t loss: -631.597 \t return: -502.100 \t ep_len: 503.000\n",
      "epoch: 364 \t loss: -532.788 \t return: -336.933 \t ep_len: 337.800\n",
      "epoch: 365 \t loss: -535.179 \t return: -412.429 \t ep_len: 413.286\n",
      "epoch: 366 \t loss: -262.226 \t return: -265.105 \t ep_len: 266.105\n",
      "epoch: 367 \t loss: -586.869 \t return: -436.083 \t ep_len: 436.917\n",
      "epoch: 368 \t loss: -464.583 \t return: -391.385 \t ep_len: 392.308\n",
      "epoch: 369 \t loss: -526.561 \t return: -434.615 \t ep_len: 435.538\n",
      "epoch: 370 \t loss: -446.992 \t return: -383.846 \t ep_len: 384.769\n",
      "epoch: 371 \t loss: -550.421 \t return: -425.154 \t ep_len: 426.077\n",
      "epoch: 372 \t loss: -526.553 \t return: -503.000 \t ep_len: 503.900\n",
      "epoch: 373 \t loss: -564.621 \t return: -422.667 \t ep_len: 423.500\n",
      "epoch: 374 \t loss: -518.824 \t return: -337.533 \t ep_len: 338.400\n",
      "epoch: 375 \t loss: -420.496 \t return: -341.867 \t ep_len: 342.800\n",
      "epoch: 376 \t loss: -474.920 \t return: -480.333 \t ep_len: 481.333\n",
      "epoch: 377 \t loss: -551.287 \t return: -364.933 \t ep_len: 365.800\n",
      "epoch: 378 \t loss: -420.842 \t return: -405.000 \t ep_len: 406.000\n",
      "epoch: 379 \t loss: -499.194 \t return: -390.769 \t ep_len: 391.692\n",
      "epoch: 380 \t loss: -383.482 \t return: -392.000 \t ep_len: 393.000\n",
      "epoch: 381 \t loss: -481.210 \t return: -427.583 \t ep_len: 428.500\n",
      "epoch: 382 \t loss: -409.124 \t return: -363.786 \t ep_len: 364.786\n",
      "epoch: 383 \t loss: -468.082 \t return: -342.765 \t ep_len: 343.647\n",
      "epoch: 384 \t loss: -304.382 \t return: -278.722 \t ep_len: 279.722\n",
      "epoch: 385 \t loss: -321.842 \t return: -299.882 \t ep_len: 300.882\n",
      "epoch: 386 \t loss: -469.096 \t return: -421.417 \t ep_len: 422.417\n",
      "epoch: 387 \t loss: -358.993 \t return: -351.467 \t ep_len: 352.467\n",
      "epoch: 388 \t loss: -499.876 \t return: -366.214 \t ep_len: 367.143\n",
      "epoch: 389 \t loss: -436.205 \t return: -319.625 \t ep_len: 320.562\n",
      "epoch: 390 \t loss: -425.830 \t return: -358.333 \t ep_len: 359.333\n",
      "epoch: 391 \t loss: -393.087 \t return: -308.647 \t ep_len: 309.647\n",
      "epoch: 392 \t loss: -491.059 \t return: -387.538 \t ep_len: 388.462\n",
      "epoch: 393 \t loss: -410.036 \t return: -365.929 \t ep_len: 366.857\n",
      "epoch: 394 \t loss: -411.930 \t return: -362.929 \t ep_len: 363.929\n",
      "epoch: 395 \t loss: -313.006 \t return: -295.056 \t ep_len: 296.056\n",
      "epoch: 396 \t loss: -411.927 \t return: -334.824 \t ep_len: 335.765\n",
      "epoch: 397 \t loss: -322.425 \t return: -249.950 \t ep_len: 250.950\n",
      "epoch: 398 \t loss: -360.496 \t return: -296.111 \t ep_len: 297.111\n",
      "epoch: 399 \t loss: -416.047 \t return: -388.000 \t ep_len: 389.000\n",
      "epoch: 400 \t loss: -367.793 \t return: -353.267 \t ep_len: 354.267\n",
      "epoch: 401 \t loss: -446.204 \t return: -405.154 \t ep_len: 406.077\n",
      "epoch: 402 \t loss: -393.726 \t return: -344.733 \t ep_len: 345.667\n",
      "epoch: 403 \t loss: -368.654 \t return: -383.286 \t ep_len: 384.214\n",
      "epoch: 404 \t loss: -417.637 \t return: -367.929 \t ep_len: 368.786\n",
      "epoch: 405 \t loss: -382.651 \t return: -367.357 \t ep_len: 368.286\n",
      "epoch: 406 \t loss: -399.211 \t return: -371.500 \t ep_len: 372.429\n",
      "epoch: 407 \t loss: -444.873 \t return: -470.364 \t ep_len: 471.273\n",
      "epoch: 408 \t loss: -315.633 \t return: -318.611 \t ep_len: 319.556\n",
      "epoch: 409 \t loss: -342.116 \t return: -357.600 \t ep_len: 358.600\n",
      "epoch: 410 \t loss: -416.299 \t return: -387.071 \t ep_len: 388.000\n",
      "epoch: 411 \t loss: -369.125 \t return: -393.154 \t ep_len: 394.077\n",
      "epoch: 412 \t loss: -289.639 \t return: -357.143 \t ep_len: 358.143\n",
      "epoch: 413 \t loss: -329.414 \t return: -351.600 \t ep_len: 352.533\n",
      "epoch: 414 \t loss: -331.045 \t return: -268.200 \t ep_len: 269.200\n",
      "epoch: 415 \t loss: -250.336 \t return: -274.947 \t ep_len: 275.947\n",
      "epoch: 416 \t loss: -264.869 \t return: -281.833 \t ep_len: 282.778\n",
      "epoch: 417 \t loss: -337.148 \t return: -320.000 \t ep_len: 320.938\n",
      "epoch: 418 \t loss: -301.210 \t return: -280.111 \t ep_len: 281.056\n",
      "epoch: 419 \t loss: -272.431 \t return: -293.765 \t ep_len: 294.765\n",
      "epoch: 420 \t loss: -202.979 \t return: -275.263 \t ep_len: 276.263\n",
      "epoch: 421 \t loss: -265.719 \t return: -288.211 \t ep_len: 289.158\n",
      "epoch: 422 \t loss: -405.795 \t return: -604.444 \t ep_len: 605.333\n",
      "epoch: 423 \t loss: -309.581 \t return: -339.133 \t ep_len: 340.067\n",
      "epoch: 424 \t loss: -199.859 \t return: -254.200 \t ep_len: 255.200\n",
      "epoch: 425 \t loss: -335.767 \t return: -424.333 \t ep_len: 425.250\n",
      "epoch: 426 \t loss: -263.773 \t return: -395.786 \t ep_len: 396.786\n",
      "epoch: 427 \t loss: -342.092 \t return: -461.182 \t ep_len: 462.000\n",
      "epoch: 428 \t loss: -235.372 \t return: -310.611 \t ep_len: 311.611\n",
      "epoch: 429 \t loss: -218.153 \t return: -341.562 \t ep_len: 342.562\n",
      "epoch: 430 \t loss: -365.270 \t return: -443.385 \t ep_len: 444.308\n",
      "epoch: 431 \t loss: -313.586 \t return: -358.214 \t ep_len: 359.071\n",
      "epoch: 432 \t loss: -232.363 \t return: -295.278 \t ep_len: 296.278\n",
      "epoch: 433 \t loss: -392.372 \t return: -489.000 \t ep_len: 489.818\n",
      "epoch: 434 \t loss: -309.012 \t return: -322.235 \t ep_len: 323.176\n",
      "epoch: 435 \t loss: -335.459 \t return: -337.562 \t ep_len: 338.500\n",
      "epoch: 436 \t loss: -427.589 \t return: -392.615 \t ep_len: 393.385\n",
      "epoch: 437 \t loss: -311.613 \t return: -351.267 \t ep_len: 352.200\n",
      "epoch: 438 \t loss: -204.179 \t return: -250.750 \t ep_len: 251.750\n",
      "epoch: 439 \t loss: -405.809 \t return: -577.222 \t ep_len: 578.111\n",
      "epoch: 440 \t loss: -343.511 \t return: -385.786 \t ep_len: 386.786\n",
      "epoch: 441 \t loss: -327.295 \t return: -308.118 \t ep_len: 309.059\n",
      "epoch: 442 \t loss: -323.649 \t return: -277.000 \t ep_len: 277.889\n",
      "epoch: 443 \t loss: -293.409 \t return: -303.235 \t ep_len: 304.235\n",
      "epoch: 444 \t loss: -192.961 \t return: -219.174 \t ep_len: 220.174\n",
      "epoch: 445 \t loss: -337.335 \t return: -318.312 \t ep_len: 319.250\n",
      "epoch: 446 \t loss: -220.141 \t return: -229.083 \t ep_len: 230.083\n",
      "epoch: 447 \t loss: -331.771 \t return: -303.882 \t ep_len: 304.824\n",
      "epoch: 448 \t loss: -227.288 \t return: -227.542 \t ep_len: 228.542\n",
      "epoch: 449 \t loss: -231.639 \t return: -281.444 \t ep_len: 282.444\n",
      "epoch: 450 \t loss: -287.725 \t return: -304.471 \t ep_len: 305.412\n",
      "epoch: 451 \t loss: -320.236 \t return: -338.000 \t ep_len: 338.938\n",
      "epoch: 452 \t loss: -398.448 \t return: -434.385 \t ep_len: 435.231\n",
      "epoch: 453 \t loss: -408.153 \t return: -417.750 \t ep_len: 418.667\n",
      "epoch: 454 \t loss: -328.531 \t return: -328.062 \t ep_len: 329.062\n",
      "epoch: 455 \t loss: -262.665 \t return: -277.778 \t ep_len: 278.778\n",
      "epoch: 456 \t loss: -411.134 \t return: -402.000 \t ep_len: 402.846\n",
      "epoch: 457 \t loss: -259.577 \t return: -280.167 \t ep_len: 281.167\n",
      "epoch: 458 \t loss: -299.249 \t return: -320.562 \t ep_len: 321.500\n",
      "epoch: 459 \t loss: -386.133 \t return: -334.067 \t ep_len: 335.000\n",
      "epoch: 460 \t loss: -267.698 \t return: -298.706 \t ep_len: 299.706\n",
      "epoch: 461 \t loss: -256.387 \t return: -267.053 \t ep_len: 268.053\n",
      "epoch: 462 \t loss: -327.838 \t return: -297.444 \t ep_len: 298.389\n",
      "epoch: 463 \t loss: -329.571 \t return: -276.810 \t ep_len: 277.810\n",
      "epoch: 464 \t loss: -289.904 \t return: -256.095 \t ep_len: 257.095\n",
      "epoch: 465 \t loss: -188.798 \t return: -217.130 \t ep_len: 218.130\n",
      "epoch: 466 \t loss: -304.117 \t return: -282.789 \t ep_len: 283.737\n",
      "epoch: 467 \t loss: -273.652 \t return: -254.150 \t ep_len: 255.150\n",
      "epoch: 468 \t loss: -357.642 \t return: -319.056 \t ep_len: 320.056\n",
      "epoch: 469 \t loss: -358.260 \t return: -383.733 \t ep_len: 384.667\n",
      "epoch: 470 \t loss: -236.726 \t return: -262.526 \t ep_len: 263.526\n",
      "epoch: 471 \t loss: -356.060 \t return: -360.667 \t ep_len: 361.667\n",
      "epoch: 472 \t loss: -205.599 \t return: -265.500 \t ep_len: 266.500\n",
      "epoch: 473 \t loss: -324.860 \t return: -295.529 \t ep_len: 296.412\n",
      "epoch: 474 \t loss: -306.769 \t return: -249.810 \t ep_len: 250.810\n",
      "epoch: 475 \t loss: -180.723 \t return: -231.727 \t ep_len: 232.727\n",
      "epoch: 476 \t loss: -222.352 \t return: -267.368 \t ep_len: 268.368\n",
      "epoch: 477 \t loss: -243.683 \t return: -263.684 \t ep_len: 264.684\n",
      "epoch: 478 \t loss: -186.903 \t return: -181.897 \t ep_len: 182.897\n",
      "epoch: 479 \t loss: -390.353 \t return: -475.909 \t ep_len: 476.909\n",
      "epoch: 480 \t loss: -314.007 \t return: -289.947 \t ep_len: 290.895\n",
      "epoch: 481 \t loss: -275.769 \t return: -262.316 \t ep_len: 263.316\n",
      "epoch: 482 \t loss: -274.337 \t return: -295.059 \t ep_len: 296.059\n",
      "epoch: 483 \t loss: -238.617 \t return: -284.056 \t ep_len: 285.056\n",
      "epoch: 484 \t loss: -225.111 \t return: -260.800 \t ep_len: 261.800\n",
      "epoch: 485 \t loss: -246.007 \t return: -300.353 \t ep_len: 301.353\n",
      "epoch: 486 \t loss: -164.543 \t return: -184.333 \t ep_len: 185.333\n",
      "epoch: 487 \t loss: -343.677 \t return: -358.857 \t ep_len: 359.786\n",
      "epoch: 488 \t loss: -253.395 \t return: -222.692 \t ep_len: 223.654\n",
      "epoch: 489 \t loss: -323.471 \t return: -326.938 \t ep_len: 327.938\n",
      "epoch: 490 \t loss: -188.722 \t return: -212.292 \t ep_len: 213.292\n",
      "epoch: 491 \t loss: -232.139 \t return: -228.542 \t ep_len: 229.542\n",
      "epoch: 492 \t loss: -404.901 \t return: -393.846 \t ep_len: 394.769\n",
      "epoch: 493 \t loss: -299.413 \t return: -313.000 \t ep_len: 314.000\n",
      "epoch: 494 \t loss: -307.839 \t return: -252.200 \t ep_len: 253.150\n",
      "epoch: 495 \t loss: -349.371 \t return: -300.556 \t ep_len: 301.556\n",
      "epoch: 496 \t loss: -379.070 \t return: -315.353 \t ep_len: 316.353\n",
      "epoch: 497 \t loss: -279.406 \t return: -270.263 \t ep_len: 271.263\n",
      "epoch: 498 \t loss: -318.923 \t return: -269.368 \t ep_len: 270.368\n",
      "epoch: 499 \t loss: -365.910 \t return: -280.526 \t ep_len: 281.526\n",
      "epoch: 500 \t loss: -267.421 \t return: -258.429 \t ep_len: 259.429\n",
      "epoch: 501 \t loss: -292.083 \t return: -296.056 \t ep_len: 297.056\n",
      "epoch: 502 \t loss: -450.086 \t return: -395.231 \t ep_len: 396.154\n",
      "epoch: 503 \t loss: -256.073 \t return: -251.550 \t ep_len: 252.550\n",
      "epoch: 504 \t loss: -341.402 \t return: -281.167 \t ep_len: 282.167\n",
      "epoch: 505 \t loss: -286.656 \t return: -262.526 \t ep_len: 263.526\n",
      "epoch: 506 \t loss: -354.627 \t return: -338.533 \t ep_len: 339.533\n",
      "epoch: 507 \t loss: -304.393 \t return: -268.263 \t ep_len: 269.263\n",
      "epoch: 508 \t loss: -342.979 \t return: -286.211 \t ep_len: 287.211\n",
      "epoch: 509 \t loss: -220.703 \t return: -223.739 \t ep_len: 224.739\n",
      "epoch: 510 \t loss: -344.722 \t return: -307.235 \t ep_len: 308.235\n",
      "epoch: 511 \t loss: -249.980 \t return: -232.130 \t ep_len: 233.130\n",
      "epoch: 512 \t loss: -227.795 \t return: -262.211 \t ep_len: 263.211\n",
      "epoch: 513 \t loss: -172.912 \t return: -192.500 \t ep_len: 193.500\n",
      "epoch: 514 \t loss: -257.995 \t return: -243.952 \t ep_len: 244.952\n",
      "epoch: 515 \t loss: -293.126 \t return: -265.700 \t ep_len: 266.700\n",
      "epoch: 516 \t loss: -194.908 \t return: -243.143 \t ep_len: 244.143\n",
      "epoch: 517 \t loss: -282.796 \t return: -291.158 \t ep_len: 292.158\n",
      "epoch: 518 \t loss: -320.173 \t return: -314.000 \t ep_len: 315.000\n",
      "epoch: 519 \t loss: -208.991 \t return: -241.905 \t ep_len: 242.905\n",
      "epoch: 520 \t loss: -193.405 \t return: -246.182 \t ep_len: 247.182\n",
      "epoch: 521 \t loss: -246.232 \t return: -312.188 \t ep_len: 313.188\n",
      "epoch: 522 \t loss: -186.968 \t return: -283.667 \t ep_len: 284.667\n",
      "epoch: 523 \t loss: -312.082 \t return: -425.154 \t ep_len: 426.000\n",
      "epoch: 524 \t loss: -236.238 \t return: -326.125 \t ep_len: 327.125\n",
      "epoch: 525 \t loss: -196.720 \t return: -346.067 \t ep_len: 347.067\n",
      "epoch: 526 \t loss: -157.551 \t return: -257.800 \t ep_len: 258.800\n",
      "epoch: 527 \t loss: -220.982 \t return: -349.533 \t ep_len: 350.533\n",
      "epoch: 528 \t loss: -191.008 \t return: -334.467 \t ep_len: 335.400\n",
      "epoch: 529 \t loss: -246.806 \t return: -575.111 \t ep_len: 576.000\n",
      "epoch: 530 \t loss: -306.374 \t return: -461.545 \t ep_len: 462.273\n",
      "epoch: 531 \t loss: -225.740 \t return: -404.000 \t ep_len: 404.846\n",
      "epoch: 532 \t loss: -255.406 \t return: -434.154 \t ep_len: 435.077\n",
      "epoch: 533 \t loss: -199.089 \t return: -334.467 \t ep_len: 335.467\n",
      "epoch: 534 \t loss: -253.139 \t return: -473.273 \t ep_len: 474.091\n",
      "epoch: 535 \t loss: -270.699 \t return: -432.750 \t ep_len: 433.583\n",
      "epoch: 536 \t loss: -251.719 \t return: -500.700 \t ep_len: 501.400\n",
      "epoch: 537 \t loss: -263.085 \t return: -502.800 \t ep_len: 503.600\n",
      "epoch: 538 \t loss: -268.109 \t return: -452.167 \t ep_len: 453.000\n",
      "epoch: 539 \t loss: -229.656 \t return: -446.308 \t ep_len: 447.231\n",
      "epoch: 540 \t loss: -264.952 \t return: -501.900 \t ep_len: 502.700\n",
      "epoch: 541 \t loss: -216.919 \t return: -404.154 \t ep_len: 405.077\n",
      "epoch: 542 \t loss: -282.423 \t return: -519.900 \t ep_len: 520.800\n",
      "epoch: 543 \t loss: -213.305 \t return: -358.214 \t ep_len: 359.214\n",
      "epoch: 544 \t loss: -235.113 \t return: -429.083 \t ep_len: 429.917\n",
      "epoch: 545 \t loss: -257.202 \t return: -567.600 \t ep_len: 568.300\n",
      "epoch: 546 \t loss: -286.414 \t return: -651.556 \t ep_len: 652.222\n",
      "epoch: 547 \t loss: -245.995 \t return: -520.636 \t ep_len: 521.364\n",
      "epoch: 548 \t loss: -212.924 \t return: -433.000 \t ep_len: 434.000\n",
      "epoch: 549 \t loss: -257.304 \t return: -493.909 \t ep_len: 494.818\n",
      "epoch: 550 \t loss: -219.397 \t return: -360.071 \t ep_len: 361.000\n",
      "epoch: 551 \t loss: -317.000 \t return: -567.200 \t ep_len: 567.900\n",
      "epoch: 552 \t loss: -217.457 \t return: -389.769 \t ep_len: 390.692\n",
      "epoch: 553 \t loss: -308.666 \t return: -681.625 \t ep_len: 682.375\n",
      "epoch: 554 \t loss: -282.366 \t return: -468.455 \t ep_len: 469.273\n",
      "epoch: 555 \t loss: -281.583 \t return: -490.583 \t ep_len: 491.417\n",
      "epoch: 556 \t loss: -282.141 \t return: -506.364 \t ep_len: 507.182\n",
      "epoch: 557 \t loss: -250.939 \t return: -422.769 \t ep_len: 423.769\n",
      "epoch: 558 \t loss: -310.747 \t return: -589.778 \t ep_len: 590.778\n",
      "epoch: 559 \t loss: -327.825 \t return: -455.545 \t ep_len: 456.273\n",
      "epoch: 560 \t loss: -293.102 \t return: -416.167 \t ep_len: 417.000\n",
      "epoch: 561 \t loss: -327.642 \t return: -417.667 \t ep_len: 418.500\n",
      "epoch: 562 \t loss: -265.611 \t return: -377.071 \t ep_len: 378.071\n",
      "epoch: 563 \t loss: -235.016 \t return: -380.143 \t ep_len: 381.071\n",
      "epoch: 564 \t loss: -259.994 \t return: -341.933 \t ep_len: 342.800\n",
      "epoch: 565 \t loss: -256.014 \t return: -401.615 \t ep_len: 402.615\n",
      "epoch: 566 \t loss: -331.525 \t return: -490.818 \t ep_len: 491.727\n",
      "epoch: 567 \t loss: -425.086 \t return: -762.714 \t ep_len: 763.571\n",
      "epoch: 568 \t loss: -283.313 \t return: -400.385 \t ep_len: 401.308\n",
      "epoch: 569 \t loss: -241.558 \t return: -305.667 \t ep_len: 306.611\n",
      "epoch: 570 \t loss: -269.984 \t return: -387.077 \t ep_len: 388.077\n",
      "epoch: 571 \t loss: -273.415 \t return: -391.308 \t ep_len: 392.308\n",
      "epoch: 572 \t loss: -291.536 \t return: -386.154 \t ep_len: 387.077\n",
      "epoch: 573 \t loss: -332.818 \t return: -385.538 \t ep_len: 386.385\n",
      "epoch: 574 \t loss: -266.598 \t return: -318.625 \t ep_len: 319.625\n",
      "epoch: 575 \t loss: -165.282 \t return: -210.625 \t ep_len: 211.625\n",
      "epoch: 576 \t loss: -235.088 \t return: -261.950 \t ep_len: 262.950\n",
      "epoch: 577 \t loss: -312.634 \t return: -341.235 \t ep_len: 342.176\n",
      "epoch: 578 \t loss: -321.904 \t return: -342.800 \t ep_len: 343.667\n",
      "epoch: 579 \t loss: -260.677 \t return: -271.789 \t ep_len: 272.737\n",
      "epoch: 580 \t loss: -245.717 \t return: -220.739 \t ep_len: 221.696\n",
      "epoch: 581 \t loss: -183.346 \t return: -210.542 \t ep_len: 211.542\n",
      "epoch: 582 \t loss: -271.238 \t return: -364.929 \t ep_len: 365.929\n",
      "epoch: 583 \t loss: -117.088 \t return: -168.133 \t ep_len: 169.133\n",
      "epoch: 584 \t loss: -279.147 \t return: -264.526 \t ep_len: 265.474\n",
      "epoch: 585 \t loss: -171.650 \t return: -241.952 \t ep_len: 242.952\n",
      "epoch: 586 \t loss: -196.149 \t return: -245.238 \t ep_len: 246.238\n",
      "epoch: 587 \t loss: -214.598 \t return: -208.583 \t ep_len: 209.542\n",
      "epoch: 588 \t loss: -141.731 \t return: -180.857 \t ep_len: 181.857\n",
      "epoch: 589 \t loss: -244.861 \t return: -243.905 \t ep_len: 244.857\n",
      "epoch: 590 \t loss: -214.232 \t return: -266.105 \t ep_len: 267.105\n",
      "epoch: 591 \t loss: -245.992 \t return: -254.050 \t ep_len: 255.050\n",
      "epoch: 592 \t loss: -233.814 \t return: -300.059 \t ep_len: 301.059\n",
      "epoch: 593 \t loss: -237.614 \t return: -225.130 \t ep_len: 226.087\n",
      "epoch: 594 \t loss: -288.366 \t return: -366.786 \t ep_len: 367.786\n",
      "epoch: 595 \t loss: -258.915 \t return: -301.167 \t ep_len: 302.167\n",
      "epoch: 596 \t loss: -220.379 \t return: -249.200 \t ep_len: 250.150\n",
      "epoch: 597 \t loss: -219.323 \t return: -240.762 \t ep_len: 241.762\n",
      "epoch: 598 \t loss: -134.599 \t return: -179.241 \t ep_len: 180.241\n",
      "epoch: 599 \t loss: -206.195 \t return: -211.074 \t ep_len: 212.074\n",
      "epoch: 600 \t loss: -257.562 \t return: -284.222 \t ep_len: 285.167\n",
      "epoch: 601 \t loss: -138.899 \t return: -189.815 \t ep_len: 190.815\n",
      "epoch: 602 \t loss: -268.665 \t return: -259.650 \t ep_len: 260.600\n",
      "epoch: 603 \t loss: -239.685 \t return: -310.882 \t ep_len: 311.824\n",
      "epoch: 604 \t loss: -170.034 \t return: -237.905 \t ep_len: 238.905\n",
      "epoch: 605 \t loss: -233.872 \t return: -312.938 \t ep_len: 313.938\n",
      "epoch: 606 \t loss: -147.234 \t return: -186.704 \t ep_len: 187.704\n",
      "epoch: 607 \t loss: -223.316 \t return: -217.560 \t ep_len: 218.560\n",
      "epoch: 608 \t loss: -387.680 \t return: -472.364 \t ep_len: 473.273\n",
      "epoch: 609 \t loss: -255.773 \t return: -200.654 \t ep_len: 201.615\n",
      "epoch: 610 \t loss: -211.994 \t return: -179.286 \t ep_len: 180.286\n",
      "epoch: 611 \t loss: -302.246 \t return: -255.818 \t ep_len: 256.773\n",
      "epoch: 612 \t loss: -291.467 \t return: -271.333 \t ep_len: 272.286\n",
      "epoch: 613 \t loss: -192.517 \t return: -242.500 \t ep_len: 243.500\n",
      "epoch: 614 \t loss: -214.791 \t return: -234.667 \t ep_len: 235.667\n",
      "epoch: 615 \t loss: -226.063 \t return: -244.286 \t ep_len: 245.286\n",
      "epoch: 616 \t loss: -187.409 \t return: -230.458 \t ep_len: 231.458\n",
      "epoch: 617 \t loss: -168.402 \t return: -203.720 \t ep_len: 204.720\n",
      "epoch: 618 \t loss: -248.841 \t return: -225.615 \t ep_len: 226.577\n",
      "epoch: 619 \t loss: -156.659 \t return: -168.097 \t ep_len: 169.097\n",
      "epoch: 620 \t loss: -262.022 \t return: -238.667 \t ep_len: 239.667\n",
      "epoch: 621 \t loss: -274.124 \t return: -272.316 \t ep_len: 273.316\n",
      "epoch: 622 \t loss: -211.671 \t return: -208.833 \t ep_len: 209.833\n",
      "epoch: 623 \t loss: -193.154 \t return: -220.739 \t ep_len: 221.739\n",
      "epoch: 624 \t loss: -209.448 \t return: -217.708 \t ep_len: 218.708\n",
      "epoch: 625 \t loss: -261.061 \t return: -239.762 \t ep_len: 240.762\n",
      "epoch: 626 \t loss: -245.099 \t return: -244.000 \t ep_len: 245.000\n",
      "epoch: 627 \t loss: -235.365 \t return: -230.682 \t ep_len: 231.682\n",
      "epoch: 628 \t loss: -281.674 \t return: -234.227 \t ep_len: 235.227\n",
      "epoch: 629 \t loss: -212.897 \t return: -233.273 \t ep_len: 234.273\n",
      "epoch: 630 \t loss: -202.157 \t return: -204.080 \t ep_len: 205.080\n",
      "epoch: 631 \t loss: -393.812 \t return: -269.316 \t ep_len: 270.316\n",
      "epoch: 632 \t loss: -251.672 \t return: -227.409 \t ep_len: 228.409\n",
      "epoch: 633 \t loss: -254.665 \t return: -240.381 \t ep_len: 241.381\n",
      "epoch: 634 \t loss: -436.989 \t return: -378.200 \t ep_len: 379.200\n",
      "epoch: 635 \t loss: -429.736 \t return: -396.154 \t ep_len: 397.154\n",
      "epoch: 636 \t loss: -239.806 \t return: -204.600 \t ep_len: 205.600\n",
      "epoch: 637 \t loss: -292.910 \t return: -238.591 \t ep_len: 239.591\n",
      "epoch: 638 \t loss: -346.978 \t return: -269.684 \t ep_len: 270.684\n",
      "epoch: 639 \t loss: -344.695 \t return: -299.111 \t ep_len: 300.111\n",
      "epoch: 640 \t loss: -283.034 \t return: -186.296 \t ep_len: 187.296\n",
      "epoch: 641 \t loss: -360.830 \t return: -230.667 \t ep_len: 231.625\n",
      "epoch: 642 \t loss: -405.671 \t return: -357.500 \t ep_len: 358.500\n",
      "epoch: 643 \t loss: -404.574 \t return: -244.522 \t ep_len: 245.478\n",
      "epoch: 644 \t loss: -328.957 \t return: -238.857 \t ep_len: 239.810\n",
      "epoch: 645 \t loss: -252.140 \t return: -229.455 \t ep_len: 230.455\n",
      "epoch: 646 \t loss: -246.848 \t return: -193.231 \t ep_len: 194.231\n",
      "epoch: 647 \t loss: -370.217 \t return: -316.353 \t ep_len: 317.353\n",
      "epoch: 648 \t loss: -245.583 \t return: -234.636 \t ep_len: 235.636\n",
      "epoch: 649 \t loss: -470.481 \t return: -333.133 \t ep_len: 334.133\n",
      "epoch: 650 \t loss: -484.133 \t return: -347.000 \t ep_len: 347.933\n",
      "epoch: 651 \t loss: -392.639 \t return: -330.588 \t ep_len: 331.588\n",
      "epoch: 652 \t loss: -419.141 \t return: -299.111 \t ep_len: 300.111\n",
      "epoch: 653 \t loss: -410.877 \t return: -315.000 \t ep_len: 316.000\n",
      "epoch: 654 \t loss: -439.041 \t return: -389.692 \t ep_len: 390.692\n",
      "epoch: 655 \t loss: -344.610 \t return: -318.529 \t ep_len: 319.529\n",
      "epoch: 656 \t loss: -263.991 \t return: -248.333 \t ep_len: 249.333\n",
      "epoch: 657 \t loss: -313.779 \t return: -212.000 \t ep_len: 212.958\n",
      "epoch: 658 \t loss: -358.621 \t return: -254.950 \t ep_len: 255.900\n",
      "epoch: 659 \t loss: -195.046 \t return: -203.640 \t ep_len: 204.640\n",
      "epoch: 660 \t loss: -186.107 \t return: -202.423 \t ep_len: 203.423\n",
      "epoch: 661 \t loss: -294.871 \t return: -271.263 \t ep_len: 272.263\n",
      "epoch: 662 \t loss: -193.012 \t return: -189.333 \t ep_len: 190.333\n",
      "epoch: 663 \t loss: -270.617 \t return: -224.846 \t ep_len: 225.846\n",
      "epoch: 664 \t loss: -239.752 \t return: -227.000 \t ep_len: 228.000\n",
      "epoch: 665 \t loss: -220.618 \t return: -218.522 \t ep_len: 219.522\n",
      "epoch: 666 \t loss: -233.747 \t return: -227.045 \t ep_len: 228.045\n",
      "epoch: 667 \t loss: -185.457 \t return: -192.462 \t ep_len: 193.462\n",
      "epoch: 668 \t loss: -291.998 \t return: -212.250 \t ep_len: 213.208\n",
      "epoch: 669 \t loss: -228.878 \t return: -225.261 \t ep_len: 226.261\n",
      "epoch: 670 \t loss: -306.545 \t return: -277.611 \t ep_len: 278.611\n",
      "epoch: 671 \t loss: -148.452 \t return: -191.654 \t ep_len: 192.654\n",
      "epoch: 672 \t loss: -179.313 \t return: -200.400 \t ep_len: 201.400\n",
      "epoch: 673 \t loss: -192.155 \t return: -219.043 \t ep_len: 220.043\n",
      "epoch: 674 \t loss: -237.625 \t return: -263.211 \t ep_len: 264.211\n",
      "epoch: 675 \t loss: -239.242 \t return: -220.826 \t ep_len: 221.826\n",
      "epoch: 676 \t loss: -278.288 \t return: -249.950 \t ep_len: 250.900\n",
      "epoch: 677 \t loss: -297.068 \t return: -278.474 \t ep_len: 279.474\n",
      "epoch: 678 \t loss: -259.600 \t return: -218.261 \t ep_len: 219.261\n",
      "epoch: 679 \t loss: -170.704 \t return: -209.667 \t ep_len: 210.667\n",
      "epoch: 680 \t loss: -247.643 \t return: -260.550 \t ep_len: 261.550\n",
      "epoch: 681 \t loss: -135.909 \t return: -139.974 \t ep_len: 140.974\n",
      "epoch: 682 \t loss: -128.075 \t return: -181.071 \t ep_len: 182.071\n",
      "epoch: 683 \t loss: -239.374 \t return: -271.105 \t ep_len: 272.105\n",
      "epoch: 684 \t loss: -202.830 \t return: -230.455 \t ep_len: 231.409\n",
      "epoch: 685 \t loss: -164.138 \t return: -195.185 \t ep_len: 196.185\n",
      "epoch: 686 \t loss: -167.975 \t return: -252.524 \t ep_len: 253.524\n",
      "epoch: 687 \t loss: -230.687 \t return: -263.632 \t ep_len: 264.632\n",
      "epoch: 688 \t loss: -155.190 \t return: -228.136 \t ep_len: 229.136\n",
      "epoch: 689 \t loss: -133.300 \t return: -173.310 \t ep_len: 174.310\n",
      "epoch: 690 \t loss: -170.616 \t return: -193.962 \t ep_len: 194.962\n",
      "epoch: 691 \t loss: -212.085 \t return: -223.696 \t ep_len: 224.652\n",
      "epoch: 692 \t loss: -145.498 \t return: -177.750 \t ep_len: 178.750\n",
      "epoch: 693 \t loss: -201.834 \t return: -275.895 \t ep_len: 276.895\n",
      "epoch: 694 \t loss: -223.803 \t return: -253.762 \t ep_len: 254.762\n",
      "epoch: 695 \t loss: -203.430 \t return: -226.591 \t ep_len: 227.591\n",
      "epoch: 696 \t loss: -202.848 \t return: -223.913 \t ep_len: 224.913\n",
      "epoch: 697 \t loss: -149.010 \t return: -221.826 \t ep_len: 222.826\n",
      "epoch: 698 \t loss: -177.153 \t return: -215.625 \t ep_len: 216.625\n",
      "epoch: 699 \t loss: -180.440 \t return: -245.227 \t ep_len: 246.227\n",
      "epoch: 700 \t loss: -153.779 \t return: -194.423 \t ep_len: 195.423\n",
      "epoch: 701 \t loss: -410.526 \t return: -370.429 \t ep_len: 371.214\n",
      "epoch: 702 \t loss: -158.793 \t return: -203.800 \t ep_len: 204.800\n",
      "epoch: 703 \t loss: -196.013 \t return: -227.318 \t ep_len: 228.318\n",
      "epoch: 704 \t loss: -143.948 \t return: -190.333 \t ep_len: 191.333\n",
      "epoch: 705 \t loss: -151.301 \t return: -188.741 \t ep_len: 189.741\n",
      "epoch: 706 \t loss: -184.373 \t return: -228.091 \t ep_len: 229.045\n",
      "epoch: 707 \t loss: -139.176 \t return: -193.692 \t ep_len: 194.692\n",
      "epoch: 708 \t loss: -144.224 \t return: -183.517 \t ep_len: 184.517\n",
      "epoch: 709 \t loss: -156.447 \t return: -200.500 \t ep_len: 201.500\n",
      "epoch: 710 \t loss: -180.376 \t return: -218.696 \t ep_len: 219.696\n",
      "epoch: 711 \t loss: -149.982 \t return: -227.565 \t ep_len: 228.565\n",
      "epoch: 712 \t loss: -211.174 \t return: -276.750 \t ep_len: 277.700\n",
      "epoch: 713 \t loss: -226.273 \t return: -266.263 \t ep_len: 267.158\n",
      "epoch: 714 \t loss: -191.050 \t return: -286.000 \t ep_len: 287.000\n",
      "epoch: 715 \t loss: -169.700 \t return: -232.545 \t ep_len: 233.545\n",
      "epoch: 716 \t loss: -247.557 \t return: -416.000 \t ep_len: 416.833\n",
      "epoch: 717 \t loss: -191.646 \t return: -236.636 \t ep_len: 237.591\n",
      "epoch: 718 \t loss: -193.789 \t return: -285.444 \t ep_len: 286.389\n",
      "epoch: 719 \t loss: -171.232 \t return: -265.789 \t ep_len: 266.789\n",
      "epoch: 720 \t loss: -206.370 \t return: -356.857 \t ep_len: 357.857\n",
      "epoch: 721 \t loss: -141.180 \t return: -335.176 \t ep_len: 336.176\n",
      "epoch: 722 \t loss: -126.614 \t return: -264.211 \t ep_len: 265.211\n",
      "epoch: 723 \t loss: -207.720 \t return: -429.417 \t ep_len: 430.333\n",
      "epoch: 724 \t loss: -186.216 \t return: -345.500 \t ep_len: 346.500\n",
      "epoch: 725 \t loss: -260.508 \t return: -440.083 \t ep_len: 440.917\n",
      "epoch: 726 \t loss: -186.005 \t return: -394.154 \t ep_len: 395.077\n",
      "epoch: 727 \t loss: -203.416 \t return: -418.167 \t ep_len: 419.000\n",
      "epoch: 728 \t loss: -204.660 \t return: -426.857 \t ep_len: 427.786\n",
      "epoch: 729 \t loss: -266.980 \t return: -551.600 \t ep_len: 552.300\n",
      "epoch: 730 \t loss: -223.330 \t return: -382.467 \t ep_len: 383.267\n",
      "epoch: 731 \t loss: -206.305 \t return: -472.727 \t ep_len: 473.545\n",
      "epoch: 732 \t loss: -204.788 \t return: -466.000 \t ep_len: 466.727\n",
      "epoch: 733 \t loss: -175.285 \t return: -663.625 \t ep_len: 664.250\n",
      "epoch: 734 \t loss: -151.772 \t return: -416.786 \t ep_len: 417.643\n",
      "epoch: 735 \t loss: -195.939 \t return: -647.000 \t ep_len: 647.750\n",
      "epoch: 736 \t loss: -143.371 \t return: -387.615 \t ep_len: 388.615\n",
      "epoch: 737 \t loss: -154.090 \t return: -428.615 \t ep_len: 429.538\n",
      "epoch: 738 \t loss: -177.715 \t return: -417.167 \t ep_len: 418.083\n",
      "epoch: 739 \t loss: -170.850 \t return: -306.611 \t ep_len: 307.556\n",
      "epoch: 740 \t loss: -146.838 \t return: -300.222 \t ep_len: 301.222\n",
      "epoch: 741 \t loss: -233.784 \t return: -339.467 \t ep_len: 340.333\n",
      "epoch: 742 \t loss: -132.157 \t return: -279.053 \t ep_len: 280.053\n",
      "epoch: 743 \t loss: -187.985 \t return: -328.625 \t ep_len: 329.625\n",
      "epoch: 744 \t loss: -136.387 \t return: -207.500 \t ep_len: 208.500\n",
      "epoch: 745 \t loss: -193.509 \t return: -354.267 \t ep_len: 355.267\n",
      "epoch: 746 \t loss: -164.716 \t return: -309.389 \t ep_len: 310.389\n",
      "epoch: 747 \t loss: -179.950 \t return: -257.100 \t ep_len: 258.100\n",
      "epoch: 748 \t loss: -165.322 \t return: -205.269 \t ep_len: 206.269\n",
      "epoch: 749 \t loss: -194.881 \t return: -253.500 \t ep_len: 254.500\n",
      "epoch: 750 \t loss: -150.552 \t return: -280.944 \t ep_len: 281.944\n",
      "epoch: 751 \t loss: -195.331 \t return: -228.045 \t ep_len: 229.000\n",
      "epoch: 752 \t loss: -193.922 \t return: -266.947 \t ep_len: 267.895\n",
      "epoch: 753 \t loss: -138.464 \t return: -227.043 \t ep_len: 228.043\n",
      "epoch: 754 \t loss: -186.056 \t return: -312.250 \t ep_len: 313.250\n",
      "epoch: 755 \t loss: -198.660 \t return: -244.238 \t ep_len: 245.143\n",
      "epoch: 756 \t loss: -155.623 \t return: -272.421 \t ep_len: 273.421\n",
      "epoch: 757 \t loss: -128.763 \t return: -282.167 \t ep_len: 283.167\n",
      "epoch: 758 \t loss: -204.835 \t return: -415.154 \t ep_len: 416.154\n",
      "epoch: 759 \t loss: -126.590 \t return: -230.455 \t ep_len: 231.455\n",
      "epoch: 760 \t loss: -131.459 \t return: -201.800 \t ep_len: 202.800\n",
      "epoch: 761 \t loss: -255.073 \t return: -393.000 \t ep_len: 393.923\n",
      "epoch: 762 \t loss: -195.945 \t return: -314.000 \t ep_len: 314.941\n",
      "epoch: 763 \t loss: -206.880 \t return: -266.474 \t ep_len: 267.474\n",
      "epoch: 764 \t loss: -133.506 \t return: -179.893 \t ep_len: 180.893\n",
      "epoch: 765 \t loss: -195.472 \t return: -221.478 \t ep_len: 222.435\n",
      "epoch: 766 \t loss: -102.366 \t return: -175.067 \t ep_len: 176.067\n",
      "epoch: 767 \t loss: -182.669 \t return: -277.053 \t ep_len: 278.053\n",
      "epoch: 768 \t loss: -131.258 \t return: -209.042 \t ep_len: 210.042\n",
      "epoch: 769 \t loss: -206.820 \t return: -251.750 \t ep_len: 252.750\n",
      "epoch: 770 \t loss: -174.842 \t return: -223.250 \t ep_len: 224.250\n",
      "epoch: 771 \t loss: -152.490 \t return: -261.450 \t ep_len: 262.450\n",
      "epoch: 772 \t loss: -194.381 \t return: -279.667 \t ep_len: 280.667\n",
      "epoch: 773 \t loss: -137.017 \t return: -201.231 \t ep_len: 202.231\n",
      "epoch: 774 \t loss: -178.912 \t return: -258.000 \t ep_len: 259.000\n",
      "epoch: 775 \t loss: -221.674 \t return: -267.600 \t ep_len: 268.600\n",
      "epoch: 776 \t loss: -169.520 \t return: -279.684 \t ep_len: 280.684\n",
      "epoch: 777 \t loss: -164.001 \t return: -268.000 \t ep_len: 269.000\n",
      "epoch: 778 \t loss: -208.951 \t return: -252.050 \t ep_len: 253.050\n",
      "epoch: 779 \t loss: -264.366 \t return: -364.786 \t ep_len: 365.786\n",
      "epoch: 780 \t loss: -168.452 \t return: -211.385 \t ep_len: 212.385\n",
      "epoch: 781 \t loss: -153.454 \t return: -178.071 \t ep_len: 179.071\n",
      "epoch: 782 \t loss: -197.581 \t return: -269.526 \t ep_len: 270.526\n",
      "epoch: 783 \t loss: -142.538 \t return: -211.375 \t ep_len: 212.375\n",
      "epoch: 784 \t loss: -222.834 \t return: -294.000 \t ep_len: 295.000\n",
      "epoch: 785 \t loss: -182.336 \t return: -217.565 \t ep_len: 218.565\n",
      "epoch: 786 \t loss: -132.931 \t return: -166.433 \t ep_len: 167.433\n",
      "epoch: 787 \t loss: -152.262 \t return: -192.815 \t ep_len: 193.815\n",
      "epoch: 788 \t loss: -150.231 \t return: -208.200 \t ep_len: 209.200\n",
      "epoch: 789 \t loss: -96.290 \t return: -150.882 \t ep_len: 151.882\n",
      "epoch: 790 \t loss: -155.220 \t return: -172.806 \t ep_len: 173.806\n",
      "epoch: 791 \t loss: -120.904 \t return: -186.259 \t ep_len: 187.259\n",
      "epoch: 792 \t loss: -175.655 \t return: -237.857 \t ep_len: 238.857\n",
      "epoch: 793 \t loss: -152.608 \t return: -168.613 \t ep_len: 169.613\n",
      "epoch: 794 \t loss: -144.077 \t return: -144.029 \t ep_len: 145.029\n",
      "epoch: 795 \t loss: -166.799 \t return: -153.606 \t ep_len: 154.606\n",
      "epoch: 796 \t loss: -145.552 \t return: -183.500 \t ep_len: 184.500\n",
      "epoch: 797 \t loss: -120.908 \t return: -186.370 \t ep_len: 187.370\n",
      "epoch: 798 \t loss: -95.787 \t return: -136.027 \t ep_len: 137.027\n",
      "epoch: 799 \t loss: -204.019 \t return: -238.048 \t ep_len: 239.048\n",
      "epoch: 800 \t loss: -156.605 \t return: -192.962 \t ep_len: 193.962\n",
      "epoch: 801 \t loss: -150.791 \t return: -162.875 \t ep_len: 163.875\n",
      "epoch: 802 \t loss: -173.867 \t return: -147.088 \t ep_len: 148.088\n",
      "epoch: 803 \t loss: -135.121 \t return: -165.767 \t ep_len: 166.767\n",
      "epoch: 804 \t loss: -115.118 \t return: -138.946 \t ep_len: 139.946\n",
      "epoch: 805 \t loss: -121.046 \t return: -162.161 \t ep_len: 163.161\n",
      "epoch: 806 \t loss: -121.188 \t return: -154.343 \t ep_len: 155.343\n",
      "epoch: 807 \t loss: -109.477 \t return: -142.278 \t ep_len: 143.278\n",
      "epoch: 808 \t loss: -148.720 \t return: -181.483 \t ep_len: 182.483\n",
      "epoch: 809 \t loss: -109.642 \t return: -141.778 \t ep_len: 142.778\n",
      "epoch: 810 \t loss: -143.910 \t return: -208.875 \t ep_len: 209.875\n",
      "epoch: 811 \t loss: -85.114 \t return: -114.250 \t ep_len: 115.250\n",
      "epoch: 812 \t loss: -152.423 \t return: -187.750 \t ep_len: 188.750\n",
      "epoch: 813 \t loss: -148.345 \t return: -166.333 \t ep_len: 167.333\n",
      "epoch: 814 \t loss: -121.579 \t return: -165.258 \t ep_len: 166.258\n",
      "epoch: 815 \t loss: -112.528 \t return: -144.457 \t ep_len: 145.457\n",
      "epoch: 816 \t loss: -222.753 \t return: -211.208 \t ep_len: 212.167\n",
      "epoch: 817 \t loss: -121.737 \t return: -155.647 \t ep_len: 156.647\n",
      "epoch: 818 \t loss: -124.157 \t return: -154.970 \t ep_len: 155.970\n",
      "epoch: 819 \t loss: -116.464 \t return: -173.241 \t ep_len: 174.241\n",
      "epoch: 820 \t loss: -122.856 \t return: -168.500 \t ep_len: 169.500\n",
      "epoch: 821 \t loss: -138.714 \t return: -189.000 \t ep_len: 190.000\n",
      "epoch: 822 \t loss: -194.793 \t return: -194.577 \t ep_len: 195.538\n",
      "epoch: 823 \t loss: -147.148 \t return: -200.269 \t ep_len: 201.269\n",
      "epoch: 824 \t loss: -184.618 \t return: -243.381 \t ep_len: 244.381\n",
      "epoch: 825 \t loss: -115.039 \t return: -159.812 \t ep_len: 160.812\n",
      "epoch: 826 \t loss: -207.270 \t return: -220.042 \t ep_len: 221.000\n",
      "epoch: 827 \t loss: -113.494 \t return: -167.467 \t ep_len: 168.467\n",
      "epoch: 828 \t loss: -231.726 \t return: -192.769 \t ep_len: 193.769\n",
      "epoch: 829 \t loss: -107.760 \t return: -146.800 \t ep_len: 147.800\n",
      "epoch: 830 \t loss: -161.994 \t return: -217.708 \t ep_len: 218.708\n",
      "epoch: 831 \t loss: -229.501 \t return: -242.810 \t ep_len: 243.810\n",
      "epoch: 832 \t loss: -171.962 \t return: -195.000 \t ep_len: 196.000\n",
      "epoch: 833 \t loss: -173.338 \t return: -163.355 \t ep_len: 164.355\n",
      "epoch: 834 \t loss: -115.065 \t return: -153.909 \t ep_len: 154.909\n",
      "epoch: 835 \t loss: -168.579 \t return: -161.500 \t ep_len: 162.500\n",
      "epoch: 836 \t loss: -156.720 \t return: -143.657 \t ep_len: 144.657\n",
      "epoch: 837 \t loss: -90.926 \t return: -135.216 \t ep_len: 136.216\n",
      "epoch: 838 \t loss: -143.726 \t return: -195.885 \t ep_len: 196.885\n",
      "epoch: 839 \t loss: -101.902 \t return: -137.972 \t ep_len: 138.972\n",
      "epoch: 840 \t loss: -132.554 \t return: -134.895 \t ep_len: 135.895\n",
      "epoch: 841 \t loss: -191.924 \t return: -190.778 \t ep_len: 191.778\n",
      "epoch: 842 \t loss: -148.090 \t return: -166.000 \t ep_len: 167.000\n",
      "epoch: 843 \t loss: -127.453 \t return: -185.679 \t ep_len: 186.679\n",
      "epoch: 844 \t loss: -110.203 \t return: -156.312 \t ep_len: 157.312\n",
      "epoch: 845 \t loss: -139.949 \t return: -166.067 \t ep_len: 167.067\n",
      "epoch: 846 \t loss: -154.863 \t return: -200.800 \t ep_len: 201.800\n",
      "epoch: 847 \t loss: -221.991 \t return: -216.417 \t ep_len: 217.375\n",
      "epoch: 848 \t loss: -241.528 \t return: -253.095 \t ep_len: 254.048\n",
      "epoch: 849 \t loss: -123.101 \t return: -178.679 \t ep_len: 179.679\n",
      "epoch: 850 \t loss: -207.739 \t return: -240.714 \t ep_len: 241.714\n",
      "epoch: 851 \t loss: -119.443 \t return: -180.429 \t ep_len: 181.429\n",
      "epoch: 852 \t loss: -138.651 \t return: -196.885 \t ep_len: 197.885\n",
      "epoch: 853 \t loss: -177.445 \t return: -250.857 \t ep_len: 251.857\n",
      "epoch: 854 \t loss: -125.444 \t return: -172.167 \t ep_len: 173.167\n",
      "epoch: 855 \t loss: -181.931 \t return: -232.667 \t ep_len: 233.667\n",
      "epoch: 856 \t loss: -117.061 \t return: -144.472 \t ep_len: 145.472\n",
      "epoch: 857 \t loss: -141.156 \t return: -226.773 \t ep_len: 227.773\n",
      "epoch: 858 \t loss: -137.943 \t return: -190.111 \t ep_len: 191.111\n",
      "epoch: 859 \t loss: -184.101 \t return: -264.684 \t ep_len: 265.684\n",
      "epoch: 860 \t loss: -120.293 \t return: -163.452 \t ep_len: 164.452\n",
      "epoch: 861 \t loss: -162.532 \t return: -182.500 \t ep_len: 183.500\n",
      "epoch: 862 \t loss: -107.029 \t return: -157.875 \t ep_len: 158.875\n",
      "epoch: 863 \t loss: -93.971 \t return: -135.243 \t ep_len: 136.243\n",
      "epoch: 864 \t loss: -135.318 \t return: -178.964 \t ep_len: 179.964\n",
      "epoch: 865 \t loss: -113.041 \t return: -151.559 \t ep_len: 152.559\n",
      "epoch: 866 \t loss: -143.931 \t return: -192.296 \t ep_len: 193.296\n",
      "epoch: 867 \t loss: -125.245 \t return: -186.862 \t ep_len: 187.862\n",
      "epoch: 868 \t loss: -155.562 \t return: -214.692 \t ep_len: 215.692\n",
      "epoch: 869 \t loss: -178.693 \t return: -204.000 \t ep_len: 205.000\n",
      "epoch: 870 \t loss: -177.600 \t return: -213.731 \t ep_len: 214.731\n",
      "epoch: 871 \t loss: -183.591 \t return: -199.360 \t ep_len: 200.360\n",
      "epoch: 872 \t loss: -157.481 \t return: -238.000 \t ep_len: 239.000\n",
      "epoch: 873 \t loss: -164.846 \t return: -193.885 \t ep_len: 194.885\n",
      "epoch: 874 \t loss: -131.139 \t return: -196.577 \t ep_len: 197.577\n",
      "epoch: 875 \t loss: -151.385 \t return: -219.435 \t ep_len: 220.435\n",
      "epoch: 876 \t loss: -128.068 \t return: -190.286 \t ep_len: 191.286\n",
      "epoch: 877 \t loss: -140.063 \t return: -217.652 \t ep_len: 218.652\n",
      "epoch: 878 \t loss: -146.720 \t return: -201.080 \t ep_len: 202.080\n",
      "epoch: 879 \t loss: -171.345 \t return: -234.708 \t ep_len: 235.708\n",
      "epoch: 880 \t loss: -100.870 \t return: -152.879 \t ep_len: 153.879\n",
      "epoch: 881 \t loss: -97.183 \t return: -174.207 \t ep_len: 175.207\n",
      "epoch: 882 \t loss: -139.039 \t return: -180.357 \t ep_len: 181.357\n",
      "epoch: 883 \t loss: -121.497 \t return: -186.185 \t ep_len: 187.185\n",
      "epoch: 884 \t loss: -94.086 \t return: -126.400 \t ep_len: 127.400\n",
      "epoch: 885 \t loss: -197.528 \t return: -227.455 \t ep_len: 228.455\n",
      "epoch: 886 \t loss: -134.656 \t return: -147.139 \t ep_len: 148.139\n",
      "epoch: 887 \t loss: -107.474 \t return: -140.750 \t ep_len: 141.750\n",
      "epoch: 888 \t loss: -104.855 \t return: -172.448 \t ep_len: 173.448\n",
      "epoch: 889 \t loss: -106.224 \t return: -147.382 \t ep_len: 148.382\n",
      "epoch: 890 \t loss: -164.757 \t return: -198.192 \t ep_len: 199.192\n",
      "epoch: 891 \t loss: -146.699 \t return: -179.143 \t ep_len: 180.143\n",
      "epoch: 892 \t loss: -156.994 \t return: -162.419 \t ep_len: 163.419\n",
      "epoch: 893 \t loss: -123.178 \t return: -175.552 \t ep_len: 176.552\n",
      "epoch: 894 \t loss: -190.255 \t return: -213.875 \t ep_len: 214.875\n",
      "epoch: 895 \t loss: -93.737 \t return: -147.471 \t ep_len: 148.471\n",
      "epoch: 896 \t loss: -112.914 \t return: -143.371 \t ep_len: 144.371\n",
      "epoch: 897 \t loss: -111.140 \t return: -138.556 \t ep_len: 139.556\n",
      "epoch: 898 \t loss: -95.311 \t return: -153.485 \t ep_len: 154.485\n",
      "epoch: 899 \t loss: -143.716 \t return: -165.871 \t ep_len: 166.871\n",
      "epoch: 900 \t loss: -103.039 \t return: -146.714 \t ep_len: 147.714\n",
      "epoch: 901 \t loss: -97.511 \t return: -146.472 \t ep_len: 147.472\n",
      "epoch: 902 \t loss: -114.061 \t return: -133.842 \t ep_len: 134.842\n",
      "epoch: 903 \t loss: -122.828 \t return: -151.394 \t ep_len: 152.394\n",
      "epoch: 904 \t loss: -115.665 \t return: -220.391 \t ep_len: 221.391\n",
      "epoch: 905 \t loss: -92.082 \t return: -137.757 \t ep_len: 138.757\n",
      "epoch: 906 \t loss: -86.860 \t return: -116.178 \t ep_len: 117.178\n",
      "epoch: 907 \t loss: -112.180 \t return: -142.833 \t ep_len: 143.833\n",
      "epoch: 908 \t loss: -116.052 \t return: -151.939 \t ep_len: 152.939\n",
      "epoch: 909 \t loss: -102.980 \t return: -135.108 \t ep_len: 136.108\n",
      "epoch: 910 \t loss: -99.793 \t return: -152.212 \t ep_len: 153.212\n",
      "epoch: 911 \t loss: -128.977 \t return: -151.059 \t ep_len: 152.059\n",
      "epoch: 912 \t loss: -121.032 \t return: -160.156 \t ep_len: 161.156\n",
      "epoch: 913 \t loss: -96.166 \t return: -163.344 \t ep_len: 164.344\n",
      "epoch: 914 \t loss: -180.864 \t return: -183.344 \t ep_len: 184.312\n",
      "epoch: 915 \t loss: -115.916 \t return: -161.387 \t ep_len: 162.387\n",
      "epoch: 916 \t loss: -140.910 \t return: -180.929 \t ep_len: 181.929\n",
      "epoch: 917 \t loss: -117.042 \t return: -150.636 \t ep_len: 151.636\n",
      "epoch: 918 \t loss: -131.863 \t return: -156.844 \t ep_len: 157.844\n",
      "epoch: 919 \t loss: -129.164 \t return: -137.972 \t ep_len: 138.972\n",
      "epoch: 920 \t loss: -102.693 \t return: -143.314 \t ep_len: 144.314\n",
      "epoch: 921 \t loss: -176.611 \t return: -173.000 \t ep_len: 174.000\n",
      "epoch: 922 \t loss: -84.802 \t return: -124.390 \t ep_len: 125.390\n",
      "epoch: 923 \t loss: -113.022 \t return: -156.188 \t ep_len: 157.188\n",
      "epoch: 924 \t loss: -139.820 \t return: -185.667 \t ep_len: 186.667\n",
      "epoch: 925 \t loss: -107.716 \t return: -149.588 \t ep_len: 150.588\n",
      "epoch: 926 \t loss: -82.863 \t return: -124.683 \t ep_len: 125.683\n",
      "epoch: 927 \t loss: -116.012 \t return: -172.000 \t ep_len: 173.000\n",
      "epoch: 928 \t loss: -117.168 \t return: -137.108 \t ep_len: 138.108\n",
      "epoch: 929 \t loss: -68.691 \t return: -119.000 \t ep_len: 120.000\n",
      "epoch: 930 \t loss: -147.481 \t return: -172.828 \t ep_len: 173.828\n",
      "epoch: 931 \t loss: -114.887 \t return: -130.436 \t ep_len: 131.436\n",
      "epoch: 932 \t loss: -173.796 \t return: -179.643 \t ep_len: 180.643\n",
      "epoch: 933 \t loss: -170.182 \t return: -178.586 \t ep_len: 179.586\n",
      "epoch: 934 \t loss: -124.367 \t return: -164.848 \t ep_len: 165.848\n",
      "epoch: 935 \t loss: -185.914 \t return: -184.630 \t ep_len: 185.630\n",
      "epoch: 936 \t loss: -84.500 \t return: -130.400 \t ep_len: 131.400\n",
      "epoch: 937 \t loss: -63.359 \t return: -100.140 \t ep_len: 101.140\n",
      "epoch: 938 \t loss: -93.279 \t return: -127.974 \t ep_len: 128.974\n",
      "epoch: 939 \t loss: -88.138 \t return: -154.727 \t ep_len: 155.727\n",
      "epoch: 940 \t loss: -109.166 \t return: -148.294 \t ep_len: 149.294\n",
      "epoch: 941 \t loss: -115.166 \t return: -149.059 \t ep_len: 150.059\n",
      "epoch: 942 \t loss: -115.646 \t return: -168.167 \t ep_len: 169.167\n",
      "epoch: 943 \t loss: -92.745 \t return: -131.658 \t ep_len: 132.658\n",
      "epoch: 944 \t loss: -135.092 \t return: -192.074 \t ep_len: 193.074\n",
      "epoch: 945 \t loss: -130.753 \t return: -160.156 \t ep_len: 161.156\n",
      "epoch: 946 \t loss: -89.157 \t return: -142.171 \t ep_len: 143.171\n",
      "epoch: 947 \t loss: -78.769 \t return: -126.150 \t ep_len: 127.150\n",
      "epoch: 948 \t loss: -110.570 \t return: -159.438 \t ep_len: 160.438\n",
      "epoch: 949 \t loss: -89.586 \t return: -130.737 \t ep_len: 131.737\n",
      "epoch: 950 \t loss: -101.938 \t return: -143.114 \t ep_len: 144.114\n",
      "epoch: 951 \t loss: -103.907 \t return: -156.438 \t ep_len: 157.438\n",
      "epoch: 952 \t loss: -182.121 \t return: -199.040 \t ep_len: 200.040\n",
      "epoch: 953 \t loss: -130.983 \t return: -168.600 \t ep_len: 169.600\n",
      "epoch: 954 \t loss: -116.769 \t return: -168.871 \t ep_len: 169.871\n",
      "epoch: 955 \t loss: -105.385 \t return: -170.600 \t ep_len: 171.600\n",
      "epoch: 956 \t loss: -124.726 \t return: -161.500 \t ep_len: 162.500\n",
      "epoch: 957 \t loss: -101.715 \t return: -127.625 \t ep_len: 128.625\n",
      "epoch: 958 \t loss: -85.937 \t return: -130.842 \t ep_len: 131.842\n",
      "epoch: 959 \t loss: -145.039 \t return: -178.900 \t ep_len: 179.900\n",
      "epoch: 960 \t loss: -147.937 \t return: -152.265 \t ep_len: 153.265\n",
      "epoch: 961 \t loss: -118.973 \t return: -151.083 \t ep_len: 152.083\n",
      "epoch: 962 \t loss: -105.653 \t return: -143.600 \t ep_len: 144.600\n",
      "epoch: 963 \t loss: -132.109 \t return: -151.194 \t ep_len: 152.194\n",
      "epoch: 964 \t loss: -106.250 \t return: -137.297 \t ep_len: 138.297\n",
      "epoch: 965 \t loss: -106.584 \t return: -142.361 \t ep_len: 143.361\n",
      "epoch: 966 \t loss: -119.508 \t return: -158.469 \t ep_len: 159.469\n",
      "epoch: 967 \t loss: -125.935 \t return: -136.486 \t ep_len: 137.486\n",
      "epoch: 968 \t loss: -123.851 \t return: -189.000 \t ep_len: 190.000\n",
      "epoch: 969 \t loss: -166.303 \t return: -194.808 \t ep_len: 195.808\n",
      "epoch: 970 \t loss: -154.087 \t return: -171.655 \t ep_len: 172.655\n",
      "epoch: 971 \t loss: -119.325 \t return: -135.757 \t ep_len: 136.757\n",
      "epoch: 972 \t loss: -114.557 \t return: -162.806 \t ep_len: 163.806\n",
      "epoch: 973 \t loss: -141.273 \t return: -182.964 \t ep_len: 183.964\n",
      "epoch: 974 \t loss: -123.714 \t return: -139.222 \t ep_len: 140.222\n",
      "epoch: 975 \t loss: -155.517 \t return: -197.154 \t ep_len: 198.154\n",
      "epoch: 976 \t loss: -149.356 \t return: -172.483 \t ep_len: 173.483\n",
      "epoch: 977 \t loss: -170.232 \t return: -194.423 \t ep_len: 195.423\n",
      "epoch: 978 \t loss: -106.774 \t return: -146.400 \t ep_len: 147.400\n",
      "epoch: 979 \t loss: -127.392 \t return: -166.200 \t ep_len: 167.200\n",
      "epoch: 980 \t loss: -102.091 \t return: -142.806 \t ep_len: 143.806\n",
      "epoch: 981 \t loss: -102.078 \t return: -161.129 \t ep_len: 162.129\n",
      "epoch: 982 \t loss: -94.879 \t return: -128.256 \t ep_len: 129.256\n",
      "epoch: 983 \t loss: -103.731 \t return: -137.108 \t ep_len: 138.108\n",
      "epoch: 984 \t loss: -122.362 \t return: -145.029 \t ep_len: 146.029\n",
      "epoch: 985 \t loss: -103.728 \t return: -137.132 \t ep_len: 138.132\n",
      "epoch: 986 \t loss: -148.800 \t return: -163.871 \t ep_len: 164.871\n",
      "epoch: 987 \t loss: -118.100 \t return: -157.030 \t ep_len: 158.030\n",
      "epoch: 988 \t loss: -115.989 \t return: -169.400 \t ep_len: 170.400\n",
      "epoch: 989 \t loss: -133.915 \t return: -169.767 \t ep_len: 170.767\n",
      "epoch: 990 \t loss: -160.556 \t return: -184.179 \t ep_len: 185.179\n",
      "epoch: 991 \t loss: -116.890 \t return: -167.600 \t ep_len: 168.600\n",
      "epoch: 992 \t loss: -109.203 \t return: -138.250 \t ep_len: 139.250\n",
      "epoch: 993 \t loss: -110.036 \t return: -135.179 \t ep_len: 136.179\n",
      "epoch: 994 \t loss: -93.124 \t return: -146.971 \t ep_len: 147.971\n",
      "epoch: 995 \t loss: -89.213 \t return: -147.647 \t ep_len: 148.647\n",
      "epoch: 996 \t loss: -111.841 \t return: -156.656 \t ep_len: 157.656\n",
      "epoch: 997 \t loss: -74.449 \t return: -113.614 \t ep_len: 114.614\n",
      "epoch: 998 \t loss: -79.734 \t return: -126.425 \t ep_len: 127.425\n",
      "epoch: 999 \t loss: -98.133 \t return: -133.184 \t ep_len: 134.184\n",
      "epoch: 1000 \t loss: -82.457 \t return: -124.800 \t ep_len: 125.800\n",
      "epoch: 1001 \t loss: -77.496 \t return: -138.053 \t ep_len: 139.053\n",
      "epoch: 1002 \t loss: -83.828 \t return: -146.088 \t ep_len: 147.088\n",
      "epoch: 1003 \t loss: -127.882 \t return: -130.590 \t ep_len: 131.564\n",
      "epoch: 1004 \t loss: -90.043 \t return: -122.756 \t ep_len: 123.756\n",
      "epoch: 1005 \t loss: -92.254 \t return: -161.032 \t ep_len: 162.032\n",
      "epoch: 1006 \t loss: -78.792 \t return: -165.900 \t ep_len: 166.900\n",
      "epoch: 1007 \t loss: -71.198 \t return: -110.326 \t ep_len: 111.326\n",
      "epoch: 1008 \t loss: -93.668 \t return: -142.171 \t ep_len: 143.171\n",
      "epoch: 1009 \t loss: -80.946 \t return: -128.026 \t ep_len: 129.026\n",
      "epoch: 1010 \t loss: -89.045 \t return: -151.606 \t ep_len: 152.606\n",
      "epoch: 1011 \t loss: -84.807 \t return: -131.632 \t ep_len: 132.632\n",
      "epoch: 1012 \t loss: -100.012 \t return: -132.122 \t ep_len: 133.122\n",
      "epoch: 1013 \t loss: -65.415 \t return: -114.500 \t ep_len: 115.500\n",
      "epoch: 1014 \t loss: -79.837 \t return: -133.949 \t ep_len: 134.949\n",
      "epoch: 1015 \t loss: -86.720 \t return: -129.200 \t ep_len: 130.200\n",
      "epoch: 1016 \t loss: -52.126 \t return: -98.392 \t ep_len: 99.392\n",
      "epoch: 1017 \t loss: -80.385 \t return: -147.088 \t ep_len: 148.088\n",
      "epoch: 1018 \t loss: -97.837 \t return: -154.182 \t ep_len: 155.182\n",
      "epoch: 1019 \t loss: -95.272 \t return: -128.026 \t ep_len: 129.026\n",
      "epoch: 1020 \t loss: -106.523 \t return: -131.342 \t ep_len: 132.342\n",
      "epoch: 1021 \t loss: -81.618 \t return: -134.486 \t ep_len: 135.486\n",
      "epoch: 1022 \t loss: -68.146 \t return: -115.977 \t ep_len: 116.977\n",
      "epoch: 1023 \t loss: -67.654 \t return: -111.761 \t ep_len: 112.761\n",
      "epoch: 1024 \t loss: -62.986 \t return: -134.270 \t ep_len: 135.243\n",
      "epoch: 1025 \t loss: -66.507 \t return: -115.674 \t ep_len: 116.674\n",
      "epoch: 1026 \t loss: -66.431 \t return: -111.022 \t ep_len: 112.022\n",
      "epoch: 1027 \t loss: -58.574 \t return: -114.044 \t ep_len: 115.044\n",
      "epoch: 1028 \t loss: -67.573 \t return: -118.405 \t ep_len: 119.405\n",
      "epoch: 1029 \t loss: -111.831 \t return: -143.000 \t ep_len: 144.000\n",
      "epoch: 1030 \t loss: -62.095 \t return: -116.372 \t ep_len: 117.372\n",
      "epoch: 1031 \t loss: -59.822 \t return: -100.300 \t ep_len: 101.300\n",
      "epoch: 1032 \t loss: -64.425 \t return: -106.213 \t ep_len: 107.213\n",
      "epoch: 1033 \t loss: -87.967 \t return: -121.049 \t ep_len: 122.049\n",
      "epoch: 1034 \t loss: -100.863 \t return: -127.282 \t ep_len: 128.282\n",
      "epoch: 1035 \t loss: -76.915 \t return: -128.025 \t ep_len: 129.025\n",
      "epoch: 1036 \t loss: -55.367 \t return: -112.644 \t ep_len: 113.644\n",
      "epoch: 1037 \t loss: -55.876 \t return: -122.095 \t ep_len: 123.095\n",
      "epoch: 1038 \t loss: -121.895 \t return: -193.115 \t ep_len: 194.115\n",
      "epoch: 1039 \t loss: -69.415 \t return: -128.225 \t ep_len: 129.225\n",
      "epoch: 1040 \t loss: -75.209 \t return: -151.242 \t ep_len: 152.242\n",
      "epoch: 1041 \t loss: -61.134 \t return: -119.071 \t ep_len: 120.071\n",
      "epoch: 1042 \t loss: -75.440 \t return: -140.278 \t ep_len: 141.278\n",
      "epoch: 1043 \t loss: -56.046 \t return: -114.822 \t ep_len: 115.822\n",
      "epoch: 1044 \t loss: -59.321 \t return: -116.023 \t ep_len: 117.023\n",
      "epoch: 1045 \t loss: -63.179 \t return: -110.022 \t ep_len: 111.022\n",
      "epoch: 1046 \t loss: -55.093 \t return: -113.000 \t ep_len: 114.000\n",
      "epoch: 1047 \t loss: -65.320 \t return: -128.128 \t ep_len: 129.128\n",
      "epoch: 1048 \t loss: -69.943 \t return: -118.548 \t ep_len: 119.548\n",
      "epoch: 1049 \t loss: -69.371 \t return: -133.897 \t ep_len: 134.897\n",
      "epoch: 1050 \t loss: -76.881 \t return: -133.842 \t ep_len: 134.842\n",
      "epoch: 1051 \t loss: -87.559 \t return: -143.028 \t ep_len: 144.028\n",
      "epoch: 1052 \t loss: -70.278 \t return: -119.286 \t ep_len: 120.286\n",
      "epoch: 1053 \t loss: -78.376 \t return: -119.810 \t ep_len: 120.810\n",
      "epoch: 1054 \t loss: -51.614 \t return: -97.078 \t ep_len: 98.078\n",
      "epoch: 1055 \t loss: -62.830 \t return: -120.929 \t ep_len: 121.929\n",
      "epoch: 1056 \t loss: -77.219 \t return: -150.794 \t ep_len: 151.794\n",
      "epoch: 1057 \t loss: -100.363 \t return: -159.273 \t ep_len: 160.273\n",
      "epoch: 1058 \t loss: -63.909 \t return: -113.422 \t ep_len: 114.422\n",
      "epoch: 1059 \t loss: -48.723 \t return: -97.902 \t ep_len: 98.902\n",
      "epoch: 1060 \t loss: -61.117 \t return: -123.167 \t ep_len: 124.167\n",
      "epoch: 1061 \t loss: -57.462 \t return: -115.250 \t ep_len: 116.250\n",
      "epoch: 1062 \t loss: -72.236 \t return: -127.513 \t ep_len: 128.513\n",
      "epoch: 1063 \t loss: -67.459 \t return: -130.564 \t ep_len: 131.564\n",
      "epoch: 1064 \t loss: -67.285 \t return: -118.690 \t ep_len: 119.690\n",
      "epoch: 1065 \t loss: -78.642 \t return: -131.949 \t ep_len: 132.949\n",
      "epoch: 1066 \t loss: -63.107 \t return: -115.907 \t ep_len: 116.907\n",
      "epoch: 1067 \t loss: -51.681 \t return: -108.277 \t ep_len: 109.277\n",
      "epoch: 1068 \t loss: -69.533 \t return: -121.829 \t ep_len: 122.829\n",
      "epoch: 1069 \t loss: -65.331 \t return: -122.732 \t ep_len: 123.732\n",
      "epoch: 1070 \t loss: -54.500 \t return: -112.909 \t ep_len: 113.909\n",
      "epoch: 1071 \t loss: -85.747 \t return: -126.125 \t ep_len: 127.125\n",
      "epoch: 1072 \t loss: -55.912 \t return: -115.674 \t ep_len: 116.674\n",
      "epoch: 1073 \t loss: -70.708 \t return: -124.675 \t ep_len: 125.675\n",
      "epoch: 1074 \t loss: -54.281 \t return: -120.651 \t ep_len: 121.651\n",
      "epoch: 1075 \t loss: -61.219 \t return: -123.976 \t ep_len: 124.976\n",
      "epoch: 1076 \t loss: -60.880 \t return: -124.775 \t ep_len: 125.775\n",
      "epoch: 1077 \t loss: -102.048 \t return: -149.771 \t ep_len: 150.771\n",
      "epoch: 1078 \t loss: -101.147 \t return: -134.816 \t ep_len: 135.816\n",
      "epoch: 1079 \t loss: -73.260 \t return: -128.974 \t ep_len: 129.974\n",
      "epoch: 1080 \t loss: -93.354 \t return: -142.343 \t ep_len: 143.343\n",
      "epoch: 1081 \t loss: -98.445 \t return: -160.806 \t ep_len: 161.806\n",
      "epoch: 1082 \t loss: -104.077 \t return: -144.086 \t ep_len: 145.086\n",
      "epoch: 1083 \t loss: -108.292 \t return: -166.300 \t ep_len: 167.300\n",
      "epoch: 1084 \t loss: -105.050 \t return: -143.286 \t ep_len: 144.286\n",
      "epoch: 1085 \t loss: -92.569 \t return: -173.138 \t ep_len: 174.138\n",
      "epoch: 1086 \t loss: -145.086 \t return: -168.400 \t ep_len: 169.400\n",
      "epoch: 1087 \t loss: -122.983 \t return: -167.848 \t ep_len: 168.848\n",
      "epoch: 1088 \t loss: -72.512 \t return: -117.442 \t ep_len: 118.442\n",
      "epoch: 1089 \t loss: -81.681 \t return: -131.128 \t ep_len: 132.128\n",
      "epoch: 1090 \t loss: -125.950 \t return: -143.270 \t ep_len: 144.270\n",
      "epoch: 1091 \t loss: -115.103 \t return: -155.971 \t ep_len: 156.971\n",
      "epoch: 1092 \t loss: -110.091 \t return: -157.031 \t ep_len: 158.031\n",
      "epoch: 1093 \t loss: -141.575 \t return: -166.364 \t ep_len: 167.364\n",
      "epoch: 1094 \t loss: -173.997 \t return: -246.348 \t ep_len: 247.348\n",
      "epoch: 1095 \t loss: -113.187 \t return: -144.314 \t ep_len: 145.314\n",
      "epoch: 1096 \t loss: -100.584 \t return: -147.486 \t ep_len: 148.486\n",
      "epoch: 1097 \t loss: -89.637 \t return: -114.000 \t ep_len: 115.000\n",
      "epoch: 1098 \t loss: -85.953 \t return: -127.769 \t ep_len: 128.769\n",
      "epoch: 1099 \t loss: -119.333 \t return: -161.219 \t ep_len: 162.219\n",
      "epoch: 1100 \t loss: -107.588 \t return: -133.211 \t ep_len: 134.211\n",
      "epoch: 1101 \t loss: -95.103 \t return: -139.250 \t ep_len: 140.250\n",
      "epoch: 1102 \t loss: -93.104 \t return: -133.231 \t ep_len: 134.231\n",
      "epoch: 1103 \t loss: -101.188 \t return: -153.303 \t ep_len: 154.303\n",
      "epoch: 1104 \t loss: -84.566 \t return: -132.263 \t ep_len: 133.263\n",
      "epoch: 1105 \t loss: -78.446 \t return: -126.878 \t ep_len: 127.878\n",
      "epoch: 1106 \t loss: -63.094 \t return: -113.044 \t ep_len: 114.044\n",
      "epoch: 1107 \t loss: -71.771 \t return: -126.415 \t ep_len: 127.415\n",
      "epoch: 1108 \t loss: -106.860 \t return: -169.000 \t ep_len: 170.000\n",
      "epoch: 1109 \t loss: -92.860 \t return: -147.222 \t ep_len: 148.222\n",
      "epoch: 1110 \t loss: -109.136 \t return: -156.375 \t ep_len: 157.375\n",
      "epoch: 1111 \t loss: -98.391 \t return: -137.132 \t ep_len: 138.132\n",
      "epoch: 1112 \t loss: -85.678 \t return: -135.514 \t ep_len: 136.514\n",
      "epoch: 1113 \t loss: -100.441 \t return: -148.657 \t ep_len: 149.657\n",
      "epoch: 1114 \t loss: -97.773 \t return: -165.355 \t ep_len: 166.355\n",
      "epoch: 1115 \t loss: -91.970 \t return: -138.333 \t ep_len: 139.333\n",
      "epoch: 1116 \t loss: -107.359 \t return: -161.576 \t ep_len: 162.576\n",
      "epoch: 1117 \t loss: -82.159 \t return: -119.116 \t ep_len: 120.116\n",
      "epoch: 1118 \t loss: -88.052 \t return: -133.342 \t ep_len: 134.342\n",
      "epoch: 1119 \t loss: -169.597 \t return: -245.682 \t ep_len: 246.682\n",
      "epoch: 1120 \t loss: -95.935 \t return: -160.387 \t ep_len: 161.387\n",
      "epoch: 1121 \t loss: -100.075 \t return: -173.276 \t ep_len: 174.276\n",
      "epoch: 1122 \t loss: -98.740 \t return: -141.750 \t ep_len: 142.750\n",
      "epoch: 1123 \t loss: -97.348 \t return: -153.242 \t ep_len: 154.242\n",
      "epoch: 1124 \t loss: -64.823 \t return: -108.413 \t ep_len: 109.413\n",
      "epoch: 1125 \t loss: -85.002 \t return: -159.625 \t ep_len: 160.625\n",
      "epoch: 1126 \t loss: -66.572 \t return: -130.605 \t ep_len: 131.605\n",
      "epoch: 1127 \t loss: -58.027 \t return: -108.935 \t ep_len: 109.935\n",
      "epoch: 1128 \t loss: -67.757 \t return: -124.875 \t ep_len: 125.875\n",
      "epoch: 1129 \t loss: -70.103 \t return: -110.696 \t ep_len: 111.696\n",
      "epoch: 1130 \t loss: -77.347 \t return: -138.730 \t ep_len: 139.730\n",
      "epoch: 1131 \t loss: -111.159 \t return: -128.026 \t ep_len: 129.026\n",
      "epoch: 1132 \t loss: -72.071 \t return: -138.514 \t ep_len: 139.514\n",
      "epoch: 1133 \t loss: -67.394 \t return: -111.000 \t ep_len: 112.000\n",
      "epoch: 1134 \t loss: -57.894 \t return: -106.468 \t ep_len: 107.468\n",
      "epoch: 1135 \t loss: -61.397 \t return: -117.465 \t ep_len: 118.465\n",
      "epoch: 1136 \t loss: -47.091 \t return: -94.000 \t ep_len: 95.000\n",
      "epoch: 1137 \t loss: -73.954 \t return: -138.833 \t ep_len: 139.833\n",
      "epoch: 1138 \t loss: -69.098 \t return: -129.872 \t ep_len: 130.872\n",
      "epoch: 1139 \t loss: -56.052 \t return: -117.209 \t ep_len: 118.209\n",
      "epoch: 1140 \t loss: -56.247 \t return: -113.591 \t ep_len: 114.591\n",
      "epoch: 1141 \t loss: -59.284 \t return: -117.302 \t ep_len: 118.302\n",
      "epoch: 1142 \t loss: -58.364 \t return: -117.442 \t ep_len: 118.442\n",
      "epoch: 1143 \t loss: -49.133 \t return: -101.780 \t ep_len: 102.780\n",
      "epoch: 1144 \t loss: -51.426 \t return: -107.208 \t ep_len: 108.208\n",
      "epoch: 1145 \t loss: -77.338 \t return: -120.214 \t ep_len: 121.214\n",
      "epoch: 1146 \t loss: -76.523 \t return: -128.179 \t ep_len: 129.179\n",
      "epoch: 1147 \t loss: -65.285 \t return: -122.707 \t ep_len: 123.707\n",
      "epoch: 1148 \t loss: -58.690 \t return: -115.659 \t ep_len: 116.659\n",
      "epoch: 1149 \t loss: -85.263 \t return: -140.861 \t ep_len: 141.861\n",
      "epoch: 1150 \t loss: -77.280 \t return: -114.244 \t ep_len: 115.244\n",
      "epoch: 1151 \t loss: -73.948 \t return: -130.868 \t ep_len: 131.868\n",
      "epoch: 1152 \t loss: -44.412 \t return: -92.389 \t ep_len: 93.389\n",
      "epoch: 1153 \t loss: -72.278 \t return: -113.244 \t ep_len: 114.244\n",
      "epoch: 1154 \t loss: -93.035 \t return: -132.053 \t ep_len: 133.053\n",
      "epoch: 1155 \t loss: -55.570 \t return: -105.979 \t ep_len: 106.979\n",
      "epoch: 1156 \t loss: -66.009 \t return: -116.419 \t ep_len: 117.419\n",
      "epoch: 1157 \t loss: -73.278 \t return: -108.043 \t ep_len: 109.043\n",
      "epoch: 1158 \t loss: -97.742 \t return: -134.769 \t ep_len: 135.769\n",
      "epoch: 1159 \t loss: -73.587 \t return: -121.366 \t ep_len: 122.366\n",
      "epoch: 1160 \t loss: -82.609 \t return: -115.558 \t ep_len: 116.558\n",
      "epoch: 1161 \t loss: -44.115 \t return: -94.038 \t ep_len: 95.038\n",
      "epoch: 1162 \t loss: -67.948 \t return: -127.282 \t ep_len: 128.282\n",
      "epoch: 1163 \t loss: -77.297 \t return: -121.561 \t ep_len: 122.561\n",
      "epoch: 1164 \t loss: -57.591 \t return: -106.404 \t ep_len: 107.404\n",
      "epoch: 1165 \t loss: -68.377 \t return: -115.535 \t ep_len: 116.535\n",
      "epoch: 1166 \t loss: -46.434 \t return: -104.167 \t ep_len: 105.167\n",
      "epoch: 1167 \t loss: -103.014 \t return: -170.333 \t ep_len: 171.333\n",
      "epoch: 1168 \t loss: -80.748 \t return: -122.190 \t ep_len: 123.190\n",
      "epoch: 1169 \t loss: -65.172 \t return: -108.125 \t ep_len: 109.125\n",
      "epoch: 1170 \t loss: -67.654 \t return: -113.875 \t ep_len: 114.875\n",
      "epoch: 1171 \t loss: -54.831 \t return: -96.741 \t ep_len: 97.741\n",
      "epoch: 1172 \t loss: -58.743 \t return: -102.660 \t ep_len: 103.660\n",
      "epoch: 1173 \t loss: -65.265 \t return: -111.553 \t ep_len: 112.553\n",
      "epoch: 1174 \t loss: -84.260 \t return: -143.400 \t ep_len: 144.400\n",
      "epoch: 1175 \t loss: -131.886 \t return: -160.548 \t ep_len: 161.548\n",
      "epoch: 1176 \t loss: -60.698 \t return: -115.744 \t ep_len: 116.744\n",
      "epoch: 1177 \t loss: -90.711 \t return: -136.784 \t ep_len: 137.784\n",
      "epoch: 1178 \t loss: -57.183 \t return: -112.489 \t ep_len: 113.489\n",
      "epoch: 1179 \t loss: -62.868 \t return: -119.786 \t ep_len: 120.786\n",
      "epoch: 1180 \t loss: -49.010 \t return: -105.787 \t ep_len: 106.787\n",
      "epoch: 1181 \t loss: -51.104 \t return: -106.936 \t ep_len: 107.936\n",
      "epoch: 1182 \t loss: -49.351 \t return: -95.288 \t ep_len: 96.288\n",
      "epoch: 1183 \t loss: -82.471 \t return: -134.432 \t ep_len: 135.432\n",
      "epoch: 1184 \t loss: -69.222 \t return: -110.042 \t ep_len: 111.042\n",
      "epoch: 1185 \t loss: -44.922 \t return: -80.161 \t ep_len: 81.161\n",
      "epoch: 1186 \t loss: -44.106 \t return: -97.961 \t ep_len: 98.961\n",
      "epoch: 1187 \t loss: -49.920 \t return: -116.814 \t ep_len: 117.814\n",
      "epoch: 1188 \t loss: -73.082 \t return: -116.279 \t ep_len: 117.279\n",
      "epoch: 1189 \t loss: -66.143 \t return: -109.957 \t ep_len: 110.957\n",
      "epoch: 1190 \t loss: -41.354 \t return: -93.792 \t ep_len: 94.792\n",
      "epoch: 1191 \t loss: -52.706 \t return: -124.700 \t ep_len: 125.700\n",
      "epoch: 1192 \t loss: -41.060 \t return: -91.509 \t ep_len: 92.509\n",
      "epoch: 1193 \t loss: -64.241 \t return: -115.289 \t ep_len: 116.289\n",
      "epoch: 1194 \t loss: -48.367 \t return: -111.217 \t ep_len: 112.217\n",
      "epoch: 1195 \t loss: -48.970 \t return: -92.019 \t ep_len: 93.019\n",
      "epoch: 1196 \t loss: -45.836 \t return: -116.488 \t ep_len: 117.488\n",
      "epoch: 1197 \t loss: -44.719 \t return: -112.413 \t ep_len: 113.413\n",
      "epoch: 1198 \t loss: -34.907 \t return: -88.246 \t ep_len: 89.246\n",
      "epoch: 1199 \t loss: -54.332 \t return: -121.171 \t ep_len: 122.171\n",
      "epoch: 1200 \t loss: -46.338 \t return: -102.184 \t ep_len: 103.184\n",
      "epoch: 1201 \t loss: -49.843 \t return: -110.556 \t ep_len: 111.556\n",
      "epoch: 1202 \t loss: -50.451 \t return: -99.500 \t ep_len: 100.500\n",
      "epoch: 1203 \t loss: -43.369 \t return: -102.280 \t ep_len: 103.280\n",
      "epoch: 1204 \t loss: -42.076 \t return: -104.490 \t ep_len: 105.490\n",
      "epoch: 1205 \t loss: -36.108 \t return: -101.408 \t ep_len: 102.408\n",
      "epoch: 1206 \t loss: -34.967 \t return: -99.200 \t ep_len: 100.200\n",
      "epoch: 1207 \t loss: -49.540 \t return: -112.022 \t ep_len: 113.000\n",
      "epoch: 1208 \t loss: -41.320 \t return: -85.300 \t ep_len: 86.300\n",
      "epoch: 1209 \t loss: -48.562 \t return: -109.979 \t ep_len: 110.979\n",
      "epoch: 1210 \t loss: -45.622 \t return: -114.750 \t ep_len: 115.750\n",
      "epoch: 1211 \t loss: -33.520 \t return: -86.448 \t ep_len: 87.448\n",
      "epoch: 1212 \t loss: -54.468 \t return: -105.714 \t ep_len: 106.714\n",
      "epoch: 1213 \t loss: -42.391 \t return: -105.061 \t ep_len: 106.061\n",
      "epoch: 1214 \t loss: -56.117 \t return: -143.314 \t ep_len: 144.314\n",
      "epoch: 1215 \t loss: -43.103 \t return: -91.630 \t ep_len: 92.630\n",
      "epoch: 1216 \t loss: -44.975 \t return: -107.761 \t ep_len: 108.761\n",
      "epoch: 1217 \t loss: -38.810 \t return: -105.681 \t ep_len: 106.681\n",
      "epoch: 1218 \t loss: -50.988 \t return: -109.936 \t ep_len: 110.936\n",
      "epoch: 1219 \t loss: -69.521 \t return: -118.667 \t ep_len: 119.667\n",
      "epoch: 1220 \t loss: -48.878 \t return: -102.755 \t ep_len: 103.755\n",
      "epoch: 1221 \t loss: -38.428 \t return: -97.392 \t ep_len: 98.392\n",
      "epoch: 1222 \t loss: -40.615 \t return: -109.723 \t ep_len: 110.723\n",
      "epoch: 1223 \t loss: -36.320 \t return: -95.654 \t ep_len: 96.654\n",
      "epoch: 1224 \t loss: -42.068 \t return: -112.089 \t ep_len: 113.089\n",
      "epoch: 1225 \t loss: -58.874 \t return: -157.281 \t ep_len: 158.281\n",
      "epoch: 1226 \t loss: -36.099 \t return: -103.898 \t ep_len: 104.898\n",
      "epoch: 1227 \t loss: -67.539 \t return: -129.500 \t ep_len: 130.500\n",
      "epoch: 1228 \t loss: -40.209 \t return: -101.816 \t ep_len: 102.816\n",
      "epoch: 1229 \t loss: -52.300 \t return: -133.026 \t ep_len: 134.026\n",
      "epoch: 1230 \t loss: -41.948 \t return: -101.286 \t ep_len: 102.286\n",
      "epoch: 1231 \t loss: -31.809 \t return: -71.536 \t ep_len: 72.536\n",
      "epoch: 1232 \t loss: -30.536 \t return: -77.266 \t ep_len: 78.266\n",
      "epoch: 1233 \t loss: -45.175 \t return: -102.816 \t ep_len: 103.816\n",
      "epoch: 1234 \t loss: -49.334 \t return: -100.240 \t ep_len: 101.240\n",
      "epoch: 1235 \t loss: -38.093 \t return: -90.436 \t ep_len: 91.436\n",
      "epoch: 1236 \t loss: -39.202 \t return: -85.310 \t ep_len: 86.310\n",
      "epoch: 1237 \t loss: -36.099 \t return: -87.333 \t ep_len: 88.333\n",
      "epoch: 1238 \t loss: -32.614 \t return: -82.145 \t ep_len: 83.145\n",
      "epoch: 1239 \t loss: -31.858 \t return: -82.650 \t ep_len: 83.650\n",
      "epoch: 1240 \t loss: -33.849 \t return: -87.421 \t ep_len: 88.421\n",
      "epoch: 1241 \t loss: -31.093 \t return: -77.141 \t ep_len: 78.141\n",
      "epoch: 1242 \t loss: -32.535 \t return: -80.661 \t ep_len: 81.661\n",
      "epoch: 1243 \t loss: -33.084 \t return: -89.429 \t ep_len: 90.429\n",
      "epoch: 1244 \t loss: -25.959 \t return: -79.219 \t ep_len: 80.219\n",
      "epoch: 1245 \t loss: -35.947 \t return: -87.441 \t ep_len: 88.441\n",
      "epoch: 1246 \t loss: -45.897 \t return: -105.702 \t ep_len: 106.702\n",
      "epoch: 1247 \t loss: -31.839 \t return: -81.803 \t ep_len: 82.803\n",
      "epoch: 1248 \t loss: -25.341 \t return: -74.881 \t ep_len: 75.881\n",
      "epoch: 1249 \t loss: -28.324 \t return: -81.443 \t ep_len: 82.443\n",
      "epoch: 1250 \t loss: -26.870 \t return: -71.522 \t ep_len: 72.522\n",
      "epoch: 1251 \t loss: -31.159 \t return: -86.224 \t ep_len: 87.224\n",
      "epoch: 1252 \t loss: -26.691 \t return: -76.292 \t ep_len: 77.292\n",
      "epoch: 1253 \t loss: -25.227 \t return: -75.284 \t ep_len: 76.284\n",
      "epoch: 1254 \t loss: -40.472 \t return: -93.333 \t ep_len: 94.333\n",
      "epoch: 1255 \t loss: -25.120 \t return: -79.694 \t ep_len: 80.694\n",
      "epoch: 1256 \t loss: -30.916 \t return: -79.742 \t ep_len: 80.742\n",
      "epoch: 1257 \t loss: -26.111 \t return: -72.912 \t ep_len: 73.912\n",
      "epoch: 1258 \t loss: -25.535 \t return: -76.246 \t ep_len: 77.246\n",
      "epoch: 1259 \t loss: -27.382 \t return: -79.317 \t ep_len: 80.317\n",
      "epoch: 1260 \t loss: -38.010 \t return: -95.769 \t ep_len: 96.769\n",
      "epoch: 1261 \t loss: -20.324 \t return: -64.156 \t ep_len: 65.156\n",
      "epoch: 1262 \t loss: -31.096 \t return: -81.065 \t ep_len: 82.065\n",
      "epoch: 1263 \t loss: -30.998 \t return: -78.492 \t ep_len: 79.492\n",
      "epoch: 1264 \t loss: -22.555 \t return: -65.987 \t ep_len: 66.987\n",
      "epoch: 1265 \t loss: -21.962 \t return: -72.676 \t ep_len: 73.676\n",
      "epoch: 1266 \t loss: -29.016 \t return: -73.882 \t ep_len: 74.882\n",
      "epoch: 1267 \t loss: -24.265 \t return: -75.954 \t ep_len: 76.954\n",
      "epoch: 1268 \t loss: -25.518 \t return: -79.742 \t ep_len: 80.742\n",
      "epoch: 1269 \t loss: -29.196 \t return: -83.417 \t ep_len: 84.417\n",
      "epoch: 1270 \t loss: -33.083 \t return: -75.358 \t ep_len: 76.358\n",
      "epoch: 1271 \t loss: -24.696 \t return: -73.500 \t ep_len: 74.500\n",
      "epoch: 1272 \t loss: -22.512 \t return: -72.261 \t ep_len: 73.261\n",
      "epoch: 1273 \t loss: -26.215 \t return: -80.145 \t ep_len: 81.145\n",
      "epoch: 1274 \t loss: -19.336 \t return: -62.620 \t ep_len: 63.620\n",
      "epoch: 1275 \t loss: -17.576 \t return: -62.350 \t ep_len: 63.350\n",
      "epoch: 1276 \t loss: -23.091 \t return: -77.077 \t ep_len: 78.077\n",
      "epoch: 1277 \t loss: -18.441 \t return: -69.472 \t ep_len: 70.472\n",
      "epoch: 1278 \t loss: -25.577 \t return: -73.824 \t ep_len: 74.824\n",
      "epoch: 1279 \t loss: -14.509 \t return: -62.212 \t ep_len: 63.212\n",
      "epoch: 1280 \t loss: -28.023 \t return: -80.403 \t ep_len: 81.403\n",
      "epoch: 1281 \t loss: -29.594 \t return: -84.695 \t ep_len: 85.695\n",
      "epoch: 1282 \t loss: -21.132 \t return: -77.108 \t ep_len: 78.108\n",
      "epoch: 1283 \t loss: -21.828 \t return: -73.676 \t ep_len: 74.676\n",
      "epoch: 1284 \t loss: -20.528 \t return: -71.536 \t ep_len: 72.536\n",
      "epoch: 1285 \t loss: -20.453 \t return: -65.130 \t ep_len: 66.130\n",
      "epoch: 1286 \t loss: -17.043 \t return: -61.012 \t ep_len: 62.012\n",
      "epoch: 1287 \t loss: -25.305 \t return: -74.045 \t ep_len: 75.045\n",
      "epoch: 1288 \t loss: -23.499 \t return: -77.077 \t ep_len: 78.077\n",
      "epoch: 1289 \t loss: -26.547 \t return: -82.410 \t ep_len: 83.410\n",
      "epoch: 1290 \t loss: -17.623 \t return: -61.173 \t ep_len: 62.173\n",
      "epoch: 1291 \t loss: -21.041 \t return: -69.278 \t ep_len: 70.278\n",
      "epoch: 1292 \t loss: -18.260 \t return: -63.362 \t ep_len: 64.362\n",
      "epoch: 1293 \t loss: -19.181 \t return: -65.276 \t ep_len: 66.276\n",
      "epoch: 1294 \t loss: -21.901 \t return: -65.263 \t ep_len: 66.263\n",
      "epoch: 1295 \t loss: -21.507 \t return: -64.221 \t ep_len: 65.221\n",
      "epoch: 1296 \t loss: -23.543 \t return: -72.647 \t ep_len: 73.647\n",
      "epoch: 1297 \t loss: -25.022 \t return: -66.808 \t ep_len: 67.808\n",
      "epoch: 1298 \t loss: -22.056 \t return: -73.806 \t ep_len: 74.806\n",
      "epoch: 1299 \t loss: -16.761 \t return: -59.277 \t ep_len: 60.277\n",
      "epoch: 1300 \t loss: -24.875 \t return: -74.761 \t ep_len: 75.761\n",
      "epoch: 1301 \t loss: -26.855 \t return: -76.134 \t ep_len: 77.134\n",
      "epoch: 1302 \t loss: -17.436 \t return: -60.402 \t ep_len: 61.402\n",
      "epoch: 1303 \t loss: -23.165 \t return: -69.634 \t ep_len: 70.634\n",
      "epoch: 1304 \t loss: -16.266 \t return: -57.233 \t ep_len: 58.233\n",
      "epoch: 1305 \t loss: -17.521 \t return: -63.282 \t ep_len: 64.282\n",
      "epoch: 1306 \t loss: -18.548 \t return: -70.831 \t ep_len: 71.831\n",
      "epoch: 1307 \t loss: -19.618 \t return: -60.829 \t ep_len: 61.829\n",
      "epoch: 1308 \t loss: -17.178 \t return: -59.867 \t ep_len: 60.867\n",
      "epoch: 1309 \t loss: -13.760 \t return: -58.023 \t ep_len: 59.023\n",
      "epoch: 1310 \t loss: -14.535 \t return: -59.819 \t ep_len: 60.819\n",
      "epoch: 1311 \t loss: -13.729 \t return: -56.955 \t ep_len: 57.955\n",
      "epoch: 1312 \t loss: -17.219 \t return: -61.737 \t ep_len: 62.737\n",
      "epoch: 1313 \t loss: -13.877 \t return: -55.225 \t ep_len: 56.225\n",
      "epoch: 1314 \t loss: -15.280 \t return: -59.566 \t ep_len: 60.566\n",
      "epoch: 1315 \t loss: -15.752 \t return: -58.082 \t ep_len: 59.082\n",
      "epoch: 1316 \t loss: -12.809 \t return: -57.558 \t ep_len: 58.558\n",
      "epoch: 1317 \t loss: -14.292 \t return: -57.314 \t ep_len: 58.314\n",
      "epoch: 1318 \t loss: -15.738 \t return: -57.663 \t ep_len: 58.663\n",
      "epoch: 1319 \t loss: -15.583 \t return: -58.412 \t ep_len: 59.412\n",
      "epoch: 1320 \t loss: -11.857 \t return: -52.989 \t ep_len: 53.989\n",
      "epoch: 1321 \t loss: -13.750 \t return: -54.978 \t ep_len: 55.978\n",
      "epoch: 1322 \t loss: -19.232 \t return: -60.914 \t ep_len: 61.914\n",
      "epoch: 1323 \t loss: -14.466 \t return: -57.884 \t ep_len: 58.884\n",
      "epoch: 1324 \t loss: -15.171 \t return: -56.713 \t ep_len: 57.713\n",
      "epoch: 1325 \t loss: -19.808 \t return: -69.507 \t ep_len: 70.507\n",
      "epoch: 1326 \t loss: -14.975 \t return: -58.233 \t ep_len: 59.233\n",
      "epoch: 1327 \t loss: -12.722 \t return: -53.804 \t ep_len: 54.804\n",
      "epoch: 1328 \t loss: -15.188 \t return: -53.170 \t ep_len: 54.170\n",
      "epoch: 1329 \t loss: -11.666 \t return: -50.918 \t ep_len: 51.918\n",
      "epoch: 1330 \t loss: -12.106 \t return: -52.383 \t ep_len: 53.383\n",
      "epoch: 1331 \t loss: -13.241 \t return: -53.630 \t ep_len: 54.630\n",
      "epoch: 1332 \t loss: -14.189 \t return: -57.242 \t ep_len: 58.242\n",
      "epoch: 1333 \t loss: -12.192 \t return: -53.652 \t ep_len: 54.652\n",
      "epoch: 1334 \t loss: -11.749 \t return: -50.122 \t ep_len: 51.122\n",
      "epoch: 1335 \t loss: -13.898 \t return: -49.129 \t ep_len: 50.129\n",
      "epoch: 1336 \t loss: -9.882 \t return: -49.260 \t ep_len: 50.260\n",
      "epoch: 1337 \t loss: -12.022 \t return: -50.773 \t ep_len: 51.773\n",
      "epoch: 1338 \t loss: -9.223 \t return: -47.689 \t ep_len: 48.689\n",
      "epoch: 1339 \t loss: -11.299 \t return: -52.809 \t ep_len: 53.809\n",
      "epoch: 1340 \t loss: -9.014 \t return: -44.936 \t ep_len: 45.936\n",
      "epoch: 1341 \t loss: -16.140 \t return: -55.463 \t ep_len: 56.463\n",
      "epoch: 1342 \t loss: -8.041 \t return: -45.324 \t ep_len: 46.324\n",
      "epoch: 1343 \t loss: -13.686 \t return: -55.886 \t ep_len: 56.886\n",
      "epoch: 1344 \t loss: -7.565 \t return: -48.059 \t ep_len: 49.059\n",
      "epoch: 1345 \t loss: -9.859 \t return: -48.373 \t ep_len: 49.373\n",
      "epoch: 1346 \t loss: -9.417 \t return: -51.125 \t ep_len: 52.125\n",
      "epoch: 1347 \t loss: -10.852 \t return: -50.020 \t ep_len: 51.020\n",
      "epoch: 1348 \t loss: -11.005 \t return: -54.889 \t ep_len: 55.889\n",
      "epoch: 1349 \t loss: -12.062 \t return: -54.154 \t ep_len: 55.154\n",
      "epoch: 1350 \t loss: -9.152 \t return: -47.864 \t ep_len: 48.864\n",
      "epoch: 1351 \t loss: -9.820 \t return: -49.230 \t ep_len: 50.230\n",
      "epoch: 1352 \t loss: -8.777 \t return: -45.532 \t ep_len: 46.532\n",
      "epoch: 1353 \t loss: -8.336 \t return: -45.771 \t ep_len: 46.771\n",
      "epoch: 1354 \t loss: -9.471 \t return: -50.418 \t ep_len: 51.418\n",
      "epoch: 1355 \t loss: -9.216 \t return: -45.794 \t ep_len: 46.794\n",
      "epoch: 1356 \t loss: -10.538 \t return: -48.059 \t ep_len: 49.059\n",
      "epoch: 1357 \t loss: -11.546 \t return: -51.227 \t ep_len: 52.227\n",
      "epoch: 1358 \t loss: -10.091 \t return: -44.800 \t ep_len: 45.800\n",
      "epoch: 1359 \t loss: -8.706 \t return: -47.028 \t ep_len: 48.028\n",
      "epoch: 1360 \t loss: -8.707 \t return: -44.216 \t ep_len: 45.216\n",
      "epoch: 1361 \t loss: -12.166 \t return: -57.218 \t ep_len: 58.218\n",
      "epoch: 1362 \t loss: -9.035 \t return: -48.118 \t ep_len: 49.118\n",
      "epoch: 1363 \t loss: -8.621 \t return: -45.822 \t ep_len: 46.822\n",
      "epoch: 1364 \t loss: -9.403 \t return: -47.394 \t ep_len: 48.394\n",
      "epoch: 1365 \t loss: -7.432 \t return: -46.236 \t ep_len: 47.236\n",
      "epoch: 1366 \t loss: -7.496 \t return: -41.974 \t ep_len: 42.974\n",
      "epoch: 1367 \t loss: -8.943 \t return: -48.088 \t ep_len: 49.088\n",
      "epoch: 1368 \t loss: -6.820 \t return: -42.371 \t ep_len: 43.371\n",
      "epoch: 1369 \t loss: -7.934 \t return: -45.916 \t ep_len: 46.916\n",
      "epoch: 1370 \t loss: -8.876 \t return: -45.092 \t ep_len: 46.092\n",
      "epoch: 1371 \t loss: -6.880 \t return: -44.108 \t ep_len: 45.108\n",
      "epoch: 1372 \t loss: -8.122 \t return: -44.564 \t ep_len: 45.564\n",
      "epoch: 1373 \t loss: -7.501 \t return: -45.389 \t ep_len: 46.389\n",
      "epoch: 1374 \t loss: -7.062 \t return: -45.426 \t ep_len: 46.426\n",
      "epoch: 1375 \t loss: -6.374 \t return: -40.875 \t ep_len: 41.875\n",
      "epoch: 1376 \t loss: -8.317 \t return: -45.972 \t ep_len: 46.972\n",
      "epoch: 1377 \t loss: -7.385 \t return: -43.310 \t ep_len: 44.310\n",
      "epoch: 1378 \t loss: -7.519 \t return: -46.733 \t ep_len: 47.733\n",
      "epoch: 1379 \t loss: -8.630 \t return: -45.330 \t ep_len: 46.330\n",
      "epoch: 1380 \t loss: -5.978 \t return: -40.975 \t ep_len: 41.975\n",
      "epoch: 1381 \t loss: -5.299 \t return: -37.984 \t ep_len: 38.984\n",
      "epoch: 1382 \t loss: -5.796 \t return: -40.115 \t ep_len: 41.115\n",
      "epoch: 1383 \t loss: -7.286 \t return: -42.982 \t ep_len: 43.982\n",
      "epoch: 1384 \t loss: -6.500 \t return: -41.636 \t ep_len: 42.636\n",
      "epoch: 1385 \t loss: -5.614 \t return: -39.984 \t ep_len: 40.984\n",
      "epoch: 1386 \t loss: -7.154 \t return: -41.092 \t ep_len: 42.092\n",
      "epoch: 1387 \t loss: -4.642 \t return: -39.387 \t ep_len: 40.387\n",
      "epoch: 1388 \t loss: -6.937 \t return: -44.081 \t ep_len: 45.081\n",
      "epoch: 1389 \t loss: -6.332 \t return: -39.878 \t ep_len: 40.878\n",
      "epoch: 1390 \t loss: -6.451 \t return: -41.769 \t ep_len: 42.769\n",
      "epoch: 1391 \t loss: -7.538 \t return: -40.512 \t ep_len: 41.512\n",
      "epoch: 1392 \t loss: -7.203 \t return: -42.868 \t ep_len: 43.868\n",
      "epoch: 1393 \t loss: -6.953 \t return: -40.867 \t ep_len: 41.867\n",
      "epoch: 1394 \t loss: -5.421 \t return: -42.164 \t ep_len: 43.164\n",
      "epoch: 1395 \t loss: -5.304 \t return: -37.922 \t ep_len: 38.922\n",
      "epoch: 1396 \t loss: -5.085 \t return: -39.387 \t ep_len: 40.387\n",
      "epoch: 1397 \t loss: -6.424 \t return: -41.717 \t ep_len: 42.717\n",
      "epoch: 1398 \t loss: -8.481 \t return: -46.790 \t ep_len: 47.790\n",
      "epoch: 1399 \t loss: -5.733 \t return: -41.261 \t ep_len: 42.261\n",
      "epoch: 1400 \t loss: -6.009 \t return: -42.241 \t ep_len: 43.241\n",
      "epoch: 1401 \t loss: -5.695 \t return: -41.067 \t ep_len: 42.067\n",
      "epoch: 1402 \t loss: -7.573 \t return: -44.333 \t ep_len: 45.333\n",
      "epoch: 1403 \t loss: -6.568 \t return: -39.911 \t ep_len: 40.911\n",
      "epoch: 1404 \t loss: -4.919 \t return: -39.200 \t ep_len: 40.200\n",
      "epoch: 1405 \t loss: -5.814 \t return: -42.826 \t ep_len: 43.826\n",
      "epoch: 1406 \t loss: -4.462 \t return: -38.425 \t ep_len: 39.425\n",
      "epoch: 1407 \t loss: -5.433 \t return: -41.118 \t ep_len: 42.118\n",
      "epoch: 1408 \t loss: -7.962 \t return: -45.574 \t ep_len: 46.574\n",
      "epoch: 1409 \t loss: -4.856 \t return: -39.419 \t ep_len: 40.419\n",
      "epoch: 1410 \t loss: -5.474 \t return: -39.200 \t ep_len: 40.200\n",
      "epoch: 1411 \t loss: -5.134 \t return: -39.183 \t ep_len: 40.183\n",
      "epoch: 1412 \t loss: -5.962 \t return: -42.336 \t ep_len: 43.336\n",
      "epoch: 1413 \t loss: -5.541 \t return: -39.387 \t ep_len: 40.387\n",
      "epoch: 1414 \t loss: -3.979 \t return: -38.172 \t ep_len: 39.172\n",
      "epoch: 1415 \t loss: -6.169 \t return: -41.298 \t ep_len: 42.298\n",
      "epoch: 1416 \t loss: -4.759 \t return: -38.865 \t ep_len: 39.865\n",
      "epoch: 1417 \t loss: -4.620 \t return: -37.969 \t ep_len: 38.969\n",
      "epoch: 1418 \t loss: -5.466 \t return: -39.120 \t ep_len: 40.120\n",
      "epoch: 1419 \t loss: -4.813 \t return: -38.062 \t ep_len: 39.062\n",
      "epoch: 1420 \t loss: -6.066 \t return: -41.244 \t ep_len: 42.244\n",
      "epoch: 1421 \t loss: -5.315 \t return: -38.968 \t ep_len: 39.968\n",
      "epoch: 1422 \t loss: -6.228 \t return: -41.880 \t ep_len: 42.880\n",
      "epoch: 1423 \t loss: -4.169 \t return: -37.623 \t ep_len: 38.623\n",
      "epoch: 1424 \t loss: -7.423 \t return: -44.297 \t ep_len: 45.297\n",
      "epoch: 1425 \t loss: -3.405 \t return: -36.507 \t ep_len: 37.507\n",
      "epoch: 1426 \t loss: -4.495 \t return: -38.289 \t ep_len: 39.289\n",
      "epoch: 1427 \t loss: -3.337 \t return: -35.824 \t ep_len: 36.824\n",
      "epoch: 1428 \t loss: -4.936 \t return: -37.715 \t ep_len: 38.715\n",
      "epoch: 1429 \t loss: -5.043 \t return: -37.569 \t ep_len: 38.569\n",
      "epoch: 1430 \t loss: -3.534 \t return: -37.083 \t ep_len: 38.083\n",
      "epoch: 1431 \t loss: -5.332 \t return: -38.730 \t ep_len: 39.730\n",
      "epoch: 1432 \t loss: -3.685 \t return: -36.609 \t ep_len: 37.609\n",
      "epoch: 1433 \t loss: -3.624 \t return: -35.599 \t ep_len: 36.599\n",
      "epoch: 1434 \t loss: -4.321 \t return: -37.508 \t ep_len: 38.508\n",
      "epoch: 1435 \t loss: -3.840 \t return: -36.609 \t ep_len: 37.609\n",
      "epoch: 1436 \t loss: -4.127 \t return: -37.260 \t ep_len: 38.260\n",
      "epoch: 1437 \t loss: -4.349 \t return: -38.724 \t ep_len: 39.724\n",
      "epoch: 1438 \t loss: -4.083 \t return: -36.684 \t ep_len: 37.684\n",
      "epoch: 1439 \t loss: -4.358 \t return: -37.227 \t ep_len: 38.227\n",
      "epoch: 1440 \t loss: -5.563 \t return: -40.131 \t ep_len: 41.131\n",
      "epoch: 1441 \t loss: -6.372 \t return: -44.288 \t ep_len: 45.288\n",
      "epoch: 1442 \t loss: -5.385 \t return: -41.050 \t ep_len: 42.050\n",
      "epoch: 1443 \t loss: -4.265 \t return: -37.313 \t ep_len: 38.313\n",
      "epoch: 1444 \t loss: -5.057 \t return: -40.792 \t ep_len: 41.792\n",
      "epoch: 1445 \t loss: -5.128 \t return: -39.176 \t ep_len: 40.176\n",
      "epoch: 1446 \t loss: -4.897 \t return: -38.078 \t ep_len: 39.078\n",
      "epoch: 1447 \t loss: -5.390 \t return: -41.983 \t ep_len: 42.983\n",
      "epoch: 1448 \t loss: -6.334 \t return: -41.778 \t ep_len: 42.778\n",
      "epoch: 1449 \t loss: -5.348 \t return: -39.104 \t ep_len: 40.104\n",
      "epoch: 1450 \t loss: -4.445 \t return: -36.737 \t ep_len: 37.737\n",
      "epoch: 1451 \t loss: -2.804 \t return: -34.634 \t ep_len: 35.634\n",
      "epoch: 1452 \t loss: -4.497 \t return: -37.083 \t ep_len: 38.083\n",
      "epoch: 1453 \t loss: -5.774 \t return: -46.829 \t ep_len: 47.819\n",
      "epoch: 1454 \t loss: -4.479 \t return: -38.881 \t ep_len: 39.881\n",
      "epoch: 1455 \t loss: -4.609 \t return: -38.016 \t ep_len: 39.016\n",
      "epoch: 1456 \t loss: -3.199 \t return: -35.882 \t ep_len: 36.882\n",
      "epoch: 1457 \t loss: -3.142 \t return: -35.058 \t ep_len: 36.058\n",
      "epoch: 1458 \t loss: -4.621 \t return: -38.746 \t ep_len: 39.746\n",
      "epoch: 1459 \t loss: -3.211 \t return: -37.344 \t ep_len: 38.344\n",
      "epoch: 1460 \t loss: -3.469 \t return: -36.396 \t ep_len: 37.396\n",
      "epoch: 1461 \t loss: -3.349 \t return: -36.230 \t ep_len: 37.230\n",
      "epoch: 1462 \t loss: -3.353 \t return: -36.141 \t ep_len: 37.141\n",
      "epoch: 1463 \t loss: -3.137 \t return: -35.533 \t ep_len: 36.533\n",
      "epoch: 1464 \t loss: -3.834 \t return: -37.783 \t ep_len: 38.783\n",
      "epoch: 1465 \t loss: -4.194 \t return: -35.779 \t ep_len: 36.779\n",
      "epoch: 1466 \t loss: -3.104 \t return: -34.786 \t ep_len: 35.786\n",
      "epoch: 1467 \t loss: -3.054 \t return: -36.530 \t ep_len: 37.530\n",
      "epoch: 1468 \t loss: -3.639 \t return: -36.358 \t ep_len: 37.358\n",
      "epoch: 1469 \t loss: -3.705 \t return: -36.530 \t ep_len: 37.530\n",
      "epoch: 1470 \t loss: -2.776 \t return: -34.843 \t ep_len: 35.843\n",
      "epoch: 1471 \t loss: -4.602 \t return: -38.266 \t ep_len: 39.266\n",
      "epoch: 1472 \t loss: -3.764 \t return: -36.259 \t ep_len: 37.259\n",
      "epoch: 1473 \t loss: -5.910 \t return: -38.394 \t ep_len: 39.394\n",
      "epoch: 1474 \t loss: -2.724 \t return: -34.437 \t ep_len: 35.437\n",
      "epoch: 1475 \t loss: -4.578 \t return: -37.961 \t ep_len: 38.961\n",
      "epoch: 1476 \t loss: -2.955 \t return: -36.259 \t ep_len: 37.259\n",
      "epoch: 1477 \t loss: -3.049 \t return: -35.876 \t ep_len: 36.876\n",
      "epoch: 1478 \t loss: -2.526 \t return: -34.652 \t ep_len: 35.652\n",
      "epoch: 1479 \t loss: -3.673 \t return: -36.311 \t ep_len: 37.311\n",
      "epoch: 1480 \t loss: -5.703 \t return: -40.700 \t ep_len: 41.700\n",
      "epoch: 1481 \t loss: -2.936 \t return: -35.875 \t ep_len: 36.875\n",
      "epoch: 1482 \t loss: -3.413 \t return: -36.104 \t ep_len: 37.104\n",
      "epoch: 1483 \t loss: -3.190 \t return: -35.686 \t ep_len: 36.686\n",
      "epoch: 1484 \t loss: -3.481 \t return: -36.215 \t ep_len: 37.215\n",
      "epoch: 1485 \t loss: -3.330 \t return: -35.239 \t ep_len: 36.239\n",
      "epoch: 1486 \t loss: -3.356 \t return: -36.089 \t ep_len: 37.089\n",
      "epoch: 1487 \t loss: -4.141 \t return: -36.485 \t ep_len: 37.485\n",
      "epoch: 1488 \t loss: -2.637 \t return: -34.394 \t ep_len: 35.394\n",
      "epoch: 1489 \t loss: -2.857 \t return: -35.331 \t ep_len: 36.331\n",
      "epoch: 1490 \t loss: -3.391 \t return: -36.992 \t ep_len: 37.992\n",
      "epoch: 1491 \t loss: -2.897 \t return: -35.246 \t ep_len: 36.246\n",
      "epoch: 1492 \t loss: -2.508 \t return: -34.624 \t ep_len: 35.624\n",
      "epoch: 1493 \t loss: -4.213 \t return: -37.313 \t ep_len: 38.313\n",
      "epoch: 1494 \t loss: -3.565 \t return: -36.331 \t ep_len: 37.331\n",
      "epoch: 1495 \t loss: -3.384 \t return: -35.022 \t ep_len: 36.022\n",
      "epoch: 1496 \t loss: -2.708 \t return: -34.028 \t ep_len: 35.028\n",
      "epoch: 1497 \t loss: -2.886 \t return: -35.985 \t ep_len: 36.985\n",
      "epoch: 1498 \t loss: -3.145 \t return: -36.358 \t ep_len: 37.358\n",
      "epoch: 1499 \t loss: -3.412 \t return: -35.831 \t ep_len: 36.831\n"
     ]
    }
   ],
   "source": [
    "policy = train(env_name = env_wrapped_rew, hidden_sizes = [32], lr = 1e-2, epochs = 1500, batch_size = 5000, render = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=147, out_features=32, bias=True)\n",
       "  (1): Linear(in_features=32, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138.88888888888889"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5000/36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomStart(gym.Wrapper):\n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset(**kwargs)   # ← still a dict here\n",
    "        base = self.unwrapped                  # MiniGridEnv\n",
    "\n",
    "        # sample a free floor tile\n",
    "        while True:\n",
    "            x = base.np_random.integers(1, base.width  - 1)\n",
    "            y = base.np_random.integers(1, base.height - 1)\n",
    "            if base.grid.get(x, y) is None:\n",
    "                base.agent_pos = (x, y)\n",
    "                base.agent_dir = base.np_random.integers(0, 4)\n",
    "                break\n",
    "\n",
    "        # regenerate dict-obs; *do not* flatten here\n",
    "        obs = base.gen_obs()\n",
    "        return obs, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_base   = LargeSimpleEnv(render_mode=\"human\")\n",
    "env_rs     = RandomStart(env_base)       # randomise first\n",
    "env_flat   = MiniGridFlatImg(env_rs)     # then flatten\n",
    "env_wr     = MiniGridReward(env_flat, goal_states=[(8, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to always start at the behinning at the start of each episode\n",
    "# # create the base env *with* a render mode\n",
    "# env_base = SimpleEnv(render_mode=\"human\")      # window pops up\n",
    "# # or render_mode=\"rgb_array\"  # returns an image you can display in a notebook\n",
    "\n",
    "# # wrap exactly as before\n",
    "# env_flat_vis  = MiniGridFlatImg(env_base)\n",
    "# env_wrapped_rew_vis = MiniGridReward(env_flat_vis, goal_states=[(8, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[165], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m             env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m finished with reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(ep_rews)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mplay_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_wr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[165], line 24\u001b[0m, in \u001b[0;36mplay_policy\u001b[0;34m(env, policy, num_episodes)\u001b[0m\n\u001b[1;32m     22\u001b[0m     obs, rew, done, _, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     23\u001b[0m     ep_rews\u001b[38;5;241m.\u001b[39mappend(rew)\n\u001b[0;32m---> 24\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m finished with reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(ep_rews)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/IBP/lib/python3.11/site-packages/gymnasium/core.py:332\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/IBP/lib/python3.11/site-packages/gymnasium/core.py:332\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/IBP/lib/python3.11/site-packages/gymnasium/core.py:332\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/IBP/lib/python3.11/site-packages/minigrid/minigrid_env.py:781\u001b[0m, in \u001b[0;36mMiniGridEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow\u001b[38;5;241m.\u001b[39mblit(bg, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    780\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mpump()\n\u001b[0;32m--> 781\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mflip()\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#takes policy network and returns action distribution\n",
    "def get_policy(obs):\n",
    "    logits = policy(obs)\n",
    "    return Categorical(logits = logits)\n",
    "\n",
    "#samples actions from the action distrubution from the policy network\n",
    "def get_action(obs):\n",
    "    return get_policy(obs).sample().item()\n",
    "\n",
    "\n",
    "\n",
    "def play_policy(env, policy, num_episodes=1):\n",
    "    \"\"\"\n",
    "    Play the policy in the environment for a number of episodes.\n",
    "    \"\"\"\n",
    "    for episode in range(num_episodes):\n",
    "        obs, info = env.reset()\n",
    "        done = False\n",
    "        ep_rews = []\n",
    "        while not done:\n",
    "            action = get_action(torch.as_tensor(obs, dtype=torch.float32))\n",
    "            obs, rew, done, _, _ = env.step(action)\n",
    "            ep_rews.append(rew)\n",
    "            env.render()\n",
    "        print(f\"Episode {episode + 1} finished with reward: {sum(ep_rews)}\")\n",
    "\n",
    "play_policy(env_wr, policy, num_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = env.unwrapped.grid.get(1, 8)\n",
    "cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Generalizability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LargeSimpleEnv(MiniGridEnv):\n",
    "    def __init__(\n",
    "            self, \n",
    "            size=20, \n",
    "            agent_start_pos=(1, 8), \n",
    "            agent_start_dir=0, \n",
    "            max_steps=1000, \n",
    "            **kwargs,\n",
    "    ):\n",
    "        self.agent_start_pos = agent_start_pos\n",
    "        self.agent_start_dir = agent_start_dir\n",
    "        self.goal_pos = (8, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
    "\n",
    "        super().__init__(\n",
    "            mission_space=mission_space,\n",
    "            grid_size=size,\n",
    "            max_steps=max_steps,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "    @staticmethod\n",
    "    def _gen_mission():\n",
    "        return \"Find the shortest path\"\n",
    "\n",
    "    def _gen_grid(self, width, height):\n",
    "        #create gird\n",
    "        self.grid = Grid(width, height)\n",
    "        #place barrier\n",
    "        self.grid.wall_rect(0, 0, width, height)\n",
    "        #place goal\n",
    "        self.put_obj(Goal(), 8, 1)\n",
    "        #place walls\n",
    "        for i in range(1, width // 2):\n",
    "            self.grid.set(i, width - 4, Wall())\n",
    "            self.grid.set(i + width // 2 - 1, width - 7, Wall())\n",
    "            self.grid.set(i, width - 10, Wall())\n",
    "            self.grid.set(i + width // 2 - 1, width - 13, Wall())\n",
    "            self.grid.set(i, height - 4, Wall())\n",
    "        #place agent\n",
    "        if self.agent_start_pos is not None:\n",
    "            self.agent_pos = self.agent_start_pos #check this\n",
    "            self.agent_dir = self.agent_start_dir\n",
    "        else:\n",
    "            self.place_agent()\n",
    "\n",
    "        self.mission = \"find the shortest path\"\n",
    "    \n",
    "    def count_states(self):\n",
    "        free_cells = sum(1 for x in range(self.grid.width)\n",
    "                      for y in range(self.grid.height)\n",
    "                      if not self.grid.get(x, y)) * 4\n",
    "        return free_cells \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
