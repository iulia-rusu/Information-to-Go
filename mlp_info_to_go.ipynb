{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __future__ import should always be first\n",
    "from __future__ import annotations\n",
    "\n",
    "# Standard library imports\n",
    "from collections import defaultdict\n",
    "\n",
    "# Third-party imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "# Gymnasium & Minigrid imports\n",
    "import gymnasium as gym  # Correct way to import Gymnasium\n",
    "from gymnasium.spaces import Dict, Discrete, Box\n",
    "from minigrid.core.constants import COLOR_NAMES\n",
    "from minigrid.core.constants import DIR_TO_VEC\n",
    "from minigrid.core.grid import Grid\n",
    "from minigrid.core.actions import Actions\n",
    "from minigrid.core.mission import MissionSpace\n",
    "from minigrid.core.world_object import Door, Goal, Key, Wall\n",
    "from minigrid.manual_control import ManualControl\n",
    "from minigrid.minigrid_env import MiniGridEnv\n",
    "from gymnasium.utils.play import play\n",
    "import pandas as pd\n",
    "# Visualization imports\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleEnv(MiniGridEnv):\n",
    "    def __init__(\n",
    "            self, \n",
    "            size=10, \n",
    "            agent_start_pos=(1, 8), \n",
    "            agent_start_dir=0, \n",
    "            max_steps=256, \n",
    "            **kwargs,\n",
    "    ):\n",
    "        self.agent_start_pos = agent_start_pos\n",
    "        self.agent_start_dir = agent_start_dir\n",
    "        self.goal_pos = (8, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
    "\n",
    "        super().__init__(\n",
    "            mission_space=mission_space,\n",
    "            grid_size=size,\n",
    "            max_steps=max_steps,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "    @staticmethod\n",
    "    def _gen_mission():\n",
    "        return \"Find the shortest path\"\n",
    "\n",
    "    def _gen_grid(self, width, height):\n",
    "        #create gird\n",
    "        self.grid = Grid(width, height)\n",
    "        #place barrier\n",
    "        self.grid.wall_rect(0, 0, width, height)\n",
    "        #place goal\n",
    "        self.put_obj(Goal(), 8, 1)\n",
    "        #place walls\n",
    "        for i in range(1, width // 2):\n",
    "            self.grid.set(i, width - 4, Wall())\n",
    "            self.grid.set(i + width // 2 - 1, width - 7, Wall())\n",
    "        #place agent\n",
    "        if self.agent_start_pos is not None:\n",
    "            self.agent_pos = self.agent_start_pos #check this\n",
    "            self.agent_dir = self.agent_start_dir\n",
    "        else:\n",
    "            self.place_agent()\n",
    "\n",
    "        self.mission = \"find the shortest path\"\n",
    "    \n",
    "    def count_states(self):\n",
    "        free_cells = sum(1 for x in range(self.grid.width)\n",
    "                      for y in range(self.grid.height)\n",
    "                      if not self.grid.get(x, y)) * 4\n",
    "        return free_cells \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is working code for a simple minigrid environment with full view.\"\"\"\n",
    "\n",
    "class SimpleEnv(MiniGridEnv):\n",
    "    def __init__(\n",
    "        self, \n",
    "        size=10, \n",
    "        agent_start_pos=(1, 8), \n",
    "        agent_start_dir=0, \n",
    "        max_steps=256, \n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.agent_start_pos = agent_start_pos\n",
    "        self.agent_start_dir = agent_start_dir\n",
    "        self.goal_pos = (8, 1)\n",
    "\n",
    "        # Create a simple mission space\n",
    "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
    "\n",
    "        # Use an odd agent_view_size to pass MiniGrid's assertion\n",
    "        # Even though we'll override gen_obs(), we still need an odd value here.\n",
    "        super().__init__(\n",
    "            mission_space=mission_space,\n",
    "            grid_size=size,\n",
    "            max_steps=max_steps,\n",
    "            agent_view_size=11,  # Must be odd (>= size)\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        # 3 discrete actions (forward, turn left, turn right)\n",
    "        self.action_space = Discrete(3)\n",
    "\n",
    "    @staticmethod\n",
    "    def _gen_mission():\n",
    "        return \"Find the shortest path\"\n",
    "\n",
    "    def _gen_grid(self, width, height):\n",
    "        # Create the grid\n",
    "        self.grid = Grid(width, height)\n",
    "        # Place outer walls\n",
    "        self.grid.wall_rect(0, 0, width, height)\n",
    "        # Place a goal\n",
    "        self.put_obj(Goal(), 8, 1)\n",
    "        # Place some walls\n",
    "        for i in range(1, width // 2):\n",
    "            self.grid.set(i, width - 4, Wall())\n",
    "            self.grid.set(i + width // 2 - 1, width - 7, Wall())\n",
    "\n",
    "        # Place agent\n",
    "        if self.agent_start_pos is not None:\n",
    "            self.agent_pos = self.agent_start_pos\n",
    "            self.agent_dir = self.agent_start_dir\n",
    "        else:\n",
    "            self.place_agent()\n",
    "\n",
    "        self.mission = \"find the shortest path\"\n",
    "\n",
    "    def count_states(self):\n",
    "        free_cells = sum(\n",
    "            1\n",
    "            for x in range(self.grid.width)\n",
    "            for y in range(self.grid.height)\n",
    "            if not self.grid.get(x, y)\n",
    "        ) * 4\n",
    "        return free_cells \n",
    "\n",
    "    def gen_obs(self):\n",
    "        \"\"\"Override the default partial-view to return the full grid.\"\"\"\n",
    "        full_grid = self.grid.encode()  # shape (width, height, 3)\n",
    "        return {\n",
    "            \"image\": full_grid,\n",
    "            \"direction\": self.agent_dir,\n",
    "            \"mission\": self.mission\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SimpleEnv(render_mode= None)\n",
    "env.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs shape after step: (7, 7, 3)\n"
     ]
    }
   ],
   "source": [
    "action = 0\n",
    "obs, _, _, _, _ = env.step(action)\n",
    "print(\"Obs shape after step:\", obs[\"image\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs shape after step: (7, 7, 3)\n"
     ]
    }
   ],
   "source": [
    "action = 2\n",
    "obs1, _, _, _, _ = env.step(action)\n",
    "print(\"Obs shape after step:\", obs[\"image\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False,  True],\n",
       "        [ True,  True,  True]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[\"image\"] == obs1[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(sizes, activation = nn.Tanh, output_activation = nn.Identity):\n",
    "    layers = []\n",
    "    for i in range(len(sizes) - 1):\n",
    "        act = activation if i < len(sizes) -2 else output_activation \n",
    "        layers += [nn.Linear(sizes [i], sizes[i +1], act())]\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env_name = env, hidden_sizes = [32], lr = 1e-2, epochs = 50, batch_size = 5000, render = False):\n",
    "\n",
    "    obs_dim = env.observation_space.shape[0] \n",
    "    n_acts = env.action_space.n\n",
    "\n",
    "    #generate polucy network\n",
    "    logits_net = mlp(sizes = [obs_dim] + hidden_sizes + [n_acts])\n",
    "\n",
    "    #takes policy network and returns action distribution\n",
    "    def get_policy(obs):\n",
    "        logits = logits_net(obs)\n",
    "        return Categorical(logits = logits)\n",
    "\n",
    "    #samples actions from the action distrubution from the policy network\n",
    "    def get_action(obs):\n",
    "        return get_policy(obs).sample().item()\n",
    "    \n",
    "    #loss function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
